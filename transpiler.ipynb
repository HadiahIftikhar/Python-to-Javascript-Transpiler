{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed207ce",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "##### Keywords: if, else, elif, while, for, in, def, return, True, False, None\n",
    "##### Operators: +, -, *, /, %, **, =, ==, !=, <, >, <=, >=, and, or, not\n",
    "##### Delimiters: (, ), {, }, [, ], ',' , '.', ':', ';'\n",
    "##### Literals: INTEGER, FLOAT, STRING\n",
    "##### Other: IDENTIFIER, INDENT, DEDENT, NEWLINE, EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96572fc",
   "metadata": {},
   "source": [
    "## Token and Error Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910907aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Generator, List, Optional, Tuple\n",
    "\n",
    "class Token:\n",
    "    def __init__(self, type: str, value: str, line: int, column: int):\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "        self.line = line\n",
    "        self.column = column\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Token({self.type}, '{self.value}', line={self.line}, col={self.column})\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "class Error:\n",
    "    def __init__(self, message: str, line: int, column: int):\n",
    "        self.message = message\n",
    "        self.line = line\n",
    "        self.column = column\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Error: {self.message} at line {self.line}, column {self.column}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d04a7",
   "metadata": {},
   "source": [
    "## Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec43f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    # Defining regular expressions for token\n",
    "    TOKEN_SPECS = [\n",
    "        ('COMMENT', r'#.*'),                                  # Comments\n",
    "        ('STRING', r'\\\"([^\\\\\\\"]|\\\\.)*\\\"|\\'([^\\\\\\']|\\\\.)*\\''), # String literals\n",
    "        ('FLOAT', r'\\d+\\.\\d+'),                               # Float literals\n",
    "        ('INTEGER', r'\\d+'),                                  # Integer literals\n",
    "        ('KEYWORD', r'(if|else|elif|while|for|in|def|return|True|False|None)\\b'),  # Keywords\n",
    "        ('IDENTIFIER', r'[a-zA-Z_]\\w*'),                      # Identifiers\n",
    "        # Operators (multi-character ones first)\n",
    "        ('OP_EQ', r'=='),\n",
    "        ('OP_NE', r'!='),\n",
    "        ('OP_LE', r'<='),\n",
    "        ('OP_GE', r'>='),\n",
    "        ('OP_ASSIGN', r'='),\n",
    "        ('OP_PLUS', r'\\+'),\n",
    "        ('OP_MINUS', r'-'),\n",
    "        ('OP_MULT', r'\\*\\*|\\/\\/|\\*|\\/'),  # ** (power), // (floor div), * (mult), / (div)\n",
    "        ('OP_MOD', r'%'),\n",
    "        ('OP_LT', r'<'),\n",
    "        ('OP_GT', r'>'),\n",
    "        # Delimiters\n",
    "        ('LPAREN', r'\\('),\n",
    "        ('RPAREN', r'\\)'),\n",
    "        ('LBRACKET', r'\\['),\n",
    "        ('RBRACKET', r'\\]'),\n",
    "        ('LBRACE', r'\\{'),\n",
    "        ('RBRACE', r'\\}'),\n",
    "        ('COMMA', r','),\n",
    "        ('DOT', r'\\.'),\n",
    "        ('COLON', r':'),\n",
    "        ('SEMICOLON', r';'),\n",
    "        ('NEWLINE', r'\\n'),\n",
    "        ('WHITESPACE', r'[ \\t]+'),                            # Whitespace\n",
    "        # INDENT and DEDENT tokens are not matched by regex but generated based on whitespace\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, source_code: str):\n",
    "        self.source_code = source_code\n",
    "        self.tokens = []\n",
    "        self.errors = []\n",
    "        self.line = 1\n",
    "        self.column = 1\n",
    "        self.indent_levels = [0]  # Start with indent level 0\n",
    "    \n",
    "    def tokenize(self) -> Generator[Token, None, None]:\n",
    "        \"\"\"Tokenize the source code and yield tokens.\"\"\"\n",
    "        # Process the source code line by line to handle indentation properly\n",
    "        lines = self.source_code.split('\\n')\n",
    "        \n",
    "        for line_num, line in enumerate(lines):\n",
    "            self.line = line_num + 1\n",
    "            self.column = 1\n",
    "            \n",
    "            #calculating the amount of leading whitespace (indentation) at the beginning of the current line\n",
    "            if line.strip():  # Non-empty line      #strip() is equivalent of trim() in JS\n",
    "                indent_size = len(line) - len(line.lstrip())    #lstrip() will remove leading spaces in the line i.e. remove any indentation; and the difference in length tells you how much whitespace there was\n",
    "                indent_tokens = self._handle_indentation(indent_size)\n",
    "                for token in indent_tokens:\n",
    "                    yield token\n",
    "            else:   # Skip empty lines but still count them for line numbers\n",
    "                yield Token('NEWLINE', '\\\\n', self.line, self.column)\n",
    "                continue\n",
    "            \n",
    "            # Process the rest of the line\n",
    "            i = indent_size if 'indent_size' in locals() else 0\n",
    "            line_content = line\n",
    "            \n",
    "            while i < len(line_content):    #traversing a line character by character\n",
    "                match = None\n",
    "                \n",
    "                ## Skip spaces and tabs (already handled indentation)\n",
    "                ##if line_content[i].isspace():   #isspace() checks if the entire line is whitespace or not; here it checks whether a single character is whitespace or not since its applied on line_content[i]\n",
    "                ##    i += 1\n",
    "                ##    self.column += 1\n",
    "                ##    continue\n",
    "                \n",
    "                # Try to match each token pattern\n",
    "                for token_type, pattern in self.TOKEN_SPECS:\n",
    "                    regex = re.compile(pattern) #compiling the pattern into a regex so that we can use it to find tokens in the line\n",
    "                    match = regex.match(line_content, i)    #match() will check if the \"starting\" of the string matches the given regex or not, line_content gives the line whose starting it has to compare with the regex with i telling from which point in the line to assume as thhe starting of the line\n",
    "                    #if a match is found, 'match' will contain an object with info about the found match (like start and end, its value and so on), otherwise it'll contain \"none\"\n",
    "                    \n",
    "                    if match:\n",
    "                        value = match.group(0)  #group will give the value of the match object\n",
    "                        \n",
    "                        if token_type == 'WHITESPACE':\n",
    "                            #whitespace is not yielded becuz parser receives stream of tokens without space and doesnt care about space\n",
    "                            # Just update column and continue\n",
    "                            self.column += len(value)\n",
    "                            i += len(value)\n",
    "                            continue\n",
    "                        elif token_type == 'COMMENT':\n",
    "                            # Ignore comments\n",
    "                            i += len(value)\n",
    "                            self.column += len(value)\n",
    "                            break   # Break out of the current character processing loop after handling comments\n",
    "                        else:\n",
    "                            # For all other tokens\n",
    "                            token = Token(token_type, value, self.line, self.column)\n",
    "                            yield token\n",
    "                        \n",
    "                        i += len(value)\n",
    "                        self.column += len(value)\n",
    "                        break\n",
    "                \n",
    "                if not match:\n",
    "                    # No token matched, raise an error\n",
    "                    error_msg = f\"Invalid character: '{line_content[i]}'\"\n",
    "                    error = Error(error_msg, self.line, self.column)\n",
    "                    self.errors.append(error)\n",
    "                    print(error)  # Print the error but continue\n",
    "                    i += 1\n",
    "                    self.column += 1\n",
    "            \n",
    "            # Add NEWLINE at the end of each line except the last one\n",
    "            if line_num < len(lines) - 1 or self.source_code.endswith('\\n'):\n",
    "                yield Token('NEWLINE', '\\\\n', self.line, self.column)\n",
    "        \n",
    "        # Output any pending dedents at the end of the file\n",
    "        #end of file means all indented blocks have been dedented so pop all elements of the indent_levels stack\n",
    "        while len(self.indent_levels) > 1:\n",
    "            self.indent_levels.pop()    \n",
    "            yield Token('DEDENT', '', self.line, self.column)\n",
    "        \n",
    "        # End of file token\n",
    "        yield Token('EOF', '', self.line, self.column)\n",
    "    \n",
    "    def _handle_indentation(self, indent_size: int) -> List[Token]:\n",
    "        \"\"\"Handle Python's indentation-based block structure. Returns a list of INDENT or DEDENT tokens as needed.\"\"\"\n",
    "        tokens = []\n",
    "        previous_line_indent = self.indent_levels[-1]\n",
    "        \n",
    "        if indent_size > previous_line_indent:\n",
    "            # This is an indentation (start of a new block)\n",
    "            self.indent_levels.append(indent_size)  #when a new block is recognized through indentation its indentation level is pushed in the stack so that w ecan later check whether that block was dedented properly or not\n",
    "            tokens.append(Token('INDENT', ' ' * (indent_size - previous_line_indent), self.line, 1))\n",
    "        \n",
    "        elif indent_size < previous_line_indent:\n",
    "            # This is a dedentation (end of one or more blocks)\n",
    "            while self.indent_levels and indent_size < self.indent_levels[-1]: # ensuring that the latest code block is being dedented\n",
    "                self.indent_levels.pop()\n",
    "                tokens.append(Token('DEDENT', '', self.line, 1))\n",
    "            \n",
    "            if indent_size != self.indent_levels[-1]:\n",
    "                # Invalid indentation\n",
    "                error_msg = f\"Inconsistent indentation\"\n",
    "                error = Error(error_msg, self.line, 1)\n",
    "                self.errors.append(error)\n",
    "                print(error)  # Print the error but continue\n",
    "                \n",
    "                \n",
    "                # and what about handling indent_size == self.indent_levels[-1]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b0182e",
   "metadata": {},
   "source": [
    "## Test Script for Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c75670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lexer(source_code, test_name=\"\"):\n",
    "    print(f\"\\n=== Testing {test_name} ===\")\n",
    "    print(f\"Source code:\\n{source_code}\")\n",
    "    print(\"\\nTokens:\")\n",
    "    \n",
    "    lexer = Lexer(source_code)\n",
    "    token_count = 0\n",
    "    \n",
    "    try:\n",
    "        for token in lexer.tokenize():\n",
    "            print(token)\n",
    "            token_count += 1\n",
    "        \n",
    "        print(f\"\\nTotal tokens: {token_count}\")\n",
    "        if lexer.errors:\n",
    "            print(f\"\\nErrors ({len(lexer.errors)}):\")\n",
    "            for error in lexer.errors:\n",
    "                print(f\"  {error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Test cases\n",
    "if __name__ == \"__main__\":\n",
    "    # Test 1: Basic variable assignment\n",
    "    test_lexer(\"x = 10\", \"Basic Assignment\")\n",
    "\n",
    "    # Test 2: Simple function definition\n",
    "    test_lexer(\"\"\"def add(a, b):\n",
    "    return a + b\"\"\", \"Function Definition\")\n",
    "\n",
    "    # Test 3: If statement with proper indentation\n",
    "    test_lexer(\"\"\"if x > 10:\n",
    "    print(\"Greater than 10\")\n",
    "else:\n",
    "    print(\"Less than or equal to 10\")\"\"\", \"If Statement\")\n",
    "\n",
    "    # Test 4: Various literals and operators\n",
    "    test_lexer(\"\"\"# Testing literals\n",
    "x = 42\n",
    "y = 3.14\n",
    "name = \"John\"\n",
    "flag = True\n",
    "result = x + y * 2\n",
    "equal = x == y\"\"\", \"Literals and Operators\")\n",
    "\n",
    "    # Test 5: Loops\n",
    "    test_lexer(\"\"\"# Testing loops\n",
    "for i in range(10):\n",
    "    if i % 2 == 0:\n",
    "        print(\"Even\")\n",
    "    else:\n",
    "        print(\"Odd\")\n",
    "\n",
    "# While loop\n",
    "count = 0\n",
    "while count < 5:\n",
    "    count += 1\n",
    "\"\"\", \"Loops\")\n",
    "\n",
    "    # Test 6: Test error handling\n",
    "    test_lexer(\"x = 10 @\", \"Error Handling\")\n",
    "\n",
    "    # Test 7: Test inconsistent indentation\n",
    "    test_lexer(\"\"\"def test():\n",
    "    x = 1\n",
    "   y = 2  # Inconsistent indentation\n",
    "\"\"\", \"Inconsistent Indentation\")\n",
    "\n",
    "    # Interactive testing option\n",
    "    do_interactive = input(\"\\nDo you want to run an interactive test? (y/n): \")\n",
    "    if do_interactive.lower() == 'y':\n",
    "        print(\"\\n=== Interactive Lexer Test ===\")\n",
    "        print(\"Enter Python code (type 'exit()' on a new line to finish):\")\n",
    "        \n",
    "        lines = []\n",
    "        while True:\n",
    "            line = input(\"> \")\n",
    "            if line.strip() == \"exit()\":\n",
    "                break\n",
    "            lines.append(line)\n",
    "        \n",
    "        source_code = \"\\n\".join(lines)\n",
    "        test_lexer(source_code, \"Interactive Input\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452263c9",
   "metadata": {},
   "source": [
    "## ***ABSTRACT SYNTAX TREE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e402a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file is of abstract syntax tree (AST) node definitions.\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "# Base class for all AST nodes ASTNode is the base (parent) class for all other AST node types.\n",
    "#It doesn’t do anything itself, but helps us group all node types together under one type.\n",
    "\n",
    "class ASTNode:\n",
    "    pass\n",
    "\n",
    "# Root node; body is a list of things in the program like function definitions, statements, etc.\n",
    "@dataclass\n",
    "class Program(ASTNode):\n",
    "    body: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "# Statements\n",
    "@dataclass\n",
    "class FunctionDef(ASTNode):\n",
    "    name: str\n",
    "    params: List[str]\n",
    "    body: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class IfStatement(ASTNode):\n",
    "    condition: ASTNode\n",
    "    then_branch: List[ASTNode]\n",
    "    elif_branches: List[tuple[ASTNode, List[ASTNode]]]\n",
    "    else_branch: Optional[List[ASTNode]]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class WhileLoop(ASTNode):\n",
    "    condition: ASTNode\n",
    "    body: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class ForLoop(ASTNode):\n",
    "    var: str\n",
    "    iterable: ASTNode\n",
    "    body: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Return(ASTNode):\n",
    "    value: Optional[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Assignment(ASTNode):\n",
    "    target: str\n",
    "    value: ASTNode\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class ExpressionStatement(ASTNode):\n",
    "    expression: ASTNode\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "# Expressions\n",
    "@dataclass\n",
    "class BinaryOp(ASTNode):\n",
    "    left: ASTNode\n",
    "    operator: str\n",
    "    right: ASTNode\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class UnaryOp(ASTNode):\n",
    "    operator: str\n",
    "    operand: ASTNode\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Call(ASTNode):\n",
    "    func: ASTNode\n",
    "    args: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Identifier(ASTNode):\n",
    "    name: str\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Literal(ASTNode):\n",
    "    value: Union[str, int, float, bool, None]\n",
    "    line: int\n",
    "    column: int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13823b3",
   "metadata": {},
   "source": [
    "## ***AST VISUALIZER***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e2c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from typing import Union, List\n",
    "\n",
    "def print_ast(node: ASTNode, indent: str = ''):\n",
    "    \"\"\"Print the AST in a tree-like structure in the console.\"\"\"\n",
    "    if isinstance(node, Program):\n",
    "        print(indent + \"Program\")\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"  \")\n",
    "    elif isinstance(node, FunctionDef):\n",
    "        print(indent + f\"FunctionDef({node.name})\")\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"  \")\n",
    "    elif isinstance(node, IfStatement):\n",
    "        print(indent + \"IfStatement\")\n",
    "        print(indent + \"  Condition:\")\n",
    "        print_ast(node.condition, indent + \"    \")\n",
    "        print(indent + \"  Then:\")\n",
    "        for stmt in node.then_branch:\n",
    "            print_ast(stmt, indent + \"    \")\n",
    "        for cond, branch in node.elif_branches:\n",
    "            print(indent + \"  Elif:\")\n",
    "            print_ast(cond, indent + \"    \")\n",
    "            for stmt in branch:\n",
    "                print_ast(stmt, indent + \"      \")\n",
    "        if node.else_branch:\n",
    "            print(indent + \"  Else:\")\n",
    "            for stmt in node.else_branch:\n",
    "                print_ast(stmt, indent + \"    \")\n",
    "    elif isinstance(node, WhileLoop):\n",
    "        print(indent + \"WhileLoop\")\n",
    "        print(indent + \"  Condition:\")\n",
    "        print_ast(node.condition, indent + \"    \")\n",
    "        print(indent + \"  Body:\")\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"    \")\n",
    "    elif isinstance(node, ForLoop):\n",
    "        print(indent + f\"ForLoop(var={node.var})\")\n",
    "        print(indent + \"  Iterable:\")\n",
    "        print_ast(node.iterable, indent + \"    \")\n",
    "        print(indent + \"  Body:\")\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"    \")\n",
    "    elif isinstance(node, Return):\n",
    "        print(indent + \"Return\")\n",
    "        if node.value:\n",
    "            print_ast(node.value, indent + \"  \")\n",
    "    elif isinstance(node, Assignment):\n",
    "        print(indent + f\"Assignment(target={node.target})\")\n",
    "        print_ast(node.value, indent + \"  \")\n",
    "    elif isinstance(node, ExpressionStatement):\n",
    "        print(indent + \"ExpressionStatement\")\n",
    "        print_ast(node.expression, indent + \"  \")\n",
    "    elif isinstance(node, BinaryOp):\n",
    "        print(indent + f\"BinaryOp({node.operator})\")\n",
    "        print_ast(node.left, indent + \"  \")\n",
    "        print_ast(node.right, indent + \"  \")\n",
    "    elif isinstance(node, UnaryOp):\n",
    "        print(indent + f\"UnaryOp({node.operator})\")\n",
    "        print_ast(node.operand, indent + \"  \")\n",
    "    elif isinstance(node, Call):\n",
    "        print(indent + \"Call\")\n",
    "        print_ast(node.func, indent + \"  \")\n",
    "        for arg in node.args:\n",
    "            print_ast(arg, indent + \"    \")\n",
    "    elif isinstance(node, Identifier):\n",
    "        print(indent + f\"Identifier({node.name})\")\n",
    "    elif isinstance(node, Literal):\n",
    "        print(indent + f\"Literal({repr(node.value)})\")\n",
    "    else:\n",
    "        print(indent + f\"UnknownNode({node})\")\n",
    "\n",
    "# Optional: Graphviz visualizer\n",
    "def visualize_ast(node: ASTNode) -> Digraph:\n",
    "    dot = Digraph()\n",
    "    _build_graph(node, dot)\n",
    "    return dot\n",
    "\n",
    "def _build_graph(node: ASTNode, dot: Digraph, parent: str = None, counter=[0]):\n",
    "    node_id = f\"node{counter[0]}\"\n",
    "    counter[0] += 1\n",
    "\n",
    "    label = type(node).__name__\n",
    "    if isinstance(node, Identifier):\n",
    "        label += f\"({node.name})\"\n",
    "    elif isinstance(node, Literal):\n",
    "        label += f\"({repr(node.value)})\"\n",
    "    elif isinstance(node, Assignment):\n",
    "        label += f\"({node.target})\"\n",
    "    elif isinstance(node, BinaryOp):\n",
    "        label += f\"({node.operator})\"\n",
    "    elif isinstance(node, UnaryOp):\n",
    "        label += f\"({node.operator})\"\n",
    "    elif isinstance(node, FunctionDef):\n",
    "        label += f\"({node.name})\"\n",
    "    elif isinstance(node, ForLoop):\n",
    "        label += f\"({node.var})\"\n",
    "\n",
    "    dot.node(node_id, label)\n",
    "\n",
    "    if parent:\n",
    "        dot.edge(parent, node_id)\n",
    "\n",
    "    for field in getattr(node, '__dataclass_fields__', {}):\n",
    "        child = getattr(node, field)\n",
    "        if isinstance(child, ASTNode):\n",
    "            _build_graph(child, dot, node_id, counter)\n",
    "        elif isinstance(child, list):\n",
    "            for item in child:\n",
    "                if isinstance(item, ASTNode):\n",
    "                    _build_graph(item, dot, node_id, counter)\n",
    "        elif isinstance(child, tuple):\n",
    "            for item in child:\n",
    "                if isinstance(item, ASTNode):\n",
    "                    _build_graph(item, dot, node_id, counter)\n",
    "\n",
    "    return dot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104272b6",
   "metadata": {},
   "source": [
    "## ***PARSER***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0823d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom error class for parser errors\n",
    "class ParserError(Exception):\n",
    "    pass\n",
    "\n",
    "# Parser class converts tokens into an AST\n",
    "class Parser:\n",
    "    def __init__(self, lexer: Lexer):\n",
    "        self.tokens = list(lexer.tokenize())  # Convert lexer generator into list of tokens\n",
    "        self.pos = 0  # Current position in token list\n",
    "        self.current_token = self.tokens[self.pos]  # Currently looked-at token\n",
    "\n",
    "    def error(self, msg: str):\n",
    "        # Raise a ParserError with current token's position\n",
    "        raise ParserError(f\"{msg} at line {self.current_token.line}, column {self.current_token.column}\")\n",
    "    \n",
    "    def skip_newlines(self):\n",
    "        # Ignore NEWLINE tokens before/after blocks or statements\n",
    "        while self.current_token.type == 'NEWLINE':\n",
    "            self.advance()\n",
    "\n",
    "    def advance(self):\n",
    "        # Move to the next token\n",
    "        self.pos += 1\n",
    "        if self.pos < len(self.tokens):\n",
    "            self.current_token = self.tokens[self.pos]\n",
    "\n",
    "    def expect(self, token_type: str):\n",
    "        # Ensure the current token is of the expected type, or throw error\n",
    "        if self.current_token.type == token_type:\n",
    "            self.advance()\n",
    "        else:\n",
    "            self.error(f\"Expected token {token_type}, got {self.current_token.type}\")\n",
    "\n",
    "    def match(self, token_type: str):\n",
    "        # Match a token and advance if matched\n",
    "        if self.current_token.type == token_type:\n",
    "            self.advance()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def parse(self) -> Program:\n",
    "        # Parse a full program (list of statements)\n",
    "        body = []\n",
    "        self.skip_newlines()\n",
    "        while self.current_token.type != 'EOF':\n",
    "            stmt = self.parse_statement()\n",
    "            if stmt:\n",
    "                body.append(stmt)\n",
    "            self.skip_newlines()\n",
    "        return Program(body=body, line=0, column=0) \n",
    "\n",
    "    def parse_statement(self) -> ASTNode:\n",
    "        # Decide which type of statement to parse\n",
    "        if self.current_token.type == 'KEYWORD':\n",
    "            if self.current_token.value == 'def':\n",
    "                return self.parse_function_def()\n",
    "            elif self.current_token.value == 'return':\n",
    "                return self.parse_return()\n",
    "            elif self.current_token.value == 'if':\n",
    "                return self.parse_if()\n",
    "            elif self.current_token.value == 'while':\n",
    "                return self.parse_while()\n",
    "            elif self.current_token.value == 'for':\n",
    "                return self.parse_for()\n",
    "            \n",
    "        #######COULDNT WORK DURING SEMANTIC ANALYSIS SO CHNAGED THE LOGIC HERE##########\n",
    "        # If not a keyword, it's either an assignment or expression\n",
    "        # expr = self.parse_expression()\n",
    "        # if isinstance(expr, Identifier) and self.match('OP_ASSIGN'):\n",
    "        #     value = self.parse_expression()\n",
    "        #     return Assignment(target=expr.name, value=value)\n",
    "        # return ExpressionStatement(expr)\n",
    "        ################################################################################\n",
    "        \n",
    "        # If not a keyword, it could be assignment or expression\n",
    "        if self.current_token.type == 'IDENTIFIER':\n",
    "            # Lookahead to check for assignment\n",
    "            next_token = self.tokens[self.pos + 1] if self.pos + 1 < len(self.tokens) else None\n",
    "            if next_token and next_token.type == 'OP_ASSIGN':\n",
    "                assign_token = self.current_token\n",
    "                identifier = self.current_token.value\n",
    "                self.advance()  # consume identifier\n",
    "                self.advance()  # consume '='\n",
    "                value = self.parse_expression()\n",
    "                return Assignment(target=identifier, value=value, line=assign_token.line, column=assign_token.column)\n",
    "\n",
    "        # Otherwise, treat it as an expression statement\n",
    "        expr_token = self.current_token\n",
    "        expr = self.parse_expression()\n",
    "        return ExpressionStatement(expression=expr, line=expr_token.line, column=expr_token.column)\n",
    "\n",
    "\n",
    "    def parse_function_def(self) -> FunctionDef:\n",
    "        # Parse function definition: def name(params):\\n  <body>\n",
    "        def_token = self.current_token\n",
    "        self.expect('KEYWORD')  # 'def'\n",
    "        if self.current_token.type != 'IDENTIFIER':\n",
    "            self.error(\"Expected function name\")\n",
    "        name = self.current_token.value\n",
    "        self.advance()\n",
    "        self.expect('LPAREN')\n",
    "\n",
    "        # Parse parameter list\n",
    "        params = []\n",
    "        if self.current_token.type != 'RPAREN':\n",
    "            while True:\n",
    "                if self.current_token.type != 'IDENTIFIER':\n",
    "                    self.error(\"Expected parameter name\")\n",
    "                params.append(self.current_token.value)\n",
    "                self.advance()\n",
    "                if not self.match('COMMA'):\n",
    "                    break\n",
    "\n",
    "        self.expect('RPAREN')\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        body = self.parse_block()\n",
    "        return FunctionDef(name=name, params=params, body=body, line=def_token.line, column=def_token.column)\n",
    "\n",
    "    def parse_return(self) -> Return:\n",
    "        token = self.current_token\n",
    "        # Parse return statement\n",
    "        self.expect('KEYWORD')  # 'return'\n",
    "        if self.current_token.type == 'NEWLINE':\n",
    "            return Return(value=None, line=token.line, column=token.column)\n",
    "        value = self.parse_expression()\n",
    "        return Return(value=value, line=token.line, column=token.column)\n",
    "\n",
    "    def parse_if(self) -> IfStatement:\n",
    "        if_token = self.current_token\n",
    "        # Parse if-elif-else statement\n",
    "        self.expect('KEYWORD')  # 'if'\n",
    "        condition = self.parse_expression()\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        then_branch = self.parse_block()\n",
    "\n",
    "        elif_branches = []\n",
    "        # Handle optional elif blocks\n",
    "        while self.current_token.type == 'KEYWORD' and self.current_token.value == 'elif':\n",
    "            self.advance()\n",
    "            cond = self.parse_expression()\n",
    "            self.expect('COLON')\n",
    "            self.expect('NEWLINE')\n",
    "            self.expect('INDENT')\n",
    "            body = self.parse_block()\n",
    "            elif_branches.append((cond, body))\n",
    "\n",
    "        else_branch = None\n",
    "        # Handle optional else block\n",
    "        if self.current_token.type == 'KEYWORD' and self.current_token.value == 'else':\n",
    "            self.advance()\n",
    "            self.expect('COLON')\n",
    "            self.expect('NEWLINE')\n",
    "            self.expect('INDENT')\n",
    "            else_branch = self.parse_block()\n",
    "\n",
    "        return IfStatement(condition, then_branch, elif_branches, else_branch, line=if_token.line, column=if_token.column)\n",
    "\n",
    "    def parse_while(self) -> WhileLoop:\n",
    "        while_token = self.current_token\n",
    "        # Parse while loop\n",
    "        self.expect('KEYWORD')  # 'while'\n",
    "        condition = self.parse_expression()\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        body = self.parse_block()\n",
    "        return WhileLoop(condition=condition, body=body, line=while_token.line, column=while_token.column)\n",
    "\n",
    "    def parse_for(self) -> ForLoop:\n",
    "        for_token = self.current_token\n",
    "        # Parse for loop: for x in iterable:\n",
    "        self.expect('KEYWORD')  # 'for'\n",
    "        if self.current_token.type != 'IDENTIFIER':\n",
    "            self.error(\"Expected variable name\")\n",
    "        var = self.current_token.value\n",
    "        self.advance()\n",
    "        self.expect('KEYWORD')  # 'in'\n",
    "        iterable = self.parse_expression()\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        body = self.parse_block()\n",
    "        return ForLoop(var=var, iterable=iterable, body=body, line=for_token.line, column=for_token.column)\n",
    "\n",
    "    def parse_block(self) -> List[ASTNode]:\n",
    "        # Parse an indented block of statements\n",
    "        body = []\n",
    "        self.skip_newlines()\n",
    "        while self.current_token.type not in ('DEDENT', 'EOF'):\n",
    "            stmt = self.parse_statement()\n",
    "            if stmt:\n",
    "                body.append(stmt)\n",
    "            self.skip_newlines()\n",
    "        self.expect('DEDENT')\n",
    "        return body\n",
    "\n",
    "    def parse_expression(self, precedence=0) -> ASTNode:\n",
    "        # Parse binary expressions with precedence (e.g., 1 + 2 * 3)\n",
    "        left = self.parse_primary()\n",
    "        while self.is_operator(self.current_token) and self.get_precedence(self.current_token) >= precedence:\n",
    "            op_token = self.current_token\n",
    "            self.advance()\n",
    "            right = self.parse_expression(self.get_precedence(op_token) + 1)\n",
    "            left = BinaryOp(left=left, operator=op_token.value, right=right, line=op_token.line, column=op_token.column)\n",
    "        return left\n",
    "\n",
    "    def parse_primary(self) -> ASTNode:\n",
    "        # Parse literals, variables, function calls, unary ops, and parenthesis\n",
    "        token = self.current_token\n",
    "        if token.type == 'INTEGER':\n",
    "            self.advance()\n",
    "            return Literal(value=int(token.value), line=token.line, column=token.column)\n",
    "        elif token.type == 'FLOAT':\n",
    "            self.advance()\n",
    "            return Literal(value=float(token.value), line=token.line, column=token.column)\n",
    "        elif token.type == 'STRING':\n",
    "            self.advance()\n",
    "            return Literal(value=token.value[1:-1], line=token.line, column=token.column)\n",
    "        elif token.type == 'KEYWORD':\n",
    "            if token.value in ('True', 'False', 'None'):\n",
    "                self.advance()\n",
    "                val = {'True': True, 'False': False, 'None': None}[token.value]\n",
    "                return Literal(value=val, line=token.line, column=token.column)\n",
    "        elif token.type == 'IDENTIFIER':\n",
    "            self.advance()\n",
    "            if self.match('LPAREN'):  # Function call\n",
    "                args = []\n",
    "                if self.current_token.type != 'RPAREN':\n",
    "                    while True:\n",
    "                        args.append(self.parse_expression())\n",
    "                        if not self.match('COMMA'):\n",
    "                            break\n",
    "                self.expect('RPAREN')\n",
    "                return Call(func=Identifier(name=token.value, line=token.line, column=token.column), args=args, line=token.line, column=token.column)\n",
    "            return Identifier(name=token.value, line=token.line, column=token.column)\n",
    "        elif token.type == 'OP_MINUS':\n",
    "            self.advance()\n",
    "            operand = self.parse_primary()\n",
    "            return UnaryOp(operator='-', operand=operand)\n",
    "        elif token.type == 'LPAREN':\n",
    "            self.advance()\n",
    "            expr = self.parse_expression()\n",
    "            self.expect('RPAREN')\n",
    "            return expr\n",
    "        else:\n",
    "            self.error(f\"Unexpected token {token}\")\n",
    "\n",
    "    def is_operator(self, token: Token) -> bool:\n",
    "        # Check if token is an operator\n",
    "        return token.type.startswith('OP_')\n",
    "\n",
    "    def get_precedence(self, token: Token) -> int:\n",
    "        # Define operator precedence levels (higher = tighter binding)\n",
    "        precedence = {\n",
    "            'OP_OR': 1,\n",
    "            'OP_AND': 2,\n",
    "            'OP_EQ': 3, 'OP_NE': 3,\n",
    "            'OP_LT': 4, 'OP_LE': 4, 'OP_GT': 4, 'OP_GE': 4,\n",
    "            'OP_PLUS': 5, 'OP_MINUS': 5,\n",
    "            'OP_MULT': 6, 'OP_MOD': 6,\n",
    "            'OP_ASSIGN': 0,  # Assignment is handled separately\n",
    "        }\n",
    "        return precedence.get(token.type, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb48a8bc",
   "metadata": {},
   "source": [
    "## Testing upto parser and AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7c4e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program\n",
      "  FunctionDef(factorial)\n",
      "    IfStatement\n",
      "      Condition:\n",
      "        BinaryOp(==)\n",
      "          Identifier(n)\n",
      "          Literal(0)\n",
      "      Then:\n",
      "        Return\n",
      "          Literal(1)\n",
      "      Else:\n",
      "        Return\n",
      "          BinaryOp(*)\n",
      "            Identifier(n)\n",
      "            Call\n",
      "              Identifier(factorial)\n",
      "                BinaryOp(-)\n",
      "                  Identifier(n)\n",
      "                  Literal(1)\n",
      "  FunctionDef(is_even)\n",
      "    Return\n",
      "      BinaryOp(==)\n",
      "        BinaryOp(%)\n",
      "          Identifier(num)\n",
      "          Literal(2)\n",
      "        Literal(0)\n",
      "  Assignment(target=x)\n",
      "    Literal(5)\n",
      "  Assignment(target=fact)\n",
      "    Call\n",
      "      Identifier(factorial)\n",
      "        Identifier(x)\n",
      "  IfStatement\n",
      "    Condition:\n",
      "      Call\n",
      "        Identifier(is_even)\n",
      "          Identifier(fact)\n",
      "    Then:\n",
      "      ExpressionStatement\n",
      "        Call\n",
      "          Identifier(print)\n",
      "            Literal('Even factorial')\n",
      "    Else:\n",
      "      ExpressionStatement\n",
      "        Call\n",
      "          Identifier(print)\n",
      "            Literal('Odd factorial')\n",
      "  ForLoop(var=i)\n",
      "    Iterable:\n",
      "      Call\n",
      "        Identifier(range)\n",
      "          Literal(3)\n",
      "    Body:\n",
      "      Assignment(target=result)\n",
      "        Call\n",
      "          Identifier(factorial)\n",
      "            Identifier(i)\n",
      "      ExpressionStatement\n",
      "        Call\n",
      "          Identifier(print)\n",
      "            Identifier(result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ast_tree.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# code = '''\n",
    "# def add(x, y):\n",
    "#     return x + y\n",
    "\n",
    "# a = add(3, 5)\n",
    "# '''\n",
    "\n",
    "# code = \"\"\"\n",
    "# def foo(x):\n",
    "#     if x > 0:\n",
    "#         return x\n",
    "#     else:\n",
    "#         return -x\n",
    "# \"\"\"\n",
    "\n",
    "code = '''\n",
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n - 1)\n",
    "\n",
    "def is_even(num):\n",
    "    return num % 2 == 0\n",
    "\n",
    "x = 5\n",
    "fact = factorial(x)\n",
    "\n",
    "if is_even(fact):\n",
    "    print(\"Even factorial\")\n",
    "else:\n",
    "    print(\"Odd factorial\")\n",
    "\n",
    "for i in range(3):\n",
    "    result = factorial(i)\n",
    "    print(result)\n",
    "'''\n",
    "\n",
    "\n",
    "lexer = Lexer(code)\n",
    "parser = Parser(lexer)\n",
    "ast = parser.parse()\n",
    "\n",
    "#Console view\n",
    "print_ast(ast)\n",
    "\n",
    "\n",
    "#graph\n",
    "dot = visualize_ast(ast)\n",
    "dot.render('ast_tree', view=True, format='png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3c0576",
   "metadata": {},
   "source": [
    "## ***SEMANTIC ANALYSIS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e45e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEN = \"\\033[92m\"\n",
    "RED = \"\\033[91m\"\n",
    "\n",
    "# Custom exception class used to indicate semantic errors in the code being analyzed\n",
    "class SemanticError(Exception):\n",
    "    pass\n",
    "\n",
    "# Set of built-in function names that user-defined functions/variables should not override\n",
    "BUILTINS = {'print', 'len', 'range', 'input', 'int', 'float', 'str', 'bool'}  # Extend as needed\n",
    "\n",
    "# Scope class manages variables/functions within a block or function, supports nested scoping\n",
    "class Scope:\n",
    "    def __init__(self, parent=None):\n",
    "        self.parent = parent             # Reference to the parent scope (for nested scopes)\n",
    "        self.variables = set()           # Set of declared variable names in current scope\n",
    "        self.functions = {}              # Dictionary of declared functions: {func_name: param_list}\n",
    "        self.in_function = False         # Flag to check if this scope is inside a function\n",
    "\n",
    "    # Declare a variable in the current scope; return False if it already exists\n",
    "    def declare_var(self, name):\n",
    "        if name in self.variables:\n",
    "            return False  # Duplicate in same scope\n",
    "        self.variables.add(name)\n",
    "        return True\n",
    "\n",
    "    # Check whether a variable is declared in current or any parent scope\n",
    "    def is_var_declared(self, name):\n",
    "        if name in self.variables:\n",
    "            return True\n",
    "        if self.parent:\n",
    "            return self.parent.is_var_declared(name)\n",
    "        return False\n",
    "\n",
    "    # Declare a function with a list of parameters; returns False if already declared\n",
    "    def declare_func(self, name, params):\n",
    "        if name in self.functions:\n",
    "            return False\n",
    "        self.functions[name] = params\n",
    "        return True\n",
    "\n",
    "    # Recursively retrieve the parameter list of a declared function\n",
    "    def get_func(self, name):\n",
    "        if name in self.functions:\n",
    "            return self.functions[name]\n",
    "        if self.parent:\n",
    "            return self.parent.get_func(name)\n",
    "        return None\n",
    "\n",
    "    # Check if a function is declared by trying to get it\n",
    "    def is_func_declared(self, name):\n",
    "        return self.get_func(name) is not None\n",
    "\n",
    "# SemanticAnalyzer walks through the AST to validate semantics and detect errors\n",
    "class SemanticAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.global_scope = Scope()        # Top-level scope for global variables/functions\n",
    "        self.current_scope = self.global_scope  # Pointer to current active scope\n",
    "        self.errors = []                   # List to store error messages\n",
    "\n",
    "    # Report a semantic error with line, column, and node context\n",
    "    def error(self, msg, node):\n",
    "        line = getattr(node, 'line', '?')\n",
    "        col = getattr(node, 'column', '?')\n",
    "        node_name = getattr(node, 'name', type(node).__name__)\n",
    "        formatted = f\"[Line {line}, Column {col}] Error at '{node_name}': {msg}\"\n",
    "        self.errors.append(formatted)\n",
    "\n",
    "    # Entry point to start analyzing the AST\n",
    "    def analyze(self, node):\n",
    "        self.visit(node)  # Start visiting from the root node\n",
    "        if self.errors:\n",
    "            full_msg = \"Semantic analysis failed with the following errors:\\n  \" + \"\\n  \".join(self.errors)\n",
    "            raise SemanticError(full_msg)\n",
    "\n",
    "    # Dispatch method that calls the appropriate visit_* method based on node type\n",
    "    def visit(self, node):\n",
    "        method = 'visit_' + type(node).__name__\n",
    "        visitor = getattr(self, method, self.generic_visit)\n",
    "        return visitor(node)\n",
    "\n",
    "    # Generic visitor for composite nodes (e.g., containing other nodes in fields/lists/tuples)\n",
    "    def generic_visit(self, node):\n",
    "        for field in getattr(node, '__dataclass_fields__', {}):\n",
    "            value = getattr(node, field)\n",
    "            if isinstance(value, ASTNode):\n",
    "                self.visit(value)\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, ASTNode):\n",
    "                        self.visit(item)\n",
    "            elif isinstance(value, tuple):\n",
    "                for item in value:\n",
    "                    if isinstance(item, ASTNode):\n",
    "                        self.visit(item)\n",
    "\n",
    "    # Visit a program node which consists of multiple statements\n",
    "    def visit_Program(self, node: Program):\n",
    "        for stmt in node.body:\n",
    "            self.visit(stmt)\n",
    "\n",
    "    # Visit a function definition and validate function name, parameters, and body\n",
    "    def visit_FunctionDef(self, node: FunctionDef):\n",
    "        if node.name in BUILTINS:\n",
    "            self.error(f\"Cannot redefine built-in function '{node.name}'\", node)\n",
    "        if not self.current_scope.declare_func(node.name, node.params):\n",
    "            self.error(f\"Duplicate function definition '{node.name}'\", node)\n",
    "\n",
    "        # Create a new scope for function body\n",
    "        func_scope = Scope(parent=self.current_scope)\n",
    "        func_scope.in_function = True\n",
    "\n",
    "        # Declare parameters as variables in function scope\n",
    "        for param in node.params:\n",
    "            if not func_scope.declare_var(param):\n",
    "                self.error(f\"Duplicate parameter name '{param}' in function '{node.name}'\", node)\n",
    "\n",
    "        # Traverse function body in the new scope\n",
    "        prev_scope = self.current_scope\n",
    "        self.current_scope = func_scope\n",
    "        for stmt in node.body:\n",
    "            self.visit(stmt)\n",
    "        self.current_scope = prev_scope\n",
    "\n",
    "    # Visit an assignment: validate left-hand name, check for name conflicts, and analyze RHS\n",
    "    def visit_Assignment(self, node: Assignment):\n",
    "        if node.target in BUILTINS:\n",
    "            self.error(f\"Cannot assign to built-in name '{node.target}'\", node)\n",
    "        if self.current_scope.is_func_declared(node.target):\n",
    "            self.error(f\"Cannot assign to function name '{node.target}'\", node)\n",
    "        self.current_scope.declare_var(node.target)\n",
    "        self.visit(node.value)\n",
    "\n",
    "    # Visit an identifier node to check if it was declared\n",
    "    def visit_Identifier(self, node: Identifier):\n",
    "        if not self.current_scope.is_var_declared(node.name):\n",
    "            if self.current_scope.is_func_declared(node.name):\n",
    "                self.error(f\"Function '{node.name}' used as a variable\", node)\n",
    "            else:\n",
    "                self.error(f\"Undeclared variable '{node.name}'\", node)\n",
    "\n",
    "    # Visit a function call and validate function existence and argument count\n",
    "    def visit_Call(self, node: Call):\n",
    "        params = self.current_scope.get_func(node.func.name)\n",
    "        if params is None:\n",
    "            self.error(f\"Call to undefined function '{node.func.name}'\", node)\n",
    "        else:\n",
    "            if len(node.args) != len(params):\n",
    "                self.error(f\"Function '{node.func.name}' expects {len(params)} arguments, got {len(node.args)}\", node)\n",
    "        for arg in node.args:\n",
    "            self.visit(arg)\n",
    "\n",
    "    # Visit a return statement and ensure it's inside a function\n",
    "    def visit_Return(self, node: Return):\n",
    "        scope = self.current_scope\n",
    "        while scope:\n",
    "            if scope.in_function:\n",
    "                break\n",
    "            scope = scope.parent\n",
    "        else:\n",
    "            self.error(\"Return statement outside function\", node)\n",
    "\n",
    "        if node.value:\n",
    "            self.visit(node.value)\n",
    "\n",
    "    # Visit if/elif/else blocks and analyze each conditional branch\n",
    "    def visit_IfStatement(self, node: IfStatement):\n",
    "        self.visit(node.condition)\n",
    "        for stmt in node.then_branch:\n",
    "            self.visit(stmt)\n",
    "        for cond, body in node.elif_branches:\n",
    "            self.visit(cond)\n",
    "            for stmt in body:\n",
    "                self.visit(stmt)\n",
    "        if node.else_branch:\n",
    "            for stmt in node.else_branch:\n",
    "                self.visit(stmt)\n",
    "\n",
    "    # Visit while loop and analyze condition and body statements\n",
    "    def visit_WhileLoop(self, node: WhileLoop):\n",
    "        self.visit(node.condition)\n",
    "        for stmt in node.body:\n",
    "            self.visit(stmt)\n",
    "\n",
    "    # Visit for loop: declare loop variable in new scope and analyze loop body\n",
    "    def visit_ForLoop(self, node: ForLoop):\n",
    "        self.visit(node.iterable)\n",
    "        loop_scope = Scope(parent=self.current_scope)\n",
    "        if not loop_scope.declare_var(node.var):\n",
    "            self.error(f\"Loop variable '{node.var}' already declared\", node)\n",
    "        prev_scope = self.current_scope\n",
    "        self.current_scope = loop_scope\n",
    "        for stmt in node.body:\n",
    "            self.visit(stmt)\n",
    "        self.current_scope = prev_scope\n",
    "\n",
    "    # Visit an expression statement (e.g., standalone function call)\n",
    "    def visit_ExpressionStatement(self, node: ExpressionStatement):\n",
    "        self.visit(node.expression)\n",
    "\n",
    "    # Visit a binary operation node and analyze both left and right operands\n",
    "    def visit_BinaryOp(self, node: BinaryOp):\n",
    "        self.visit(node.left)\n",
    "        self.visit(node.right)\n",
    "\n",
    "    # Visit a unary operation node and analyze its operand\n",
    "    def visit_UnaryOp(self, node: UnaryOp):\n",
    "        self.visit(node.operand)\n",
    "\n",
    "    # Visit a literal node (e.g., number, string); literals are always valid\n",
    "    def visit_Literal(self, node: Literal):\n",
    "        pass  # Literals like 1, \"hello\", etc., are always valid so no checks needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0439696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program\n",
      "  FunctionDef(square)\n",
      "    Return\n",
      "      BinaryOp(*)\n",
      "        Identifier(x)\n",
      "        Identifier(x)\n",
      "  FunctionDef(add)\n",
      "    Assignment(target=result)\n",
      "      BinaryOp(+)\n",
      "        Identifier(a)\n",
      "        Identifier(b)\n",
      "    Return\n",
      "      Identifier(result)\n",
      "  Assignment(target=value)\n",
      "    Literal(5)\n",
      "  Assignment(target=squared)\n",
      "    Call\n",
      "      Identifier(square)\n",
      "        Identifier(value)\n",
      "  Assignment(target=total)\n",
      "    Call\n",
      "      Identifier(add)\n",
      "        Identifier(squared)\n",
      "        Literal(10)\n",
      "  FunctionDef(test)\n",
      "    Assignment(target=message)\n",
      "      Literal('All good!')\n",
      "    Return\n",
      "      Identifier(message)\n",
      "\n",
      "\u001b[92m\n",
      "Semantic analysis passed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = \"\"\"\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "def add(a, b):\n",
    "    result = a + b\n",
    "    return result\n",
    "\n",
    "value = 5\n",
    "squared = square(value)\n",
    "total = add(squared, 10)\n",
    "\n",
    "def test():\n",
    "    message = \"All good!\"\n",
    "    return message\n",
    "\"\"\"\n",
    "parseTest= '''\n",
    "def average_grade(students):  \n",
    "    total = 0\n",
    "    for s in students:\n",
    "        total += s\n",
    "    return total / len(students)\n",
    "\n",
    "grades = [85, 90, 78]\n",
    "result = average_grade(grades)\n",
    "print(result)\n",
    "\n",
    "'''\n",
    "semanticTest='''\n",
    "def max(numbers):\n",
    "    return sum(numbers) \n",
    "\n",
    "def calculate_max_average(values, values):\n",
    "    return max(values)\n",
    "\n",
    "max = 100 \n",
    "\n",
    "def test():\n",
    "    print(value)\n",
    "\n",
    "return 5 \n",
    "\n",
    "'''\n",
    "\n",
    "lexer = Lexer(source)\n",
    "parser = Parser(lexer)\n",
    "ast = parser.parse()\n",
    "analyzer = SemanticAnalyzer()\n",
    "\n",
    "#graph\n",
    "dot = visualize_ast(ast)\n",
    "dot.render('ast_tree', view=True, format='png')\n",
    "#console\n",
    "print_ast(ast)\n",
    "\n",
    "try:\n",
    "    analyzer.analyze(ast)\n",
    "    print(f\"\\n{GREEN}\\nSemantic analysis passed!\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"{RED}Semantic analysis failed:\", e)\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed207ce",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "##### Keywords: if, else, elif, while, for, in, def, return, True, False, None\n",
    "##### Operators: +, -, *, /, %, **, =, ==, !=, <, >, <=, >=, and, or, not\n",
    "##### Delimiters: (, ), {, }, [, ], ',' , '.', ':', ';'\n",
    "##### Literals: INTEGER, FLOAT, STRING\n",
    "##### Other: IDENTIFIER, INDENT, DEDENT, NEWLINE, EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96572fc",
   "metadata": {},
   "source": [
    "## Token and Error Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2746b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Generator, List, Optional, Tuple\n",
    "\n",
    "class Token:\n",
    "    def __init__(self, type: str, value: str, line: int, column: int):\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "        self.line = line\n",
    "        self.column = column\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Token({self.type}, '{self.value}', line={self.line}, col={self.column})\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "class Error:\n",
    "    def __init__(self, message: str, line: int, column: int):\n",
    "        self.message = message\n",
    "        self.line = line\n",
    "        self.column = column\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Error: {self.message} at line {self.line}, column {self.column}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d04a7",
   "metadata": {},
   "source": [
    "## Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec43f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source code:\n",
      "\n",
      "#INSERT TEST CODE HERE\n",
      "    \n",
      "\n",
      "Tokens:\n",
      "Token(NEWLINE, '\\n', line=1, col=1)\n",
      "Token(NEWLINE, '\\n', line=2, col=23)\n",
      "Token(NEWLINE, '\\n', line=3, col=1)\n",
      "Token(EOF, '', line=3, col=1)\n",
      "\n",
      "Total tokens: 4\n"
     ]
    }
   ],
   "source": [
    "class Lexer:\n",
    "    # Defining regular expressions for token\n",
    "    TOKEN_SPECS = [\n",
    "        ('COMMENT', r'#.*'),                                  # Comments\n",
    "        ('STRING', r'\\\"([^\\\\\\\"]|\\\\.)*\\\"|\\'([^\\\\\\']|\\\\.)*\\''), # String literals\n",
    "        ('FLOAT', r'\\d+\\.\\d+'),                               # Float literals\n",
    "        ('INTEGER', r'\\d+'),                                  # Integer literals\n",
    "        ('KEYWORD', r'(if|else|elif|while|for|in|def|return|True|False|None)\\b'),  # Keywords\n",
    "        ('IDENTIFIER', r'[a-zA-Z_]\\w*'),                      # Identifiers\n",
    "        # Operators (multi-character ones first)\n",
    "        ('OP_EQ', r'=='),\n",
    "        ('OP_NE', r'!='),\n",
    "        ('OP_LE', r'<='),\n",
    "        ('OP_GE', r'>='),\n",
    "        ('OP_ASSIGN', r'='),\n",
    "        ('OP_PLUS', r'\\+'),\n",
    "        ('OP_MINUS', r'-'),\n",
    "        ('OP_MULT', r'\\*\\*|\\/\\/|\\*|\\/'),  # ** (power), // (floor div), * (mult), / (div)\n",
    "        ('OP_MOD', r'%'),\n",
    "        ('OP_LT', r'<'),\n",
    "        ('OP_GT', r'>'),\n",
    "        # Delimiters\n",
    "        ('LPAREN', r'\\('),\n",
    "        ('RPAREN', r'\\)'),\n",
    "        ('LBRACKET', r'\\['),\n",
    "        ('RBRACKET', r'\\]'),\n",
    "        ('LBRACE', r'\\{'),\n",
    "        ('RBRACE', r'\\}'),\n",
    "        ('COMMA', r','),\n",
    "        ('DOT', r'\\.'),\n",
    "        ('COLON', r':'),\n",
    "        ('SEMICOLON', r';'),\n",
    "        ('NEWLINE', r'\\n'),\n",
    "        ('WHITESPACE', r'[ \\t]+'),                            # Whitespace\n",
    "        # INDENT and DEDENT tokens are not matched by regex but generated based on whitespace\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, source_code: str):\n",
    "        self.source_code = source_code\n",
    "        self.tokens = []\n",
    "        self.errors = []\n",
    "        self.line = 1\n",
    "        self.column = 1\n",
    "        self.indent_levels = [0]  # Start with indent level 0\n",
    "    \n",
    "    def tokenize(self) -> Generator[Token, None, None]:\n",
    "        \"\"\"Tokenize the source code and yield tokens.\"\"\"\n",
    "        # Process the source code line by line to handle indentation properly\n",
    "        lines = self.source_code.split('\\n')\n",
    "        \n",
    "        for line_num, line in enumerate(lines):\n",
    "            self.line = line_num + 1\n",
    "            self.column = 1\n",
    "            \n",
    "            #calculating the amount of leading whitespace (indentation) at the beginning of the current line\n",
    "            if line.strip():  # Non-empty line      #strip() is equivalent of trim() in JS\n",
    "                indent_size = len(line) - len(line.lstrip())    #lstrip() will remove leading spaces in the line i.e. remove any indentation; and the difference in length tells you how much whitespace there was\n",
    "                indent_tokens = self._handle_indentation(indent_size)\n",
    "                for token in indent_tokens:\n",
    "                    yield token\n",
    "            else:   # Skip empty lines but still count them for line numbers\n",
    "                yield Token('NEWLINE', '\\\\n', self.line, self.column)\n",
    "                continue\n",
    "            \n",
    "            # Process the rest of the line\n",
    "            i = indent_size if 'indent_size' in locals() else 0\n",
    "            line_content = line\n",
    "            \n",
    "            while i < len(line_content):    #traversing a line character by character\n",
    "                match = None\n",
    "                \n",
    "                ## Skip spaces and tabs (already handled indentation)\n",
    "                ##if line_content[i].isspace():   #isspace() checks if the entire line is whitespace or not; here it checks whether a single character is whitespace or not since its applied on line_content[i]\n",
    "                ##    i += 1\n",
    "                ##    self.column += 1\n",
    "                ##    continue\n",
    "                \n",
    "                # Try to match each token pattern\n",
    "                for token_type, pattern in self.TOKEN_SPECS:\n",
    "                    regex = re.compile(pattern) #compiling the pattern into a regex so that we can use it to find tokens in the line\n",
    "                    match = regex.match(line_content, i)    #match() will check if the \"starting\" of the string matches the given regex or not, line_content gives the line whose starting it has to compare with the regex with i telling from which point in the line to assume as thhe starting of the line\n",
    "                    #if a match is found, 'match' will contain an object with info about the found match (like start and end, its value and so on), otherwise it'll contain \"none\"\n",
    "                    \n",
    "                    if match:\n",
    "                        value = match.group(0)  #group will give the value of the match object\n",
    "                        \n",
    "                        if token_type == 'WHITESPACE':\n",
    "                            #whitespace is not yielded becuz parser receives stream of tokens without space and doesnt care about space\n",
    "                            # Just update column and continue\n",
    "                            self.column += len(value)\n",
    "                            i += len(value)\n",
    "                            continue\n",
    "                        elif token_type == 'COMMENT':\n",
    "                            # Ignore comments\n",
    "                            i += len(value)\n",
    "                            self.column += len(value)\n",
    "                            break   # Break out of the current character processing loop after handling comments\n",
    "                        else:\n",
    "                            # For all other tokens\n",
    "                            token = Token(token_type, value, self.line, self.column)\n",
    "                            yield token\n",
    "                        \n",
    "                        i += len(value)\n",
    "                        self.column += len(value)\n",
    "                        break\n",
    "                \n",
    "                if not match:\n",
    "                    # No token matched, raise an error\n",
    "                    error_msg = f\"Invalid character: '{line_content[i]}'\"\n",
    "                    error = Error(error_msg, self.line, self.column)\n",
    "                    self.errors.append(error)\n",
    "                    print(error)  # Print the error but continue\n",
    "                    i += 1\n",
    "                    self.column += 1\n",
    "            \n",
    "            # Add NEWLINE at the end of each line except the last one\n",
    "            if line_num < len(lines) - 1 or self.source_code.endswith('\\n'):\n",
    "                yield Token('NEWLINE', '\\\\n', self.line, self.column)\n",
    "        \n",
    "        # Output any pending dedents at the end of the file\n",
    "        #end of file means all indented blocks have been dedented so pop all elements of the indent_levels stack\n",
    "        while len(self.indent_levels) > 1:\n",
    "            self.indent_levels.pop()    \n",
    "            yield Token('DEDENT', '', self.line, self.column)\n",
    "        \n",
    "        # End of file token\n",
    "        yield Token('EOF', '', self.line, self.column)\n",
    "    \n",
    "    def _handle_indentation(self, indent_size: int) -> List[Token]:\n",
    "        \"\"\"Handle Python's indentation-based block structure. Returns a list of INDENT or DEDENT tokens as needed.\"\"\"\n",
    "        tokens = []\n",
    "        previous_line_indent = self.indent_levels[-1]\n",
    "        \n",
    "        if indent_size > previous_line_indent:\n",
    "            # This is an indentation (start of a new block)\n",
    "            self.indent_levels.append(indent_size)  #when a new block is recognized through indentation its indentation level is pushed in the stack so that w ecan later check whether that block was dedented properly or not\n",
    "            tokens.append(Token('INDENT', ' ' * (indent_size - previous_line_indent), self.line, 1))\n",
    "        \n",
    "        elif indent_size < previous_line_indent:\n",
    "            # This is a dedentation (end of one or more blocks)\n",
    "            while self.indent_levels and indent_size < self.indent_levels[-1]: # ensuring that the latest code block is being dedented\n",
    "                self.indent_levels.pop()\n",
    "                tokens.append(Token('DEDENT', '', self.line, 1))\n",
    "            \n",
    "            if indent_size != self.indent_levels[-1]:\n",
    "                # Invalid indentation\n",
    "                error_msg = f\"Inconsistent indentation\"\n",
    "                error = Error(error_msg, self.line, 1)\n",
    "                self.errors.append(error)\n",
    "                print(error)  # Print the error but continue\n",
    "                \n",
    "                \n",
    "                # and what about handling indent_size == self.indent_levels[-1]\n",
    "        return tokens\n",
    "  \n",
    "def test_lexer(source_code):\n",
    "    print(f\"Source code:\\n{source_code}\")\n",
    "    print(\"\\nTokens:\")\n",
    "    \n",
    "    lexer = Lexer(source_code)\n",
    "    token_count = 0\n",
    "    \n",
    "    try:\n",
    "        for token in lexer.tokenize():\n",
    "            print(token)\n",
    "            token_count += 1\n",
    "        \n",
    "        print(f\"\\nTotal tokens: {token_count}\")\n",
    "        if lexer.errors:\n",
    "            print(f\"\\nErrors ({len(lexer.errors)}):\")\n",
    "            for error in lexer.errors:\n",
    "                print(f\"  {error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test_lexer(\"\"\"\n",
    "#INSERT TEST CODE HERE\n",
    "    \"\"\", \n",
    "    )\n",
    "    \n",
    "    # Interactive testing option\n",
    "    # do_interactive = input(\"\\nDo you want to run an interactive test? (y/n): \")\n",
    "    # if do_interactive.lower() == 'y':\n",
    "    #     print(\"\\n=== Interactive Lexer Test ===\")\n",
    "    #     print(\"Enter Python code (type 'exit()' on a new line to finish):\")\n",
    "        \n",
    "    #     lines = []\n",
    "    #     while True:\n",
    "    #         line = input(\"> \")\n",
    "    #         if line.strip() == \"exit()\":\n",
    "    #             break\n",
    "    #         lines.append(line)\n",
    "        \n",
    "    #     source_code = \"\\n\".join(lines)\n",
    "    #     test_lexer(source_code, \"Interactive Input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452263c9",
   "metadata": {},
   "source": [
    "## ***ABSTRACT SYNTAX TREE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e402a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file is of abstract syntax tree (AST) node definitions.\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "# Base class for all AST nodes ASTNode is the base (parent) class for all other AST node types.\n",
    "#It doesn’t do anything itself, but helps us group all node types together under one type.\n",
    "\n",
    "class ASTNode:\n",
    "    pass\n",
    "\n",
    "# Root node; body is a list of things in the program like function definitions, statements, etc.\n",
    "@dataclass\n",
    "class Program(ASTNode):\n",
    "    body: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "# Statements\n",
    "@dataclass\n",
    "class FunctionDef(ASTNode):\n",
    "    name: str\n",
    "    params: List[str]\n",
    "    body: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class IfStatement(ASTNode):\n",
    "    condition: ASTNode\n",
    "    then_branch: List[ASTNode]\n",
    "    elif_branches: List[tuple[ASTNode, List[ASTNode]]]\n",
    "    else_branch: Optional[List[ASTNode]]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class WhileLoop(ASTNode):\n",
    "    condition: ASTNode\n",
    "    body: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class ForLoop(ASTNode):\n",
    "    var: str\n",
    "    iterable: ASTNode\n",
    "    body: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Return(ASTNode):\n",
    "    value: Optional[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Assignment(ASTNode):\n",
    "    target: str\n",
    "    value: ASTNode\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class ExpressionStatement(ASTNode):\n",
    "    expression: ASTNode\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "# Expressions\n",
    "@dataclass\n",
    "class BinaryOp(ASTNode):\n",
    "    left: ASTNode\n",
    "    operator: str\n",
    "    right: ASTNode\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class UnaryOp(ASTNode):\n",
    "    operator: str\n",
    "    operand: ASTNode\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Call(ASTNode):\n",
    "    func: ASTNode\n",
    "    args: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Identifier(ASTNode):\n",
    "    name: str\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Literal(ASTNode):\n",
    "    value: Union[str, int, float, bool, None]\n",
    "    line: int\n",
    "    column: int\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13823b3",
   "metadata": {},
   "source": [
    "## ***AST VISUALIZER***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04e2c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ast_visualizer.py\n",
    "\n",
    "from graphviz import Digraph\n",
    "from typing import Union, List\n",
    "def print_ast(node: ASTNode, indent: str = ''):\n",
    "    info = []\n",
    "    if hasattr(node, \"inferred_type\") and node.inferred_type:\n",
    "        info.append(f\"type={node.inferred_type}\")\n",
    "    if hasattr(node, \"constant_value\") and node.constant_value is not None:\n",
    "        info.append(f\"const={node.constant_value}\")\n",
    "    info_str = f\" [{', '.join(info)}]\" if info else \"\"\n",
    "\n",
    "    if isinstance(node, Program):\n",
    "        print(indent + \"Program\" + info_str)\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"  \")\n",
    "    elif isinstance(node, FunctionDef):\n",
    "        info = []\n",
    "        if hasattr(node, \"return_type\") and node.return_type:\n",
    "            info.append(f\"return_type={node.return_type}\")\n",
    "        info_str = f\" [{', '.join(info)}]\" if info else \"\"\n",
    "        print(indent + f\"FunctionDef({node.name})\" + info_str)\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"  \")\n",
    "    elif isinstance(node, IfStatement):\n",
    "        print(indent + \"IfStatement\" + info_str)\n",
    "        print(indent + \"  Condition:\")\n",
    "        print_ast(node.condition, indent + \"    \")\n",
    "        print(indent + \"  Then:\")\n",
    "        for stmt in node.then_branch:\n",
    "            print_ast(stmt, indent + \"    \")\n",
    "        for cond, branch in node.elif_branches:\n",
    "            print(indent + \"  Elif:\")\n",
    "            print_ast(cond, indent + \"    \")\n",
    "            for stmt in branch:\n",
    "                print_ast(stmt, indent + \"      \")\n",
    "        if node.else_branch:\n",
    "            print(indent + \"  Else:\")\n",
    "            for stmt in node.else_branch:\n",
    "                print_ast(stmt, indent + \"    \")\n",
    "    elif isinstance(node, WhileLoop):\n",
    "        print(indent + \"WhileLoop\" + info_str)\n",
    "        print(indent + \"  Condition:\")\n",
    "        print_ast(node.condition, indent + \"    \")\n",
    "        print(indent + \"  Body:\")\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"    \")\n",
    "    elif isinstance(node, ForLoop):\n",
    "        print(indent + f\"ForLoop(var={node.var})\" + info_str)\n",
    "        print(indent + \"  Iterable:\")\n",
    "        print_ast(node.iterable, indent + \"    \")\n",
    "        print(indent + \"  Body:\")\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"    \")\n",
    "    elif isinstance(node, Return):\n",
    "        print(indent + \"Return\" + info_str)\n",
    "        if node.value:\n",
    "            print_ast(node.value, indent + \"  \")\n",
    "    elif isinstance(node, Assignment):\n",
    "        print(indent + f\"Assignment(target={node.target})\" + info_str)\n",
    "        print_ast(node.value, indent + \"  \")\n",
    "    elif isinstance(node, ExpressionStatement):\n",
    "        print(indent + \"ExpressionStatement\" + info_str)\n",
    "        print_ast(node.expression, indent + \"  \")\n",
    "    elif isinstance(node, BinaryOp):\n",
    "        print(indent + f\"BinaryOp({node.operator})\" + info_str)\n",
    "        print_ast(node.left, indent + \"  \")\n",
    "        print_ast(node.right, indent + \"  \")\n",
    "    elif isinstance(node, UnaryOp):\n",
    "        print(indent + f\"UnaryOp({node.operator})\" + info_str)\n",
    "        print_ast(node.operand, indent + \"  \")\n",
    "    elif isinstance(node, Call):\n",
    "        print(indent + \"Call\" + info_str)\n",
    "        print_ast(node.func, indent + \"  \")\n",
    "        for arg in node.args:\n",
    "            print_ast(arg, indent + \"    \")\n",
    "    elif isinstance(node, Identifier):\n",
    "        print(indent + f\"Identifier({node.name})\" + info_str)\n",
    "    elif isinstance(node, Literal):\n",
    "        print(indent + f\"Literal({repr(node.value)})\" + info_str)\n",
    "    else:\n",
    "        print(indent + f\"UnknownNode({node})\" + info_str)\n",
    "        \n",
    "# Optional: Graphviz visualizer\n",
    "def _build_graph(node: ASTNode, dot: Digraph, parent: str = None, counter=[0]):\n",
    "    node_id = f\"node{counter[0]}\"\n",
    "    counter[0] += 1\n",
    "\n",
    "    # Build label with annotations\n",
    "    label = type(node).__name__\n",
    "    # Add main info\n",
    "    if isinstance(node, Identifier):\n",
    "        label += f\"({node.name})\"\n",
    "    elif isinstance(node, Literal):\n",
    "        label += f\"({repr(node.value)})\"\n",
    "    elif isinstance(node, Assignment):\n",
    "        label += f\"({node.target})\"\n",
    "    elif isinstance(node, BinaryOp):\n",
    "        label += f\"({node.operator})\"\n",
    "    elif isinstance(node, UnaryOp):\n",
    "        label += f\"({node.operator})\"\n",
    "    elif isinstance(node, FunctionDef):\n",
    "        label += f\"({node.name})\"\n",
    "        if hasattr(node, \"return_type\") and node.return_type:\n",
    "            label += f\"\\\\nreturn_type={node.return_type}\"\n",
    "    elif isinstance(node, ForLoop):\n",
    "        label += f\"({node.var})\"\n",
    "\n",
    "    # Add annotation info\n",
    "    info = []\n",
    "    if hasattr(node, \"inferred_type\") and node.inferred_type:\n",
    "        info.append(f\"type={node.inferred_type}\")\n",
    "    if hasattr(node, \"constant_value\") and node.constant_value is not None:\n",
    "        info.append(f\"const={node.constant_value}\")\n",
    "    if info:\n",
    "        label += \"\\\\n\" + \", \".join(info)\n",
    "\n",
    "    dot.node(node_id, label)\n",
    "\n",
    "    if parent:\n",
    "        dot.edge(parent, node_id)\n",
    "\n",
    "    for field in getattr(node, '__dataclass_fields__', {}):\n",
    "        child = getattr(node, field)\n",
    "        if isinstance(child, ASTNode):\n",
    "            _build_graph(child, dot, node_id, counter)\n",
    "        elif isinstance(child, list):\n",
    "            for item in child:\n",
    "                if isinstance(item, ASTNode):\n",
    "                    _build_graph(item, dot, node_id, counter)\n",
    "        elif isinstance(child, tuple):\n",
    "            for item in child:\n",
    "                if isinstance(item, ASTNode):\n",
    "                    _build_graph(item, dot, node_id, counter)\n",
    "\n",
    "    return dot\n",
    "\n",
    "def visualize_ast(node: ASTNode):\n",
    "    dot = Digraph(comment=\"AST\")\n",
    "    _build_graph(node, dot)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104272b6",
   "metadata": {},
   "source": [
    "## ***PARSER***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e0823d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ast_tree.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom error class for parser errors\n",
    "class ParserError(Exception):\n",
    "    pass\n",
    "\n",
    "# Parser class converts tokens into an AST\n",
    "class Parser:\n",
    "    def __init__(self, lexer: Lexer):\n",
    "        self.tokens = list(lexer.tokenize())  # Convert lexer generator into list of tokens\n",
    "        self.pos = 0  # Current position in token list\n",
    "        self.current_token = self.tokens[self.pos]  # Currently looked-at token\n",
    "\n",
    "    def error(self, msg: str):\n",
    "        # Raise a ParserError with current token's position\n",
    "        raise ParserError(f\"{msg} at line {self.current_token.line}, column {self.current_token.column}\")\n",
    "    \n",
    "    def skip_newlines(self):\n",
    "        # Ignore NEWLINE tokens before/after blocks or statements\n",
    "        while self.current_token.type == 'NEWLINE':\n",
    "            self.advance()\n",
    "\n",
    "    def advance(self):\n",
    "        # Move to the next token\n",
    "        self.pos += 1\n",
    "        if self.pos < len(self.tokens):\n",
    "            self.current_token = self.tokens[self.pos]\n",
    "\n",
    "    def expect(self, token_type: str):\n",
    "        # Ensure the current token is of the expected type, or throw error\n",
    "        if self.current_token.type == token_type:\n",
    "            self.advance()\n",
    "        else:\n",
    "            self.error(f\"Expected token {token_type}, got {self.current_token.type}\")\n",
    "\n",
    "    def match(self, token_type: str):\n",
    "        # Match a token and advance if matched\n",
    "        if self.current_token.type == token_type:\n",
    "            self.advance()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def parse(self) -> Program:\n",
    "        # Parse a full program (list of statements)\n",
    "        body = []\n",
    "        self.skip_newlines()\n",
    "        while self.current_token.type != 'EOF':\n",
    "            stmt = self.parse_statement()\n",
    "            if stmt:\n",
    "                body.append(stmt)\n",
    "            self.skip_newlines()\n",
    "        return Program(body=body, line=0, column=0) \n",
    "\n",
    "    def parse_statement(self) -> ASTNode:\n",
    "        # Decide which type of statement to parse\n",
    "        if self.current_token.type == 'KEYWORD':\n",
    "            if self.current_token.value == 'def':\n",
    "                return self.parse_function_def()\n",
    "            elif self.current_token.value == 'return':\n",
    "                return self.parse_return()\n",
    "            elif self.current_token.value == 'if':\n",
    "                return self.parse_if()\n",
    "            elif self.current_token.value == 'while':\n",
    "                return self.parse_while()\n",
    "            elif self.current_token.value == 'for':\n",
    "                return self.parse_for()\n",
    "            else:\n",
    "                print(f\"DEBUG: Unknown keyword: {self.current_token.value}\")\n",
    "                self.error(f\"Unknown keyword: {self.current_token.value}\")\n",
    "            \n",
    "        #######COULDNT WORK DURING SEMANTIC ANALYSIS SO CHNAGED THE LOGIC HERE##########\n",
    "        # If not a keyword, it's either an assignment or expression\n",
    "        # expr = self.parse_expression()\n",
    "        # if isinstance(expr, Identifier) and self.match('OP_ASSIGN'):\n",
    "        #     value = self.parse_expression()\n",
    "        #     return Assignment(target=expr.name, value=value)\n",
    "        # return ExpressionStatement(expr)\n",
    "        ################################################################################\n",
    "        \n",
    "        # If not a keyword, it could be assignment or expression\n",
    "        if self.current_token.type == 'IDENTIFIER':\n",
    "            # Lookahead to check for assignment\n",
    "            next_token = self.tokens[self.pos + 1] if self.pos + 1 < len(self.tokens) else None\n",
    "            if next_token and next_token.type == 'OP_ASSIGN':\n",
    "                assign_token = self.current_token\n",
    "                identifier = self.current_token.value\n",
    "                self.advance()  # consume identifier\n",
    "                self.advance()  # consume '='\n",
    "                value = self.parse_expression()\n",
    "                return Assignment(target=identifier, value=value, line=assign_token.line, column=assign_token.column)\n",
    "\n",
    "        # Otherwise, treat it as an expression statement\n",
    "        expr_token = self.current_token\n",
    "        expr = self.parse_expression()\n",
    "        return ExpressionStatement(expression=expr, line=expr_token.line, column=expr_token.column)\n",
    "\n",
    "    def parse_function_def(self) -> FunctionDef:\n",
    "        # Parse function definition: def name(params):\\n  <body>\n",
    "        def_token = self.current_token\n",
    "        self.expect('KEYWORD')  # 'def'\n",
    "        if self.current_token.type != 'IDENTIFIER':\n",
    "            self.error(\"Expected function name\")\n",
    "        name = self.current_token.value\n",
    "        self.advance()\n",
    "        self.expect('LPAREN')\n",
    "\n",
    "        # Parse parameter list\n",
    "        params = []\n",
    "        if self.current_token.type != 'RPAREN':\n",
    "            while True:\n",
    "                if self.current_token.type != 'IDENTIFIER':\n",
    "                    self.error(\"Expected parameter name\")\n",
    "                params.append(self.current_token.value)\n",
    "                self.advance()\n",
    "                if not self.match('COMMA'):\n",
    "                    break\n",
    "\n",
    "        self.expect('RPAREN')\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        body = self.parse_block()\n",
    "        return FunctionDef(name=name, params=params, body=body, line=def_token.line, column=def_token.column)\n",
    "\n",
    "    def parse_return(self) -> Return:\n",
    "        token = self.current_token\n",
    "        # Parse return statement\n",
    "        self.expect('KEYWORD')  # 'return'\n",
    "        if self.current_token.type == 'NEWLINE':\n",
    "            return Return(value=None, line=token.line, column=token.column)\n",
    "        value = self.parse_expression()\n",
    "        return Return(value=value, line=token.line, column=token.column)\n",
    "\n",
    "    def parse_if(self) -> IfStatement:\n",
    "        if_token = self.current_token\n",
    "        # Parse if-elif-else statement\n",
    "        self.expect('KEYWORD')  # 'if'\n",
    "        condition = self.parse_expression()\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        then_branch = self.parse_block()\n",
    "\n",
    "        elif_branches = []\n",
    "        # Handle optional elif blocks\n",
    "        while self.current_token.type == 'KEYWORD' and self.current_token.value == 'elif':\n",
    "            self.advance()\n",
    "            cond = self.parse_expression()\n",
    "            self.expect('COLON')\n",
    "            self.expect('NEWLINE')\n",
    "            self.expect('INDENT')\n",
    "            body = self.parse_block()\n",
    "            elif_branches.append((cond, body))\n",
    "\n",
    "        else_branch = None\n",
    "        # Handle optional else block\n",
    "        if self.current_token.type == 'KEYWORD' and self.current_token.value == 'else':\n",
    "            self.advance()\n",
    "            self.expect('COLON')\n",
    "            self.expect('NEWLINE')\n",
    "            self.expect('INDENT')\n",
    "            else_branch = self.parse_block()\n",
    "\n",
    "        return IfStatement(condition, then_branch, elif_branches, else_branch, line=if_token.line, column=if_token.column)\n",
    "\n",
    "    def parse_while(self) -> WhileLoop:\n",
    "        while_token = self.current_token\n",
    "        # Parse while loop\n",
    "        self.expect('KEYWORD')  # 'while'\n",
    "        condition = self.parse_expression()\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        body = self.parse_block()\n",
    "        return WhileLoop(condition=condition, body=body, line=while_token.line, column=while_token.column)\n",
    "\n",
    "    def parse_for(self) -> ForLoop:\n",
    "        for_token = self.current_token\n",
    "        # Parse for loop: for x in iterable:\n",
    "        self.expect('KEYWORD')  # 'for'\n",
    "        if self.current_token.type != 'IDENTIFIER':\n",
    "            self.error(\"Expected variable name\")\n",
    "        var = self.current_token.value\n",
    "        self.advance()\n",
    "        self.expect('KEYWORD')  # 'in'\n",
    "        iterable = self.parse_expression()\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        body = self.parse_block()\n",
    "        return ForLoop(var=var, iterable=iterable, body=body, line=for_token.line, column=for_token.column)\n",
    "\n",
    "    def parse_block(self) -> List[ASTNode]:\n",
    "        # Parse an indented block of statements\n",
    "        body = []\n",
    "        self.skip_newlines()\n",
    "        while self.current_token.type not in ('DEDENT', 'EOF'):\n",
    "            stmt = self.parse_statement()\n",
    "            if stmt:\n",
    "                body.append(stmt)\n",
    "            self.skip_newlines()\n",
    "        self.expect('DEDENT')\n",
    "        return body\n",
    "\n",
    "    def parse_expression(self, precedence=0) -> ASTNode:\n",
    "        # Parse binary expressions with precedence (e.g., 1 + 2 * 3)\n",
    "        left = self.parse_primary()\n",
    "        while self.is_operator(self.current_token) and self.get_precedence(self.current_token) >= precedence:\n",
    "            op_token = self.current_token\n",
    "            self.advance()\n",
    "            right = self.parse_expression(self.get_precedence(op_token) + 1)\n",
    "            left = BinaryOp(left=left, operator=op_token.value, right=right, line=op_token.line, column=op_token.column)\n",
    "        return left\n",
    "\n",
    "    def parse_primary(self) -> ASTNode:\n",
    "        # Parse literals, variables, function calls, unary ops, and parenthesis\n",
    "        token = self.current_token\n",
    "        if token.type == 'INTEGER':\n",
    "            self.advance()\n",
    "            return Literal(value=int(token.value), line=token.line, column=token.column)\n",
    "        elif token.type == 'FLOAT':\n",
    "            self.advance()\n",
    "            return Literal(value=float(token.value), line=token.line, column=token.column)\n",
    "        elif token.type == 'STRING':\n",
    "            self.advance()\n",
    "            return Literal(value=token.value[1:-1], line=token.line, column=token.column)\n",
    "        elif token.type == 'KEYWORD':\n",
    "            if token.value in ('True', 'False', 'None'):\n",
    "                self.advance()\n",
    "                val = {'True': True, 'False': False, 'None': None}[token.value]\n",
    "                return Literal(value=val, line=token.line, column=token.column)\n",
    "        elif token.type == 'IDENTIFIER':\n",
    "            self.advance()\n",
    "            if self.match('LPAREN'):  # Function call\n",
    "                args = []\n",
    "                if self.current_token.type != 'RPAREN':\n",
    "                    while True:\n",
    "                        args.append(self.parse_expression())\n",
    "                        if not self.match('COMMA'):\n",
    "                            break\n",
    "                self.expect('RPAREN')\n",
    "                return Call(func=Identifier(name=token.value, line=token.line, column=token.column), args=args, line=token.line, column=token.column)\n",
    "            return Identifier(name=token.value, line=token.line, column=token.column)\n",
    "        elif token.type == 'OP_MINUS':\n",
    "            self.advance()\n",
    "            operand = self.parse_primary()\n",
    "            return UnaryOp(operator='-', operand=operand)\n",
    "        elif token.type == 'LPAREN':\n",
    "            self.advance()\n",
    "            expr = self.parse_expression()\n",
    "            self.expect('RPAREN')\n",
    "            return expr\n",
    "        else:\n",
    "            self.error(f\"Unexpected token {token}\")\n",
    "\n",
    "    def is_operator(self, token: Token) -> bool:\n",
    "        # Check if token is an operator\n",
    "        return token.type.startswith('OP_')\n",
    "\n",
    "    def get_precedence(self, token: Token) -> int:\n",
    "        # Define operator precedence levels (higher = tighter binding)\n",
    "        precedence = {\n",
    "            'OP_OR': 1,\n",
    "            'OP_AND': 2,\n",
    "            'OP_EQ': 3, 'OP_NE': 3,\n",
    "            'OP_LT': 4, 'OP_LE': 4, 'OP_GT': 4, 'OP_GE': 4,\n",
    "            'OP_PLUS': 5, 'OP_MINUS': 5,\n",
    "            'OP_MULT': 6, 'OP_MOD': 6,\n",
    "            'OP_ASSIGN': 0,  # Assignment is handled separately\n",
    "        }\n",
    "        return precedence.get(token.type, -1)\n",
    " \n",
    "\n",
    "testCode = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "#Test code\n",
    "lexer = Lexer(testCode)\n",
    "parser = Parser(lexer)\n",
    "ast = parser.parse()\n",
    "\n",
    "#Console view\n",
    "print_ast(ast)\n",
    "\n",
    "    #graph\n",
    "dot = visualize_ast(ast)\n",
    "dot.render('ast_tree', view=True, format='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3c0576",
   "metadata": {},
   "source": [
    "## ***SEMANTIC ANALYSIS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e45e84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### AST Before Semantic Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:green; font-weight:bold'>✅ Semantic analysis passed!</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Symbol Table"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scope:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### AST After Semantic Analysis (With Annotations)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore, Style, init\n",
    "from IPython.display import Markdown, display\n",
    "# Enable ANSI color in terminal\n",
    "init(autoreset=True)\n",
    "\n",
    "# Custom exception class used to indicate semantic errors in the code being analyzed\n",
    "class SemanticError(Exception):\n",
    "    pass\n",
    "\n",
    "# Set of built-in function names that user-defined functions/variables should not override\n",
    "BUILTINS = {'print', 'len', 'range', 'input', 'int', 'float', 'str', 'bool'}  # Extend as needed\n",
    "\n",
    "# Scope class manages variables/functions within a block or function, supports nested scoping\n",
    "class Scope:\n",
    "    def __init__(self, parent=None):\n",
    "        self.parent = parent             # Reference to the parent scope (for nested scopes)\n",
    "        self.variables = {}              # declared variable names in current scope\n",
    "        self.functions = {}              # Dictionary of declared functions: {func_name: param_list}\n",
    "        self.in_function = False         # Flag to check if this scope is inside a function\n",
    "\n",
    "    # Declare a variable in the current scope; return False if it already exists\n",
    "    def declare_var(self, name, var_type=None):\n",
    "        if name in self.variables:\n",
    "            return False  # Duplicate in same scope\n",
    "        self.variables[name] = {\"type\": var_type}\n",
    "        return True\n",
    "\n",
    "    # Check whether a variable is declared in current or any parent scope\n",
    "    def is_var_declared(self, name):\n",
    "        if name in self.variables:\n",
    "            return True\n",
    "        if self.parent:\n",
    "            return self.parent.is_var_declared(name)\n",
    "        return False\n",
    "\n",
    "    # Declare a function with a list of parameters; returns False if already declared\n",
    "    def declare_func(self, name, func_def):\n",
    "        if name in self.functions:\n",
    "            return False\n",
    "        self.functions[name] = func_def\n",
    "        return True\n",
    "\n",
    "    # Recursively retrieve the parameter list of a declared function\n",
    "    def get_func(self, name):\n",
    "        if name in self.functions:\n",
    "            return self.functions[name]\n",
    "        if self.parent:\n",
    "            return self.parent.get_func(name)\n",
    "        return None\n",
    "\n",
    "    # Check if a function is declared by trying to get it\n",
    "    def is_func_declared(self, name):\n",
    "        return self.get_func(name) is not None\n",
    "    \n",
    "    #to show symbol table \n",
    "    def print_symbols(self, indent=0):\n",
    "        prefix = \"  \" * indent\n",
    "        print(f\"{prefix}Scope:\")\n",
    "        if self.variables:\n",
    "            for name, info in self.variables.items():\n",
    "                print(f\"{prefix}  Variable: {name}, Type: {info.get('type', 'unknown')}\")\n",
    "        if self.functions:\n",
    "            for fname, func_def in self.functions.items():\n",
    "                param_strs = [f\"{p}: {t}\" for p, t in func_def.param_types.items()]\n",
    "                return_type = getattr(func_def, 'return_type', None)\n",
    "                return_type_str = f\", Return: {return_type}\" if return_type else \"\"\n",
    "                print(f\"{prefix}  Function: {fname}({', '.join(param_strs)}){return_type_str}\")\n",
    "        if self.parent:\n",
    "            self.parent.print_symbols(indent + 1)\n",
    "\n",
    "# SemanticAnalyzer walks through the AST to validate semantics and detect errors\n",
    "class SemanticAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.global_scope = Scope()        # Top-level scope for global variables/functions\n",
    "        self.current_scope = self.global_scope  # Pointer to current active scope\n",
    "        self.errors = []                   # List to store error messages\n",
    "\n",
    "\n",
    "    # Report a semantic error with line, column, and node context\n",
    "    def error(self, msg, node):\n",
    "        line = getattr(node, 'line', '?')\n",
    "        col = getattr(node, 'column', '?')\n",
    "        node_name = getattr(node, 'name', type(node).__name__)\n",
    "        self.errors.append(f\"[Line {line}, Column {col}] Error at '{node_name}': {msg}\")\n",
    "        # self.errors.append(formatted)\n",
    "\n",
    "    # Entry point to start analyzing the AST\n",
    "    def analyze(self, node):\n",
    "        self.visit(node)  # Start visiting from the root node\n",
    "        if self.errors:\n",
    "            raise SemanticError(\"\\n\".join(self.errors))\n",
    "\n",
    "    # Dispatch method that calls the appropriate visit_* method based on node type\n",
    "    def visit(self, node):\n",
    "        method = 'visit_' + type(node).__name__\n",
    "        visitor = getattr(self, method, self.generic_visit)\n",
    "        return visitor(node)\n",
    "\n",
    "    # Generic visitor for composite nodes (e.g., containing other nodes in fields/lists/tuples)\n",
    "    def generic_visit(self, node):\n",
    "        for field in getattr(node, '__dataclass_fields__', {}):\n",
    "            value = getattr(node, field)\n",
    "            if isinstance(value, ASTNode):\n",
    "                self.visit(value)\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, ASTNode):\n",
    "                        self.visit(item)\n",
    "            elif isinstance(value, tuple):\n",
    "                for item in value:\n",
    "                    if isinstance(item, ASTNode):\n",
    "                        self.visit(item)\n",
    "\n",
    "    # Visit a program node which consists of multiple statements\n",
    "    def visit_Program(self, node: Program):\n",
    "        for stmt in node.body:\n",
    "            self.visit(stmt)\n",
    "\n",
    "    # Visit a function definition and validate function name, parameters, and body\n",
    "    def visit_FunctionDef(self, node: FunctionDef):\n",
    "        if not self.current_scope.declare_func(node.name, node):\n",
    "            self.error(f\"Duplicate function definition '{node.name}'\", node)\n",
    "        func_scope = Scope(parent=self.current_scope)\n",
    "        func_scope.in_function = True\n",
    "\n",
    "        node.param_types = {}\n",
    "        for param in node.params:\n",
    "            p_name = param if isinstance(param, str) else param[0]\n",
    "            p_type = None if isinstance(param, str) else param[1]\n",
    "            func_scope.declare_var(p_name, p_type)\n",
    "            node.param_types[p_name] = p_type\n",
    "\n",
    "        prev_scope = self.current_scope\n",
    "        self.current_scope = func_scope\n",
    "\n",
    "        return_types = set()\n",
    "        for stmt in node.body:\n",
    "            self.visit(stmt)\n",
    "            if isinstance(stmt, Return) and hasattr(stmt, 'inferred_type') and stmt.inferred_type is not None:\n",
    "                return_types.add(stmt.inferred_type)\n",
    "\n",
    "        self.current_scope = prev_scope\n",
    "        node.return_type = return_types.pop() if len(return_types) == 1 else 'multiple' if return_types else 'None'\n",
    "\n",
    "    # Visit an assignment: validate left-hand name, check for name conflicts, and analyze RHS\n",
    "    def visit_Assignment(self, node: Assignment):\n",
    "        if node.target in BUILTINS:\n",
    "            self.error(f\"Cannot assign to built-in name '{node.target}'\", node)\n",
    "        if self.current_scope.is_func_declared(node.target):\n",
    "            self.error(f\"Cannot assign to function name '{node.target}'\", node)\n",
    "        self.visit(node.value)\n",
    "        var_type = getattr(node.value, 'inferred_type', None)\n",
    "        node.inferred_type = var_type\n",
    "        self.current_scope.declare_var(node.target, var_type)\n",
    "\n",
    "    # Visit an identifier node to check if it was declared\n",
    "    def visit_Identifier(self, node: Identifier):\n",
    "        scope = self.current_scope\n",
    "        while scope:\n",
    "            if node.name in scope.variables:\n",
    "                node.inferred_type = scope.variables[node.name][\"type\"]\n",
    "                return\n",
    "            scope = scope.parent\n",
    "        if self.current_scope.is_func_declared(node.name):\n",
    "            self.error(f\"Function '{node.name}' used as a variable\", node)\n",
    "        else:\n",
    "            self.error(f\"Undeclared variable '{node.name}'\", node)\n",
    "\n",
    "    # Visit a function call and validate function existence and argument count\n",
    "    def visit_Call(self, node: Call):\n",
    "        func_def = self.current_scope.get_func(node.func.name)\n",
    "        func_name = node.func.name\n",
    "        func_def = self.current_scope.get_func(func_name)\n",
    "        if func_def is None:\n",
    "            if func_name in BUILTINS:\n",
    "                node.inferred_type = 'None'  # assume built-ins return nothing for now\n",
    "                for arg in node.args:\n",
    "                    self.visit(arg)\n",
    "                return\n",
    "            else:\n",
    "                self.error(f\"Call to undefined function '{func_name}'\", node)\n",
    "                return\n",
    "        else:\n",
    "            # Infer parameter types if not set\n",
    "            param_types_changed = False\n",
    "            for (pname, exp_type), arg in zip(func_def.param_types.items(), node.args):\n",
    "                self.visit(arg)\n",
    "                actual = getattr(arg, 'inferred_type', None)\n",
    "                if exp_type is None:\n",
    "                    func_def.param_types[pname] = actual  # Infer type from first call\n",
    "                    param_types_changed = True\n",
    "                elif actual != exp_type:\n",
    "                    self.error(f\"Type mismatch in argument: expected {exp_type}, got {actual}\", arg)\n",
    "            if len(node.args) != len(func_def.param_types):\n",
    "                self.error(f\"Function '{node.func.name}' expects {len(func_def.param_types)} arguments, got {len(node.args)}\", node)\n",
    "            # Re-analyze function body if parameter types were updated\n",
    "            if param_types_changed:\n",
    "                prev_scope = self.current_scope\n",
    "                func_scope = Scope(parent=self.global_scope)\n",
    "                func_scope.in_function = True\n",
    "                for pname, ptype in func_def.param_types.items():\n",
    "                    func_scope.declare_var(pname, ptype)\n",
    "                self.current_scope = func_scope\n",
    "                return_types = set()\n",
    "                for stmt in func_def.body:\n",
    "                    self.visit(stmt)\n",
    "                    if isinstance(stmt, Return) and hasattr(stmt, 'inferred_type') and stmt.inferred_type is not None:\n",
    "                        return_types.add(stmt.inferred_type)\n",
    "                self.current_scope = prev_scope\n",
    "                func_def.return_type = return_types.pop() if len(return_types) == 1 else 'multiple' if return_types else 'None'\n",
    "        if func_def and hasattr(func_def, 'return_type'):\n",
    "            node.inferred_type = func_def.return_type\n",
    "\n",
    "\n",
    "    # Visit a return statement and ensure it's inside a function\n",
    "    def visit_Return(self, node: Return):\n",
    "        scope = self.current_scope\n",
    "        while scope:\n",
    "            if scope.in_function:\n",
    "                break\n",
    "            scope = scope.parent\n",
    "        else:\n",
    "            self.error(\"Return statement outside function\", node)\n",
    "\n",
    "        if node.value:\n",
    "            self.visit(node.value)\n",
    "            node.inferred_type = getattr(node.value, 'inferred_type', None)\n",
    "\n",
    "    # Visit if/elif/else blocks and analyze each conditional branch\n",
    "    def visit_IfStatement(self, node: IfStatement):\n",
    "        self.visit(node.condition)\n",
    "        for stmt in node.then_branch:\n",
    "            self.visit(stmt)\n",
    "        for cond, body in node.elif_branches:\n",
    "            self.visit(cond)\n",
    "            for stmt in body:\n",
    "                self.visit(stmt)\n",
    "        if node.else_branch:\n",
    "            for stmt in node.else_branch:\n",
    "                self.visit(stmt)\n",
    "\n",
    "    # Visit while loop and analyze condition and body statements\n",
    "    def visit_WhileLoop(self, node: WhileLoop):\n",
    "        self.visit(node.condition)\n",
    "        for stmt in node.body:\n",
    "            self.visit(stmt)\n",
    "\n",
    "    # Visit for loop: declare loop variable in new scope and analyze loop body\n",
    "    def visit_ForLoop(self, node: ForLoop):\n",
    "        self.visit(node.iterable)\n",
    "        loop_scope = Scope(parent=self.current_scope)\n",
    "        if not loop_scope.declare_var(node.var):\n",
    "            self.error(f\"Loop variable '{node.var}' already declared\", node)\n",
    "        prev_scope = self.current_scope\n",
    "        self.current_scope = loop_scope\n",
    "        for stmt in node.body:\n",
    "            self.visit(stmt)\n",
    "        self.current_scope = prev_scope\n",
    "\n",
    "    # Visit an expression statement (e.g., standalone function call)\n",
    "    def visit_ExpressionStatement(self, node: ExpressionStatement):\n",
    "        self.visit(node.expression)\n",
    "\n",
    "    # Visit a binary operation node and analyze both left and right operands\n",
    "    def visit_BinaryOp(self, node: BinaryOp):\n",
    "        self.visit(node.left)\n",
    "        self.visit(node.right)\n",
    "        \n",
    "        ltype = getattr(node.left, 'inferred_type', None)\n",
    "        rtype = getattr(node.right, 'inferred_type', None)\n",
    "\n",
    "        # Handle type inference for numeric operations\n",
    "        numeric_ops = {'+', '-', '*', '/', '%', '**'}\n",
    "\n",
    "        if ltype and rtype:\n",
    "            # if node.operator in numeric_ops:\n",
    "            #     if ltype in {'int', 'float'} and rtype in {'int', 'float'}:\n",
    "            #         # Type promotion rule: int + float => float\n",
    "            #         if ltype == 'float' or rtype == 'float':\n",
    "            #             node.inferred_type = 'float'\n",
    "            #         else:\n",
    "            #             node.inferred_type = 'int'\n",
    "            #     else:\n",
    "            #         self.error(f\"Unsupported operand types for {node.operator}: '{ltype}' and '{rtype}'\", node)\n",
    "            if node.operator == '+':\n",
    "                if ltype == rtype == 'str':\n",
    "                    node.inferred_type = 'str'\n",
    "                elif ltype in {'int', 'float'} and rtype in {'int', 'float'}:\n",
    "                    node.inferred_type = 'float' if 'float' in (ltype, rtype) else 'int'\n",
    "                else:\n",
    "                    self.error(f\"Unsupported operand types for +: '{ltype}' and '{rtype}'\", node)\n",
    "            elif node.operator in {'-', '*', '/', '%', '**'}:\n",
    "                if ltype in {'int', 'float'} and rtype in {'int', 'float'}:\n",
    "                    node.inferred_type = 'float' if 'float' in (ltype, rtype) else 'int'\n",
    "                else:\n",
    "                    self.error(f\"Unsupported operand types for {node.operator}: '{ltype}' and '{rtype}'\", node)\n",
    "            elif node.operator in {'==', '!=', '<', '>', '<=', '>='}:\n",
    "                node.inferred_type = 'bool'\n",
    "            elif node.operator in {'and', 'or'}:\n",
    "                if ltype == rtype == 'bool':\n",
    "                    node.inferred_type = 'bool'\n",
    "                else:\n",
    "                    self.error(f\"Logical operators require boolean operands, got '{ltype}' and '{rtype}'\", node)\n",
    "            else:\n",
    "                self.error(f\"Unknown binary operator '{node.operator}'\", node)\n",
    "\n",
    "        # Constant folding (optional)\n",
    "        if hasattr(node.left, 'constant_value') and hasattr(node.right, 'constant_value'):\n",
    "            try:\n",
    "                node.constant_value = eval(f\"{repr(node.left.constant_value)} {node.operator} {repr(node.right.constant_value)}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            \n",
    "    # Visit a unary operation node and analyze its operand\n",
    "    def visit_UnaryOp(self, node: UnaryOp):\n",
    "        self.visit(node.operand)\n",
    "        if hasattr(node.operand, 'inferred_type'):\n",
    "            node.inferred_type = node.operand.inferred_type\n",
    "        if hasattr(node.operand, 'constant_value'):\n",
    "            try:\n",
    "                node.constant_value = eval(f\"{node.operator}{node.operand.constant_value}\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Visit a literal node (e.g., number, string); literals are always valid\n",
    "    def visit_Literal(self, node: Literal):\n",
    "        node.inferred_type = type(node.value).__name__\n",
    "        node.constant_value = node.value\n",
    "        \n",
    "\n",
    "source_code = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "lexer = Lexer(source_code)\n",
    "parser = Parser(lexer)\n",
    "ast = parser.parse()\n",
    "\n",
    "display(Markdown(\"### AST Before Semantic Analysis\"))\n",
    "print_ast(ast)\n",
    "\n",
    "analyzer = SemanticAnalyzer()\n",
    "\n",
    "try:\n",
    "    analyzer.analyze(ast)\n",
    "\n",
    "    display(Markdown(f\"<span style='color:green; font-weight:bold'>✅ Semantic analysis passed!</span>\"))\n",
    "\n",
    "    display(Markdown(\"### Symbol Table\"))\n",
    "    analyzer.global_scope.print_symbols()\n",
    "        \n",
    "    display(Markdown(\"### AST After Semantic Analysis (With Annotations)\"))\n",
    "    print_ast(ast)\n",
    "\n",
    "    dot = visualize_ast(ast)\n",
    "    dot.render('ast_tree', view=True, format='png')\n",
    "\n",
    "except Exception as e:\n",
    "    display(Markdown(f\"<span style='color:red; font-weight:bold'>❌ Semantic analysis failed:</span> {e}\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27632b7",
   "metadata": {},
   "source": [
    "## Code Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "911c862a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before optimization:\n",
      "Program\n",
      "  FunctionDef(calculate) [return_type=int]\n",
      "    Assignment(target=a) [type=int]\n",
      "      BinaryOp(+) [type=int, const=11]\n",
      "        Literal(5) [type=int, const=5]\n",
      "        BinaryOp(*) [type=int, const=6]\n",
      "          Literal(3) [type=int, const=3]\n",
      "          Literal(2) [type=int, const=2]\n",
      "    Assignment(target=b) [type=int]\n",
      "      BinaryOp(/) [type=int, const=5.0]\n",
      "        Literal(10) [type=int, const=10]\n",
      "        Literal(2) [type=int, const=2]\n",
      "    Assignment(target=c) [type=int]\n",
      "      BinaryOp(-) [type=int]\n",
      "        BinaryOp(+) [type=int]\n",
      "          Identifier(a) [type=int]\n",
      "          Identifier(b) [type=int]\n",
      "        BinaryOp(*) [type=int, const=6]\n",
      "          Literal(2) [type=int, const=2]\n",
      "          Literal(3) [type=int, const=3]\n",
      "    Return [type=int]\n",
      "      Identifier(c) [type=int]\n",
      "  Assignment(target=result) [type=int]\n",
      "    Call [type=int]\n",
      "      Identifier(calculate)\n",
      "\n",
      "Applied 4 optimizations\n",
      "\n",
      "After optimization:\n",
      "Program\n",
      "  FunctionDef(calculate) [return_type=int]\n",
      "    Assignment(target=a) [type=int]\n",
      "      Literal(11) [type=int, const=11]\n",
      "    Assignment(target=b) [type=int]\n",
      "      Literal(5.0) [type=int, const=5.0]\n",
      "    Assignment(target=c) [type=int]\n",
      "      BinaryOp(-) [type=int]\n",
      "        BinaryOp(+) [type=int]\n",
      "          Identifier(a) [type=int]\n",
      "          Identifier(b) [type=int]\n",
      "        Literal(6) [type=int, const=6]\n",
      "    Return [type=int]\n",
      "      Identifier(c) [type=int]\n",
      "  Assignment(target=result) [type=int]\n",
      "    Call [type=int]\n",
      "      Identifier(calculate)\n"
     ]
    }
   ],
   "source": [
    "#Note: These optimizations are performed: Constant folding and propagation, dead code elimination, control flow optimization, expression simplification\n",
    "from typing import List, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(self):\n",
    "        self.optimizations_applied = 0\n",
    "        self.modified = True  # Track if any optimizations were made\n",
    "        self.constants = {}   # track constant values\n",
    "        self.scope_stack = [{}]  # Stack of scopes for tracking variables in different scopes\n",
    "        self.function_params = set()  # Track current function parameters\n",
    "    \n",
    "    def visit_Identifier(self, node: Identifier) -> ASTNode:\n",
    "        \"\"\"Propagate known constant values\"\"\"\n",
    "        # Don't optimize function parameters\n",
    "        if node.name in self.function_params:\n",
    "            return node\n",
    "            \n",
    "        # Look for constant value in all scopes, from innermost to outermost\n",
    "        for scope in reversed(self.scope_stack):\n",
    "            if node.name in scope:\n",
    "                self.modified = True\n",
    "                self.optimizations_applied += 1\n",
    "                # Create new literal and preserve any existing attributes\n",
    "                new_literal = Literal(value=scope[node.name], line=node.line, column=node.column)\n",
    "                # Copy any additional attributes that might exist (like type annotations)\n",
    "                for attr in dir(node):\n",
    "                    if not attr.startswith('_') and attr not in ['name', 'line', 'column']:\n",
    "                        if hasattr(node, attr) and not callable(getattr(node, attr)):\n",
    "                            try:\n",
    "                                setattr(new_literal, attr, getattr(node, attr))\n",
    "                            except:\n",
    "                                pass\n",
    "                return new_literal\n",
    "        return node\n",
    "    \n",
    "    def optimize(self, node: ASTNode) -> ASTNode:\n",
    "        \"\"\"Main optimization entry point\"\"\"\n",
    "        if node is None:\n",
    "            return None\n",
    "            \n",
    "        # Keep optimizing until no more changes can be made\n",
    "        max_iterations = 10  # Prevent infinite loops\n",
    "        iteration = 0\n",
    "        \n",
    "        while self.modified and iteration < max_iterations:\n",
    "            self.modified = False\n",
    "            old_optimizations = self.optimizations_applied\n",
    "            node = self.visit(node)\n",
    "            iteration += 1\n",
    "            \n",
    "            # If no new optimizations were applied, we're done\n",
    "            if self.optimizations_applied == old_optimizations:\n",
    "                break\n",
    "                \n",
    "        return node\n",
    "    \n",
    "    def visit(self, node: ASTNode) -> Optional[ASTNode]:\n",
    "        \"\"\"Visit and potentially transform a node\"\"\"\n",
    "        if node is None:\n",
    "            return None\n",
    "            \n",
    "        method = 'visit_' + type(node).__name__\n",
    "        visitor = getattr(self, method, self.generic_visit)\n",
    "        return visitor(node)\n",
    "    \n",
    "    def generic_visit(self, node: ASTNode) -> ASTNode:\n",
    "        \"\"\"Default visitor that traverses all fields\"\"\"\n",
    "        for field in getattr(node, '__dataclass_fields__', {}):\n",
    "            value = getattr(node, field)\n",
    "            if isinstance(value, ASTNode):\n",
    "                optimized = self.visit(value)\n",
    "                if optimized is not None:\n",
    "                    setattr(node, field, optimized)\n",
    "            elif isinstance(value, list):\n",
    "                new_list = []\n",
    "                for item in value:\n",
    "                    if isinstance(item, ASTNode):\n",
    "                        optimized = self.visit(item)\n",
    "                        if optimized is not None:\n",
    "                            new_list.append(optimized)\n",
    "                    else:\n",
    "                        new_list.append(item)\n",
    "                setattr(node, field, new_list)\n",
    "        return node\n",
    "\n",
    "    def visit_Program(self, node: Program) -> Program:\n",
    "        \"\"\"Optimize the program's body\"\"\"\n",
    "        optimized_body = []\n",
    "        for stmt in node.body:\n",
    "            result = self.visit(stmt)\n",
    "            if result is not None:\n",
    "                if isinstance(result, list):\n",
    "                    optimized_body.extend(result)\n",
    "                else:\n",
    "                    optimized_body.append(result)\n",
    "        node.body = optimized_body\n",
    "        return node\n",
    "\n",
    "    def visit_BinaryOp(self, node: BinaryOp) -> ASTNode:\n",
    "        \"\"\"Enhanced constant folding for binary operations\"\"\"\n",
    "        # Visit operands first to ensure constant propagation happens\n",
    "        node.left = self.visit(node.left)\n",
    "        node.right = self.visit(node.right)\n",
    "        \n",
    "        # Try to evaluate if both operands are literals\n",
    "        left_val = getattr(node.left, 'value', None) if isinstance(node.left, Literal) else None\n",
    "        right_val = getattr(node.right, 'value', None) if isinstance(node.right, Literal) else None\n",
    "        \n",
    "        if left_val is not None and right_val is not None:\n",
    "            try:\n",
    "                if node.operator == '+':\n",
    "                    value = left_val + right_val\n",
    "                elif node.operator == '-':\n",
    "                    value = left_val - right_val\n",
    "                elif node.operator == '*':\n",
    "                    value = left_val * right_val\n",
    "                elif node.operator == '/':\n",
    "                    value = left_val / right_val\n",
    "                elif node.operator == '%':\n",
    "                    value = left_val % right_val\n",
    "                elif node.operator == '==':\n",
    "                    value = left_val == right_val\n",
    "                elif node.operator == '!=':\n",
    "                    value = left_val != right_val\n",
    "                elif node.operator == '<':\n",
    "                    value = left_val < right_val\n",
    "                elif node.operator == '>':\n",
    "                    value = left_val > right_val\n",
    "                elif node.operator == '<=':\n",
    "                    value = left_val <= right_val\n",
    "                elif node.operator == '>=':\n",
    "                    value = left_val >= right_val\n",
    "                else:\n",
    "                    return node\n",
    "                \n",
    "                self.modified = True\n",
    "                self.optimizations_applied += 1\n",
    "                # Create new literal and preserve any existing attributes\n",
    "                new_literal = Literal(value=value, line=node.line, column=node.column)\n",
    "                # Copy any additional attributes that might exist (like type annotations)\n",
    "                for attr in dir(node):\n",
    "                    if not attr.startswith('_') and attr not in ['left', 'right', 'operator', 'line', 'column', 'value']:\n",
    "                        if hasattr(node, attr) and not callable(getattr(node, attr)):\n",
    "                            try:\n",
    "                                setattr(new_literal, attr, getattr(node, attr))\n",
    "                            except:\n",
    "                                pass\n",
    "                return new_literal\n",
    "            except (ZeroDivisionError, TypeError, ValueError):\n",
    "                # Don't optimize if operation would cause an error\n",
    "                return node\n",
    "        return node\n",
    "\n",
    "    def visit_IfStatement(self, node: IfStatement) -> Optional[List[ASTNode]]:\n",
    "        \"\"\"Optimize if statements\"\"\"\n",
    "        # First optimize the condition\n",
    "        node.condition = self.visit(node.condition)\n",
    "        \n",
    "        # If condition is a constant literal\n",
    "        if isinstance(node.condition, Literal):\n",
    "            self.modified = True\n",
    "            self.optimizations_applied += 1\n",
    "            if node.condition.value:\n",
    "                # True condition - only keep then branch\n",
    "                optimized_then = []\n",
    "                for stmt in node.then_branch:\n",
    "                    result = self.visit(stmt)\n",
    "                    if result is not None:\n",
    "                        if isinstance(result, list):\n",
    "                            optimized_then.extend(result)\n",
    "                        else:\n",
    "                            optimized_then.append(result)\n",
    "                return optimized_then\n",
    "            elif node.else_branch:\n",
    "                # False condition - only keep else branch\n",
    "                optimized_else = []\n",
    "                for stmt in node.else_branch:\n",
    "                    result = self.visit(stmt)\n",
    "                    if result is not None:\n",
    "                        if isinstance(result, list):\n",
    "                            optimized_else.extend(result)\n",
    "                        else:\n",
    "                            optimized_else.append(result)\n",
    "                return optimized_else\n",
    "            else:\n",
    "                # False condition with no else - remove entirely\n",
    "                return []\n",
    "        \n",
    "        # Normal case: optimize all branches without removing them\n",
    "        # Optimize then branch\n",
    "        if node.then_branch:  # Only process if then_branch exists and is not empty\n",
    "            optimized_then = []\n",
    "            for stmt in node.then_branch:\n",
    "                result = self.visit(stmt)\n",
    "                if result is not None:\n",
    "                    if isinstance(result, list):\n",
    "                        optimized_then.extend(result)\n",
    "                    else:\n",
    "                        optimized_then.append(result)\n",
    "            node.then_branch = optimized_then\n",
    "                    \n",
    "        # Optimize elif branches\n",
    "        if node.elif_branches:  # Only process if elif_branches exists and is not empty\n",
    "            optimized_elif = []\n",
    "            for cond, body in node.elif_branches:\n",
    "                optimized_cond = self.visit(cond)\n",
    "                optimized_body = []\n",
    "                for stmt in body:\n",
    "                    result = self.visit(stmt)\n",
    "                    if result is not None:\n",
    "                        if isinstance(result, list):\n",
    "                            optimized_body.extend(result)\n",
    "                        else:\n",
    "                            optimized_body.append(result)\n",
    "                optimized_elif.append((optimized_cond, optimized_body))\n",
    "            node.elif_branches = optimized_elif\n",
    "            \n",
    "        # Optimize else branch\n",
    "        if node.else_branch:  # Only process if else_branch exists and is not empty\n",
    "            optimized_else = []\n",
    "            for stmt in node.else_branch:\n",
    "                result = self.visit(stmt)\n",
    "                if result is not None:\n",
    "                    if isinstance(result, list):\n",
    "                        optimized_else.extend(result)\n",
    "                    else:\n",
    "                        optimized_else.append(result)\n",
    "            node.else_branch = optimized_else\n",
    "        \n",
    "        return node\n",
    "\n",
    "    def visit_WhileLoop(self, node: WhileLoop) -> Optional[WhileLoop]:\n",
    "        \"\"\"Optimize while loops\"\"\"\n",
    "        node.condition = self.visit(node.condition)\n",
    "        \n",
    "        # If condition is a constant false, remove the loop\n",
    "        if isinstance(node.condition, Literal) and not node.condition.value:\n",
    "            self.modified = True\n",
    "            self.optimizations_applied += 1\n",
    "            return None\n",
    "                \n",
    "        # Handle loop body optimization differently based on loop type\n",
    "        if isinstance(node.condition, Literal) and node.condition.value is True:\n",
    "            # For infinite loops, don't optimize variable assignments\n",
    "            optimized_body = []\n",
    "            for stmt in node.body:\n",
    "                if isinstance(stmt, Assignment):\n",
    "                    optimized_body.append(stmt)\n",
    "                else:\n",
    "                    result = self.visit(stmt)\n",
    "                    if result is not None:\n",
    "                        optimized_body.append(result)\n",
    "            node.body = optimized_body\n",
    "        else:\n",
    "            # For normal loops, optimize everything\n",
    "            optimized_body = []\n",
    "            for stmt in node.body:\n",
    "                result = self.visit(stmt)\n",
    "                if result is not None:\n",
    "                    if isinstance(result, list):\n",
    "                        optimized_body.extend(result)\n",
    "                    else:\n",
    "                        optimized_body.append(result)\n",
    "            node.body = optimized_body\n",
    "        \n",
    "        return node\n",
    "        \n",
    "\n",
    "    def visit_FunctionDef(self, node: FunctionDef) -> FunctionDef:\n",
    "        \"\"\"Handle function scope - FIX: Don't optimize based on parameters\"\"\"\n",
    "        # Save current function parameters\n",
    "        old_params = self.function_params.copy()\n",
    "        \n",
    "        # Add current function parameters to avoid optimizing them\n",
    "        self.function_params.update(node.params)\n",
    "        \n",
    "        # Push new scope but don't add parameters as constants\n",
    "        self.scope_stack.append({})\n",
    "        \n",
    "        optimized_body = []\n",
    "        for stmt in node.body:\n",
    "            result = self.visit(stmt)\n",
    "            if result is not None:\n",
    "                if isinstance(result, list):\n",
    "                    optimized_body.extend(result)\n",
    "                else:\n",
    "                    optimized_body.append(result)\n",
    "        node.body = optimized_body\n",
    "        \n",
    "        # Restore previous state\n",
    "        self.scope_stack.pop()\n",
    "        self.function_params = old_params\n",
    "        return node\n",
    "\n",
    "    def visit_Return(self, node: Return) -> Return:\n",
    "        \"\"\"Optimize return value expressions\"\"\"\n",
    "        if node.value:\n",
    "            node.value = self.visit(node.value)\n",
    "        return node\n",
    "\n",
    "    def visit_Assignment(self, node: Assignment) -> Assignment:\n",
    "        \"\"\"Optimize assignment values and track constants\"\"\"\n",
    "        # Don't track assignments to function parameters as constants\n",
    "        if node.target in self.function_params:\n",
    "            node.value = self.visit(node.value)\n",
    "            return node\n",
    "            \n",
    "        # First optimize the value expression\n",
    "        node.value = self.visit(node.value)\n",
    "        \n",
    "        # Only track as constant if we're in the global scope (not inside a function)\n",
    "        # Inside functions, variables can have different values in different control flow paths\n",
    "        if len(self.scope_stack) == 1:  # Global scope only\n",
    "            # If the result is a literal, track it as a constant\n",
    "            if isinstance(node.value, Literal):\n",
    "                self.scope_stack[-1][node.target] = node.value.value\n",
    "                # Mark as modified to ensure another pass happens\n",
    "                self.modified = True\n",
    "            else:\n",
    "                # If assigning a non-constant, remove from constants if it exists\n",
    "                if node.target in self.scope_stack[-1]:\n",
    "                    del self.scope_stack[-1][node.target]\n",
    "        else:\n",
    "            # Inside function scope, don't track any assignments as constants\n",
    "            # because they might be in different control flow branches\n",
    "            if node.target in self.scope_stack[-1]:\n",
    "                del self.scope_stack[-1][node.target]\n",
    "        \n",
    "        return node\n",
    "\n",
    "    def visit_ExpressionStatement(self, node: ExpressionStatement) -> ExpressionStatement:\n",
    "        \"\"\"Optimize expressions in expression statements\"\"\"\n",
    "        node.expression = self.visit(node.expression)\n",
    "        return node\n",
    "\n",
    "    def visit_Call(self, node: Call) -> Call:\n",
    "        \"\"\"Optimize function calls (visit arguments)\"\"\"\n",
    "        if hasattr(node, 'args'):\n",
    "            node.args = [self.visit(arg) for arg in node.args]\n",
    "        return node\n",
    "\n",
    "def optimize_ast(ast: ASTNode) -> ASTNode:\n",
    "    \"\"\"\n",
    "    Optimize the AST and print detailed optimization information.\n",
    "    \n",
    "    Args:\n",
    "        ast: The AST to optimize\n",
    "    Returns:\n",
    "        The optimized AST\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer = Optimizer()\n",
    "    optimized_ast = optimizer.optimize(ast)\n",
    "    \n",
    "    print(f\"\\nApplied {optimizer.optimizations_applied} optimizations\")\n",
    "   \n",
    "    try:\n",
    "        dot_after = visualize_ast(optimized_ast)\n",
    "        dot_after.render('ast_after_opt', view=True, format='png')\n",
    "    except Exception as e:\n",
    "        print(f\"Visualization error: {e}\")\n",
    "    \n",
    "    return optimized_ast\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    source_code = \"\"\"\n",
    "def calculate():\n",
    "    a = 5 + 3 * 2\n",
    "    b = 10 / 2\n",
    "    c = a + b - (2 * 3)\n",
    "    return c\n",
    "\n",
    "result = calculate()\n",
    "\"\"\"\n",
    "\n",
    "    lexer = Lexer(source_code)\n",
    "    parser = Parser(lexer)\n",
    "    ast = parser.parse()\n",
    "    analyzer = SemanticAnalyzer()\n",
    "\n",
    "    try:\n",
    "        analyzer.analyze(ast)\n",
    "    except SemanticError as e:\n",
    "        print(f\"\\nSemantic Error: {e}\")\n",
    "\n",
    "    print(\"\\nBefore optimization:\")\n",
    "    print_ast(ast)\n",
    "    \n",
    "    optimized_ast = optimize_ast(ast)\n",
    "    \n",
    "    print(\"\\nAfter optimization:\")\n",
    "    print_ast(optimized_ast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cdb801",
   "metadata": {},
   "source": [
    "## Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99079f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Python Code:\n",
      "\n",
      "def calculate():\n",
      "    a = 5 + 3 * 2\n",
      "    b = 10 / 2\n",
      "    c = a + b - (2 * 3)\n",
      "    return c\n",
      "\n",
      "result = calculate()\n",
      "\n",
      "\n",
      "======================================================================================================================\n",
      "\n",
      "Javascript Code (Without Optimizations):\n",
      "function calculate() {\n",
      "    let a = (5 + (3 * 2));\n",
      "    let b = (10 / 2);\n",
      "    let c = ((a + b) - (2 * 3));\n",
      "    return c;\n",
      "}\n",
      "let result = calculate();\n",
      "\n",
      "======================================================================================================================\n",
      "\n",
      "\n",
      "Applied 4 optimizations\n",
      "\n",
      "Javascript Code After Optimizations:\n",
      "function calculate() {\n",
      "    let a = 11;\n",
      "    let b = 5.0;\n",
      "    let c = ((a + b) - 6);\n",
      "    return c;\n",
      "}\n",
      "let result = calculate();\n"
     ]
    }
   ],
   "source": [
    "#Note: let is used for all variable decalarations; Python's // becomes Math.floor(a / b) in JavaScript. and Converts range() calls to JavaScript array creation.\n",
    "\n",
    "class JavaScriptCodeGenerator:\n",
    "    def __init__(self):\n",
    "        self.indent_level = 0\n",
    "        self.indent_size = 4\n",
    "        self.declared_variables = set()  # Track declared variables to avoid re-declaring\n",
    "    \n",
    "    def indent(self):\n",
    "        \"\"\"Get current indentation string\"\"\"\n",
    "        return \" \" * (self.indent_level * self.indent_size)\n",
    "    \n",
    "    def increase_indent(self):\n",
    "        \"\"\"Increase indentation level\"\"\"\n",
    "        self.indent_level += 1\n",
    "    \n",
    "    def decrease_indent(self):\n",
    "        \"\"\"Decrease indentation level\"\"\"\n",
    "        self.indent_level = max(0, self.indent_level - 1)\n",
    "    \n",
    "    def generate(self, node):\n",
    "        \"\"\"Main entry point for code generation\"\"\"\n",
    "        if node is None:\n",
    "            return \"\"\n",
    "        \n",
    "        # Dispatch to appropriate method based on node type\n",
    "        method_name = f\"generate_{type(node).__name__}\"\n",
    "        if hasattr(self, method_name):\n",
    "            return getattr(self, method_name)(node)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Code generation not implemented for {type(node).__name__}\")\n",
    "    \n",
    "    def generate_Program(self, node):\n",
    "        \"\"\"Generate code for the entire program\"\"\"\n",
    "        lines = []\n",
    "        for stmt in node.body:\n",
    "            generated = self.generate(stmt)\n",
    "            if generated.strip():  # Only add non-empty lines\n",
    "                lines.append(generated)\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def generate_FunctionDef(self, node):\n",
    "        \"\"\"Generate JavaScript function definition\"\"\"\n",
    "        params = \", \".join(node.params)\n",
    "        lines = [f\"{self.indent()}function {node.name}({params}) {{\"]\n",
    "        \n",
    "        self.increase_indent()\n",
    "        for stmt in node.body:\n",
    "            generated = self.generate(stmt)\n",
    "            if generated.strip():\n",
    "                lines.append(generated)\n",
    "        self.decrease_indent()\n",
    "        \n",
    "        lines.append(f\"{self.indent()}}}\")\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def generate_IfStatement(self, node):\n",
    "        \"\"\"Generate JavaScript if statement\"\"\"\n",
    "        condition = self.generate(node.condition)\n",
    "        lines = [f\"{self.indent()}if ({condition}) {{\"]\n",
    "        \n",
    "        # Generate then branch\n",
    "        self.increase_indent()\n",
    "        for stmt in node.then_branch:\n",
    "            generated = self.generate(stmt)\n",
    "            if generated.strip():\n",
    "                lines.append(generated)\n",
    "        self.decrease_indent()\n",
    "        \n",
    "        # Generate elif branches\n",
    "        for elif_condition, elif_body in node.elif_branches:\n",
    "            elif_cond = self.generate(elif_condition)\n",
    "            lines.append(f\"{self.indent()}}} else if ({elif_cond}) {{\")\n",
    "            \n",
    "            self.increase_indent()\n",
    "            for stmt in elif_body:\n",
    "                generated = self.generate(stmt)\n",
    "                if generated.strip():\n",
    "                    lines.append(generated)\n",
    "            self.decrease_indent()\n",
    "        \n",
    "        # Generate else branch\n",
    "        if node.else_branch:\n",
    "            lines.append(f\"{self.indent()}}} else {{\")\n",
    "            \n",
    "            self.increase_indent()\n",
    "            for stmt in node.else_branch:\n",
    "                generated = self.generate(stmt)\n",
    "                if generated.strip():\n",
    "                    lines.append(generated)\n",
    "            self.decrease_indent()\n",
    "        \n",
    "        lines.append(f\"{self.indent()}}}\")\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def generate_WhileLoop(self, node):\n",
    "        \"\"\"Generate JavaScript while loop\"\"\"\n",
    "        condition = self.generate(node.condition)\n",
    "        lines = [f\"{self.indent()}while ({condition}) {{\"]\n",
    "        \n",
    "        self.increase_indent()\n",
    "        for stmt in node.body:\n",
    "            generated = self.generate(stmt)\n",
    "            if generated.strip():\n",
    "                lines.append(generated)\n",
    "        self.decrease_indent()\n",
    "        \n",
    "        lines.append(f\"{self.indent()}}}\")\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def generate_ForLoop(self, node):\n",
    "        \"\"\"Generate JavaScript for loop (converts Python for to JS for...of)\"\"\"\n",
    "        iterable = self.generate(node.iterable)\n",
    "        \n",
    "        # For loop variables are block-scoped, so we can always use let\n",
    "        lines = [f\"{self.indent()}for (let {node.var} of {iterable}) {{\"]\n",
    "        \n",
    "        self.increase_indent()\n",
    "        for stmt in node.body:\n",
    "            generated = self.generate(stmt)\n",
    "            if generated.strip():\n",
    "                lines.append(generated)\n",
    "        self.decrease_indent()\n",
    "        \n",
    "        lines.append(f\"{self.indent()}}}\")\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def generate_Return(self, node):\n",
    "        \"\"\"Generate JavaScript return statement\"\"\"\n",
    "        if node.value:\n",
    "            value = self.generate(node.value)\n",
    "            return f\"{self.indent()}return {value};\"\n",
    "        else:\n",
    "            return f\"{self.indent()}return;\"\n",
    "    \n",
    "    def generate_Assignment(self, node):\n",
    "        \"\"\"Generate JavaScript variable assignment\"\"\"\n",
    "        value = self.generate(node.value)\n",
    "        \n",
    "        # Check if variable was already declared to avoid re-declaration\n",
    "        if node.target in self.declared_variables:\n",
    "            # Just assignment, no declaration\n",
    "            return f\"{self.indent()}{node.target} = {value};\"\n",
    "        else:\n",
    "            # First declaration - use let\n",
    "            self.declared_variables.add(node.target)\n",
    "            return f\"{self.indent()}let {node.target} = {value};\"\n",
    "    \n",
    "    def generate_ExpressionStatement(self, node):\n",
    "        \"\"\"Generate JavaScript expression statement\"\"\"\n",
    "        expr = self.generate(node.expression)\n",
    "        return f\"{self.indent()}{expr};\"\n",
    "    \n",
    "    def generate_BinaryOp(self, node):\n",
    "        \"\"\"Generate JavaScript binary operation\"\"\"\n",
    "        left = self.generate(node.left)\n",
    "        right = self.generate(node.right)\n",
    "        \n",
    "        # Map Python operators to JavaScript operators\n",
    "        operator_map = {\n",
    "            '+': '+',\n",
    "            '-': '-',\n",
    "            '*': '*',\n",
    "            '/': '/',\n",
    "            '//': 'Math.floor(/ )',  # Floor division needs special handling\n",
    "            '%': '%',\n",
    "            '**': '**',  # Exponentiation\n",
    "            '==': '===',  # Use strict equality\n",
    "            '!=': '!==',  # Use strict inequality\n",
    "            '<': '<',\n",
    "            '>': '>',\n",
    "            '<=': '<=',\n",
    "            '>=': '>=',\n",
    "            'and': '&&',\n",
    "            'or': '||',\n",
    "            'in': 'in',\n",
    "        }\n",
    "        \n",
    "        js_operator = operator_map.get(node.operator, node.operator)\n",
    "        \n",
    "        # Special handling for floor division\n",
    "        if node.operator == '//':\n",
    "            return f\"Math.floor({left} / {right})\"\n",
    "        \n",
    "        return f\"({left} {js_operator} {right})\"\n",
    "    \n",
    "    def generate_UnaryOp(self, node):\n",
    "        \"\"\"Generate JavaScript unary operation\"\"\"\n",
    "        operand = self.generate(node.operand)\n",
    "        \n",
    "        # Map Python unary operators to JavaScript\n",
    "        operator_map = {\n",
    "            '+': '+',\n",
    "            '-': '-',\n",
    "            'not': '!',\n",
    "        }\n",
    "        \n",
    "        js_operator = operator_map.get(node.operator, node.operator)\n",
    "        return f\"({js_operator}{operand})\"\n",
    "    \n",
    "    def generate_Call(self, node):\n",
    "        \"\"\"Generate JavaScript function call\"\"\"\n",
    "        func_name = self.generate(node.func)\n",
    "        args = [self.generate(arg) for arg in node.args]\n",
    "        \n",
    "        # Handle built-in Python functions\n",
    "        if isinstance(node.func, Identifier):\n",
    "            if node.func.name == 'print':\n",
    "                # Convert print() to console.log()\n",
    "                return f\"console.log({', '.join(args)})\"\n",
    "            elif node.func.name == 'len':\n",
    "                # Convert len() to .length property\n",
    "                if args:\n",
    "                    return f\"{args[0]}.length\"\n",
    "            elif node.func.name == 'range':\n",
    "                # Convert range() to array creation\n",
    "                if len(args) == 1:\n",
    "                    return f\"Array.from({{length: {args[0]}}}, (_, i) => i)\"\n",
    "                elif len(args) == 2:\n",
    "                    return f\"Array.from({{length: {args[1]} - {args[0]}}}, (_, i) => i + {args[0]})\"\n",
    "                elif len(args) == 3:\n",
    "                    start, stop, step = args\n",
    "                    return f\"Array.from({{length: Math.ceil(({stop} - {start}) / {step})}}, (_, i) => {start} + i * {step})\"\n",
    "        \n",
    "        # Regular function call\n",
    "        return f\"{func_name}({', '.join(args)})\"\n",
    "    \n",
    "    def generate_Identifier(self, node):\n",
    "        \"\"\"Generate JavaScript identifier\"\"\"\n",
    "        return node.name\n",
    "    \n",
    "    def generate_Literal(self, node):\n",
    "        \"\"\"Generate JavaScript literal\"\"\"\n",
    "        if isinstance(node.value, str):\n",
    "            # Escape quotes and return as string literal\n",
    "            escaped = node.value.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"')\n",
    "            return f'\"{escaped}\"'\n",
    "        elif isinstance(node.value, bool):\n",
    "            # Convert Python True/False to JavaScript true/false\n",
    "            return str(node.value).lower()\n",
    "        elif node.value is None:\n",
    "            # Convert Python None to JavaScript null\n",
    "            return \"null\"\n",
    "        else:\n",
    "            # Numbers remain the same\n",
    "            return str(node.value)\n",
    "\n",
    "\n",
    "def generate_javascript_code(ast_node):\n",
    "    \"\"\"\n",
    "    Main function to generate JavaScript code from an optimized AST\n",
    "    \n",
    "    Args:\n",
    "        ast_node: The root AST node (usually a Program node)\n",
    "    \n",
    "    Returns:\n",
    "        str: Generated JavaScript code\n",
    "    \"\"\"\n",
    "    generator = JavaScriptCodeGenerator()\n",
    "    return generator.generate(ast_node)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test1_python = \"\"\"\n",
    "def calculate():\n",
    "    a = 5 + 3 * 2\n",
    "    b = 10 / 2\n",
    "    c = a + b - (2 * 3)\n",
    "    return c\n",
    "\n",
    "result = calculate()\n",
    "\"\"\"\n",
    "\n",
    "    lexer = Lexer(test1_python)\n",
    "    parser = Parser(lexer)\n",
    "    ast = parser.parse()\n",
    "    analyzer = SemanticAnalyzer()\n",
    "    analyzer.analyze(ast)    \n",
    "    \n",
    "    print(\"Original Python Code:\")\n",
    "    print(test1_python)\n",
    "    print(\"\\n======================================================================================================================\\n\")\n",
    "    generator = JavaScriptCodeGenerator()\n",
    "    unoptimized_js_code = generator.generate(ast)\n",
    "    print(\"Javascript Code (Without Optimizations):\")\n",
    "    print(unoptimized_js_code)\n",
    "    print(\"\\n======================================================================================================================\\n\")\n",
    "    optimized_ast = optimize_ast(ast)\n",
    "    generator = JavaScriptCodeGenerator()\n",
    "    js_code = generator.generate(optimized_ast)\n",
    "    print(\"Javascript Code After Optimizations:\")\n",
    "    print(js_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed207ce",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "##### Keywords: if, else, elif, while, for, in, def, return, True, False, None\n",
    "##### Operators: +, -, *, /, %, **, =, ==, !=, <, >, <=, >=, and, or, not\n",
    "##### Delimiters: (, ), {, }, [, ], ',' , '.', ':', ';'\n",
    "##### Literals: INTEGER, FLOAT, STRING\n",
    "##### Other: IDENTIFIER, INDENT, DEDENT, NEWLINE, EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96572fc",
   "metadata": {},
   "source": [
    "## Token and Error Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "910907aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Generator, List, Optional, Tuple\n",
    "\n",
    "class Token:\n",
    "    def __init__(self, type: str, value: str, line: int, column: int):\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "        self.line = line\n",
    "        self.column = column\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Token({self.type}, '{self.value}', line={self.line}, col={self.column})\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "class Error:\n",
    "    def __init__(self, message: str, line: int, column: int):\n",
    "        self.message = message\n",
    "        self.line = line\n",
    "        self.column = column\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Error: {self.message} at line {self.line}, column {self.column}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d04a7",
   "metadata": {},
   "source": [
    "## Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ec43f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    # Defining regular expressions for token\n",
    "    TOKEN_SPECS = [\n",
    "        ('COMMENT', r'#.*'),                                  # Comments\n",
    "        ('STRING', r'\\\"([^\\\\\\\"]|\\\\.)*\\\"|\\'([^\\\\\\']|\\\\.)*\\''), # String literals\n",
    "        ('FLOAT', r'\\d+\\.\\d+'),                               # Float literals\n",
    "        ('INTEGER', r'\\d+'),                                  # Integer literals\n",
    "        ('KEYWORD', r'(if|else|elif|while|for|in|def|return|True|False|None)\\b'),  # Keywords\n",
    "        ('IDENTIFIER', r'[a-zA-Z_]\\w*'),                      # Identifiers\n",
    "        # Operators (multi-character ones first)\n",
    "        ('OP_EQ', r'=='),\n",
    "        ('OP_NE', r'!='),\n",
    "        ('OP_LE', r'<='),\n",
    "        ('OP_GE', r'>='),\n",
    "        ('OP_ASSIGN', r'='),\n",
    "        ('OP_PLUS', r'\\+'),\n",
    "        ('OP_MINUS', r'-'),\n",
    "        ('OP_MULT', r'\\*\\*|\\/\\/|\\*|\\/'),  # ** (power), // (floor div), * (mult), / (div)\n",
    "        ('OP_MOD', r'%'),\n",
    "        ('OP_LT', r'<'),\n",
    "        ('OP_GT', r'>'),\n",
    "        # Delimiters\n",
    "        ('LPAREN', r'\\('),\n",
    "        ('RPAREN', r'\\)'),\n",
    "        ('LBRACKET', r'\\['),\n",
    "        ('RBRACKET', r'\\]'),\n",
    "        ('LBRACE', r'\\{'),\n",
    "        ('RBRACE', r'\\}'),\n",
    "        ('COMMA', r','),\n",
    "        ('DOT', r'\\.'),\n",
    "        ('COLON', r':'),\n",
    "        ('SEMICOLON', r';'),\n",
    "        ('NEWLINE', r'\\n'),\n",
    "        ('WHITESPACE', r'[ \\t]+'),                            # Whitespace\n",
    "        # INDENT and DEDENT tokens are not matched by regex but generated based on whitespace\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, source_code: str):\n",
    "        self.source_code = source_code\n",
    "        self.tokens = []\n",
    "        self.errors = []\n",
    "        self.line = 1\n",
    "        self.column = 1\n",
    "        self.indent_levels = [0]  # Start with indent level 0\n",
    "    \n",
    "    def tokenize(self) -> Generator[Token, None, None]:\n",
    "        \"\"\"Tokenize the source code and yield tokens.\"\"\"\n",
    "        # Process the source code line by line to handle indentation properly\n",
    "        lines = self.source_code.split('\\n')\n",
    "        \n",
    "        for line_num, line in enumerate(lines):\n",
    "            self.line = line_num + 1\n",
    "            self.column = 1\n",
    "            \n",
    "            #calculating the amount of leading whitespace (indentation) at the beginning of the current line\n",
    "            if line.strip():  # Non-empty line      #strip() is equivalent of trim() in JS\n",
    "                indent_size = len(line) - len(line.lstrip())    #lstrip() will remove leading spaces in the line i.e. remove any indentation; and the difference in length tells you how much whitespace there was\n",
    "                indent_tokens = self._handle_indentation(indent_size)\n",
    "                for token in indent_tokens:\n",
    "                    yield token\n",
    "            else:   # Skip empty lines but still count them for line numbers\n",
    "                yield Token('NEWLINE', '\\\\n', self.line, self.column)\n",
    "                continue\n",
    "            \n",
    "            # Process the rest of the line\n",
    "            i = indent_size if 'indent_size' in locals() else 0\n",
    "            line_content = line\n",
    "            \n",
    "            while i < len(line_content):    #traversing a line character by character\n",
    "                match = None\n",
    "                \n",
    "                ## Skip spaces and tabs (already handled indentation)\n",
    "                ##if line_content[i].isspace():   #isspace() checks if the entire line is whitespace or not; here it checks whether a single character is whitespace or not since its applied on line_content[i]\n",
    "                ##    i += 1\n",
    "                ##    self.column += 1\n",
    "                ##    continue\n",
    "                \n",
    "                # Try to match each token pattern\n",
    "                for token_type, pattern in self.TOKEN_SPECS:\n",
    "                    regex = re.compile(pattern) #compiling the pattern into a regex so that we can use it to find tokens in the line\n",
    "                    match = regex.match(line_content, i)    #match() will check if the \"starting\" of the string matches the given regex or not, line_content gives the line whose starting it has to compare with the regex with i telling from which point in the line to assume as thhe starting of the line\n",
    "                    #if a match is found, 'match' will contain an object with info about the found match (like start and end, its value and so on), otherwise it'll contain \"none\"\n",
    "                    \n",
    "                    if match:\n",
    "                        value = match.group(0)  #group will give the value of the match object\n",
    "                        \n",
    "                        if token_type == 'WHITESPACE':\n",
    "                            #whitespace is not yielded becuz parser receives stream of tokens without space and doesnt care about space\n",
    "                            # Just update column and continue\n",
    "                            self.column += len(value)\n",
    "                            i += len(value)\n",
    "                            continue\n",
    "                        elif token_type == 'COMMENT':\n",
    "                            # Ignore comments\n",
    "                            i += len(value)\n",
    "                            self.column += len(value)\n",
    "                            break   # Break out of the current character processing loop after handling comments\n",
    "                        else:\n",
    "                            # For all other tokens\n",
    "                            token = Token(token_type, value, self.line, self.column)\n",
    "                            yield token\n",
    "                        \n",
    "                        i += len(value)\n",
    "                        self.column += len(value)\n",
    "                        break\n",
    "                \n",
    "                if not match:\n",
    "                    # No token matched, raise an error\n",
    "                    error_msg = f\"Invalid character: '{line_content[i]}'\"\n",
    "                    error = Error(error_msg, self.line, self.column)\n",
    "                    self.errors.append(error)\n",
    "                    print(error)  # Print the error but continue\n",
    "                    i += 1\n",
    "                    self.column += 1\n",
    "            \n",
    "            # Add NEWLINE at the end of each line except the last one\n",
    "            if line_num < len(lines) - 1 or self.source_code.endswith('\\n'):\n",
    "                yield Token('NEWLINE', '\\\\n', self.line, self.column)\n",
    "        \n",
    "        # Output any pending dedents at the end of the file\n",
    "        #end of file means all indented blocks have been dedented so pop all elements of the indent_levels stack\n",
    "        while len(self.indent_levels) > 1:\n",
    "            self.indent_levels.pop()    \n",
    "            yield Token('DEDENT', '', self.line, self.column)\n",
    "        \n",
    "        # End of file token\n",
    "        yield Token('EOF', '', self.line, self.column)\n",
    "    \n",
    "    def _handle_indentation(self, indent_size: int) -> List[Token]:\n",
    "        \"\"\"Handle Python's indentation-based block structure. Returns a list of INDENT or DEDENT tokens as needed.\"\"\"\n",
    "        tokens = []\n",
    "        previous_line_indent = self.indent_levels[-1]\n",
    "        \n",
    "        if indent_size > previous_line_indent:\n",
    "            # This is an indentation (start of a new block)\n",
    "            self.indent_levels.append(indent_size)  #when a new block is recognized through indentation its indentation level is pushed in the stack so that w ecan later check whether that block was dedented properly or not\n",
    "            tokens.append(Token('INDENT', ' ' * (indent_size - previous_line_indent), self.line, 1))\n",
    "        \n",
    "        elif indent_size < previous_line_indent:\n",
    "            # This is a dedentation (end of one or more blocks)\n",
    "            while self.indent_levels and indent_size < self.indent_levels[-1]: # ensuring that the latest code block is being dedented\n",
    "                self.indent_levels.pop()\n",
    "                tokens.append(Token('DEDENT', '', self.line, 1))\n",
    "            \n",
    "            if indent_size != self.indent_levels[-1]:\n",
    "                # Invalid indentation\n",
    "                error_msg = f\"Inconsistent indentation\"\n",
    "                error = Error(error_msg, self.line, 1)\n",
    "                self.errors.append(error)\n",
    "                print(error)  # Print the error but continue\n",
    "                \n",
    "                \n",
    "                # and what about handling indent_size == self.indent_levels[-1]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b0182e",
   "metadata": {},
   "source": [
    "## Test Script for Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7c75670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Basic Assignment ===\n",
      "Source code:\n",
      "x = 10\n",
      "\n",
      "Tokens:\n",
      "Token(IDENTIFIER, 'x', line=1, col=1)\n",
      "Token(OP_ASSIGN, '=', line=1, col=3)\n",
      "Token(INTEGER, '10', line=1, col=5)\n",
      "Token(EOF, '', line=1, col=7)\n",
      "\n",
      "Total tokens: 4\n",
      "\n",
      "=== Testing Function Definition ===\n",
      "Source code:\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "Tokens:\n",
      "Token(KEYWORD, 'def', line=1, col=1)\n",
      "Token(IDENTIFIER, 'add', line=1, col=5)\n",
      "Token(LPAREN, '(', line=1, col=8)\n",
      "Token(IDENTIFIER, 'a', line=1, col=9)\n",
      "Token(COMMA, ',', line=1, col=10)\n",
      "Token(IDENTIFIER, 'b', line=1, col=12)\n",
      "Token(RPAREN, ')', line=1, col=13)\n",
      "Token(COLON, ':', line=1, col=14)\n",
      "Token(NEWLINE, '\\n', line=1, col=15)\n",
      "Token(INDENT, '    ', line=2, col=1)\n",
      "Token(KEYWORD, 'return', line=2, col=1)\n",
      "Token(IDENTIFIER, 'a', line=2, col=8)\n",
      "Token(OP_PLUS, '+', line=2, col=10)\n",
      "Token(IDENTIFIER, 'b', line=2, col=12)\n",
      "Token(DEDENT, '', line=2, col=13)\n",
      "Token(EOF, '', line=2, col=13)\n",
      "\n",
      "Total tokens: 16\n",
      "\n",
      "=== Testing If Statement ===\n",
      "Source code:\n",
      "if x > 10:\n",
      "    print(\"Greater than 10\")\n",
      "else:\n",
      "    print(\"Less than or equal to 10\")\n",
      "\n",
      "Tokens:\n",
      "Token(KEYWORD, 'if', line=1, col=1)\n",
      "Token(IDENTIFIER, 'x', line=1, col=4)\n",
      "Token(OP_GT, '>', line=1, col=6)\n",
      "Token(INTEGER, '10', line=1, col=8)\n",
      "Token(COLON, ':', line=1, col=10)\n",
      "Token(NEWLINE, '\\n', line=1, col=11)\n",
      "Token(INDENT, '    ', line=2, col=1)\n",
      "Token(IDENTIFIER, 'print', line=2, col=1)\n",
      "Token(LPAREN, '(', line=2, col=6)\n",
      "Token(STRING, '\"Greater than 10\"', line=2, col=7)\n",
      "Token(RPAREN, ')', line=2, col=24)\n",
      "Token(NEWLINE, '\\n', line=2, col=25)\n",
      "Token(DEDENT, '', line=3, col=1)\n",
      "Token(KEYWORD, 'else', line=3, col=1)\n",
      "Token(COLON, ':', line=3, col=5)\n",
      "Token(NEWLINE, '\\n', line=3, col=6)\n",
      "Token(INDENT, '    ', line=4, col=1)\n",
      "Token(IDENTIFIER, 'print', line=4, col=1)\n",
      "Token(LPAREN, '(', line=4, col=6)\n",
      "Token(STRING, '\"Less than or equal to 10\"', line=4, col=7)\n",
      "Token(RPAREN, ')', line=4, col=33)\n",
      "Token(DEDENT, '', line=4, col=34)\n",
      "Token(EOF, '', line=4, col=34)\n",
      "\n",
      "Total tokens: 23\n",
      "\n",
      "=== Testing Literals and Operators ===\n",
      "Source code:\n",
      "# Testing literals\n",
      "x = 42\n",
      "y = 3.14\n",
      "name = \"John\"\n",
      "flag = True\n",
      "result = x + y * 2\n",
      "equal = x == y\n",
      "\n",
      "Tokens:\n",
      "Token(NEWLINE, '\\n', line=1, col=19)\n",
      "Token(IDENTIFIER, 'x', line=2, col=1)\n",
      "Token(OP_ASSIGN, '=', line=2, col=3)\n",
      "Token(INTEGER, '42', line=2, col=5)\n",
      "Token(NEWLINE, '\\n', line=2, col=7)\n",
      "Token(IDENTIFIER, 'y', line=3, col=1)\n",
      "Token(OP_ASSIGN, '=', line=3, col=3)\n",
      "Token(FLOAT, '3.14', line=3, col=5)\n",
      "Token(NEWLINE, '\\n', line=3, col=9)\n",
      "Token(IDENTIFIER, 'name', line=4, col=1)\n",
      "Token(OP_ASSIGN, '=', line=4, col=6)\n",
      "Token(STRING, '\"John\"', line=4, col=8)\n",
      "Token(NEWLINE, '\\n', line=4, col=14)\n",
      "Token(IDENTIFIER, 'flag', line=5, col=1)\n",
      "Token(OP_ASSIGN, '=', line=5, col=6)\n",
      "Token(KEYWORD, 'True', line=5, col=8)\n",
      "Token(NEWLINE, '\\n', line=5, col=12)\n",
      "Token(IDENTIFIER, 'result', line=6, col=1)\n",
      "Token(OP_ASSIGN, '=', line=6, col=8)\n",
      "Token(IDENTIFIER, 'x', line=6, col=10)\n",
      "Token(OP_PLUS, '+', line=6, col=12)\n",
      "Token(IDENTIFIER, 'y', line=6, col=14)\n",
      "Token(OP_MULT, '*', line=6, col=16)\n",
      "Token(INTEGER, '2', line=6, col=18)\n",
      "Token(NEWLINE, '\\n', line=6, col=19)\n",
      "Token(IDENTIFIER, 'equal', line=7, col=1)\n",
      "Token(OP_ASSIGN, '=', line=7, col=7)\n",
      "Token(IDENTIFIER, 'x', line=7, col=9)\n",
      "Token(OP_EQ, '==', line=7, col=11)\n",
      "Token(IDENTIFIER, 'y', line=7, col=14)\n",
      "Token(EOF, '', line=7, col=15)\n",
      "\n",
      "Total tokens: 31\n",
      "\n",
      "=== Testing Loops ===\n",
      "Source code:\n",
      "# Testing loops\n",
      "for i in range(10):\n",
      "    if i % 2 == 0:\n",
      "        print(\"Even\")\n",
      "    else:\n",
      "        print(\"Odd\")\n",
      "\n",
      "# While loop\n",
      "count = 0\n",
      "while count < 5:\n",
      "    count += 1\n",
      "\n",
      "\n",
      "Tokens:\n",
      "Token(NEWLINE, '\\n', line=1, col=16)\n",
      "Token(KEYWORD, 'for', line=2, col=1)\n",
      "Token(IDENTIFIER, 'i', line=2, col=5)\n",
      "Token(KEYWORD, 'in', line=2, col=7)\n",
      "Token(IDENTIFIER, 'range', line=2, col=10)\n",
      "Token(LPAREN, '(', line=2, col=15)\n",
      "Token(INTEGER, '10', line=2, col=16)\n",
      "Token(RPAREN, ')', line=2, col=18)\n",
      "Token(COLON, ':', line=2, col=19)\n",
      "Token(NEWLINE, '\\n', line=2, col=20)\n",
      "Token(INDENT, '    ', line=3, col=1)\n",
      "Token(KEYWORD, 'if', line=3, col=1)\n",
      "Token(IDENTIFIER, 'i', line=3, col=4)\n",
      "Token(OP_MOD, '%', line=3, col=6)\n",
      "Token(INTEGER, '2', line=3, col=8)\n",
      "Token(OP_EQ, '==', line=3, col=10)\n",
      "Token(INTEGER, '0', line=3, col=13)\n",
      "Token(COLON, ':', line=3, col=14)\n",
      "Token(NEWLINE, '\\n', line=3, col=15)\n",
      "Token(INDENT, '    ', line=4, col=1)\n",
      "Token(IDENTIFIER, 'print', line=4, col=1)\n",
      "Token(LPAREN, '(', line=4, col=6)\n",
      "Token(STRING, '\"Even\"', line=4, col=7)\n",
      "Token(RPAREN, ')', line=4, col=13)\n",
      "Token(NEWLINE, '\\n', line=4, col=14)\n",
      "Token(DEDENT, '', line=5, col=1)\n",
      "Token(KEYWORD, 'else', line=5, col=1)\n",
      "Token(COLON, ':', line=5, col=5)\n",
      "Token(NEWLINE, '\\n', line=5, col=6)\n",
      "Token(INDENT, '    ', line=6, col=1)\n",
      "Token(IDENTIFIER, 'print', line=6, col=1)\n",
      "Token(LPAREN, '(', line=6, col=6)\n",
      "Token(STRING, '\"Odd\"', line=6, col=7)\n",
      "Token(RPAREN, ')', line=6, col=12)\n",
      "Token(NEWLINE, '\\n', line=6, col=13)\n",
      "Token(NEWLINE, '\\n', line=7, col=1)\n",
      "Token(DEDENT, '', line=8, col=1)\n",
      "Token(DEDENT, '', line=8, col=1)\n",
      "Token(NEWLINE, '\\n', line=8, col=13)\n",
      "Token(IDENTIFIER, 'count', line=9, col=1)\n",
      "Token(OP_ASSIGN, '=', line=9, col=7)\n",
      "Token(INTEGER, '0', line=9, col=9)\n",
      "Token(NEWLINE, '\\n', line=9, col=10)\n",
      "Token(KEYWORD, 'while', line=10, col=1)\n",
      "Token(IDENTIFIER, 'count', line=10, col=7)\n",
      "Token(OP_LT, '<', line=10, col=13)\n",
      "Token(INTEGER, '5', line=10, col=15)\n",
      "Token(COLON, ':', line=10, col=16)\n",
      "Token(NEWLINE, '\\n', line=10, col=17)\n",
      "Token(INDENT, '    ', line=11, col=1)\n",
      "Token(IDENTIFIER, 'count', line=11, col=1)\n",
      "Token(OP_PLUS, '+', line=11, col=7)\n",
      "Token(OP_ASSIGN, '=', line=11, col=8)\n",
      "Token(INTEGER, '1', line=11, col=10)\n",
      "Token(NEWLINE, '\\n', line=11, col=11)\n",
      "Token(NEWLINE, '\\n', line=12, col=1)\n",
      "Token(DEDENT, '', line=12, col=1)\n",
      "Token(EOF, '', line=12, col=1)\n",
      "\n",
      "Total tokens: 58\n",
      "\n",
      "=== Testing Error Handling ===\n",
      "Source code:\n",
      "x = 10 @\n",
      "\n",
      "Tokens:\n",
      "Token(IDENTIFIER, 'x', line=1, col=1)\n",
      "Token(OP_ASSIGN, '=', line=1, col=3)\n",
      "Token(INTEGER, '10', line=1, col=5)\n",
      "Error: Invalid character: '@' at line 1, column 8\n",
      "Token(EOF, '', line=1, col=9)\n",
      "\n",
      "Total tokens: 4\n",
      "\n",
      "Errors (1):\n",
      "  Error: Invalid character: '@' at line 1, column 8\n",
      "\n",
      "=== Testing Inconsistent Indentation ===\n",
      "Source code:\n",
      "def test():\n",
      "    x = 1\n",
      "   y = 2  # Inconsistent indentation\n",
      "\n",
      "\n",
      "Tokens:\n",
      "Token(KEYWORD, 'def', line=1, col=1)\n",
      "Token(IDENTIFIER, 'test', line=1, col=5)\n",
      "Token(LPAREN, '(', line=1, col=9)\n",
      "Token(RPAREN, ')', line=1, col=10)\n",
      "Token(COLON, ':', line=1, col=11)\n",
      "Token(NEWLINE, '\\n', line=1, col=12)\n",
      "Token(INDENT, '    ', line=2, col=1)\n",
      "Token(IDENTIFIER, 'x', line=2, col=1)\n",
      "Token(OP_ASSIGN, '=', line=2, col=3)\n",
      "Token(INTEGER, '1', line=2, col=5)\n",
      "Token(NEWLINE, '\\n', line=2, col=6)\n",
      "Error: Inconsistent indentation at line 3, column 1\n",
      "Token(DEDENT, '', line=3, col=1)\n",
      "Token(IDENTIFIER, 'y', line=3, col=1)\n",
      "Token(OP_ASSIGN, '=', line=3, col=3)\n",
      "Token(INTEGER, '2', line=3, col=5)\n",
      "Token(NEWLINE, '\\n', line=3, col=34)\n",
      "Token(NEWLINE, '\\n', line=4, col=1)\n",
      "Token(EOF, '', line=4, col=1)\n",
      "\n",
      "Total tokens: 18\n",
      "\n",
      "Errors (1):\n",
      "  Error: Inconsistent indentation at line 3, column 1\n"
     ]
    }
   ],
   "source": [
    "def test_lexer(source_code, test_name=\"\"):\n",
    "    print(f\"\\n=== Testing {test_name} ===\")\n",
    "    print(f\"Source code:\\n{source_code}\")\n",
    "    print(\"\\nTokens:\")\n",
    "    \n",
    "    lexer = Lexer(source_code)\n",
    "    token_count = 0\n",
    "    \n",
    "    try:\n",
    "        for token in lexer.tokenize():\n",
    "            print(token)\n",
    "            token_count += 1\n",
    "        \n",
    "        print(f\"\\nTotal tokens: {token_count}\")\n",
    "        if lexer.errors:\n",
    "            print(f\"\\nErrors ({len(lexer.errors)}):\")\n",
    "            for error in lexer.errors:\n",
    "                print(f\"  {error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Test cases\n",
    "if __name__ == \"__main__\":\n",
    "    # Test 1: Basic variable assignment\n",
    "    test_lexer(\"x = 10\", \"Basic Assignment\")\n",
    "\n",
    "    # Test 2: Simple function definition\n",
    "    test_lexer(\"\"\"def add(a, b):\n",
    "    return a + b\"\"\", \"Function Definition\")\n",
    "\n",
    "    # Test 3: If statement with proper indentation\n",
    "    test_lexer(\"\"\"if x > 10:\n",
    "    print(\"Greater than 10\")\n",
    "else:\n",
    "    print(\"Less than or equal to 10\")\"\"\", \"If Statement\")\n",
    "\n",
    "    # Test 4: Various literals and operators\n",
    "    test_lexer(\"\"\"# Testing literals\n",
    "x = 42\n",
    "y = 3.14\n",
    "name = \"John\"\n",
    "flag = True\n",
    "result = x + y * 2\n",
    "equal = x == y\"\"\", \"Literals and Operators\")\n",
    "\n",
    "    # Test 5: Loops\n",
    "    test_lexer(\"\"\"# Testing loops\n",
    "for i in range(10):\n",
    "    if i % 2 == 0:\n",
    "        print(\"Even\")\n",
    "    else:\n",
    "        print(\"Odd\")\n",
    "\n",
    "# While loop\n",
    "count = 0\n",
    "while count < 5:\n",
    "    count += 1\n",
    "\"\"\", \"Loops\")\n",
    "\n",
    "    # Test 6: Test error handling\n",
    "    test_lexer(\"x = 10 @\", \"Error Handling\")\n",
    "\n",
    "    # Test 7: Test inconsistent indentation\n",
    "    test_lexer(\"\"\"def test():\n",
    "    x = 1\n",
    "   y = 2  # Inconsistent indentation\n",
    "\"\"\", \"Inconsistent Indentation\")\n",
    "\n",
    "    # Interactive testing option\n",
    "    do_interactive = input(\"\\nDo you want to run an interactive test? (y/n): \")\n",
    "    if do_interactive.lower() == 'y':\n",
    "        print(\"\\n=== Interactive Lexer Test ===\")\n",
    "        print(\"Enter Python code (type 'exit()' on a new line to finish):\")\n",
    "        \n",
    "        lines = []\n",
    "        while True:\n",
    "            line = input(\"> \")\n",
    "            if line.strip() == \"exit()\":\n",
    "                break\n",
    "            lines.append(line)\n",
    "        \n",
    "        source_code = \"\\n\".join(lines)\n",
    "        test_lexer(source_code, \"Interactive Input\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed207ce",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "##### Keywords: if, else, elif, while, for, in, def, return, True, False, None\n",
    "##### Operators: +, -, *, /, %, **, =, ==, !=, <, >, <=, >=, and, or, not\n",
    "##### Delimiters: (, ), {, }, [, ], ',' , '.', ':', ';'\n",
    "##### Literals: INTEGER, FLOAT, STRING\n",
    "##### Other: IDENTIFIER, INDENT, DEDENT, NEWLINE, EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96572fc",
   "metadata": {},
   "source": [
    "## Token and Error Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910907aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Generator, List, Optional, Tuple\n",
    "\n",
    "class Token:\n",
    "    def __init__(self, type: str, value: str, line: int, column: int):\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "        self.line = line\n",
    "        self.column = column\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Token({self.type}, '{self.value}', line={self.line}, col={self.column})\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "class Error:\n",
    "    def __init__(self, message: str, line: int, column: int):\n",
    "        self.message = message\n",
    "        self.line = line\n",
    "        self.column = column\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Error: {self.message} at line {self.line}, column {self.column}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d04a7",
   "metadata": {},
   "source": [
    "## Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec43f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    # Defining regular expressions for token\n",
    "    TOKEN_SPECS = [\n",
    "        ('COMMENT', r'#.*'),                                  # Comments\n",
    "        ('STRING', r'\\\"([^\\\\\\\"]|\\\\.)*\\\"|\\'([^\\\\\\']|\\\\.)*\\''), # String literals\n",
    "        ('FLOAT', r'\\d+\\.\\d+'),                               # Float literals\n",
    "        ('INTEGER', r'\\d+'),                                  # Integer literals\n",
    "        ('KEYWORD', r'(if|else|elif|while|for|in|def|return|True|False|None)\\b'),  # Keywords\n",
    "        ('IDENTIFIER', r'[a-zA-Z_]\\w*'),                      # Identifiers\n",
    "        # Operators (multi-character ones first)\n",
    "        ('OP_EQ', r'=='),\n",
    "        ('OP_NE', r'!='),\n",
    "        ('OP_LE', r'<='),\n",
    "        ('OP_GE', r'>='),\n",
    "        ('OP_ASSIGN', r'='),\n",
    "        ('OP_PLUS', r'\\+'),\n",
    "        ('OP_MINUS', r'-'),\n",
    "        ('OP_MULT', r'\\*\\*|\\/\\/|\\*|\\/'),  # ** (power), // (floor div), * (mult), / (div)\n",
    "        ('OP_MOD', r'%'),\n",
    "        ('OP_LT', r'<'),\n",
    "        ('OP_GT', r'>'),\n",
    "        # Delimiters\n",
    "        ('LPAREN', r'\\('),\n",
    "        ('RPAREN', r'\\)'),\n",
    "        ('LBRACKET', r'\\['),\n",
    "        ('RBRACKET', r'\\]'),\n",
    "        ('LBRACE', r'\\{'),\n",
    "        ('RBRACE', r'\\}'),\n",
    "        ('COMMA', r','),\n",
    "        ('DOT', r'\\.'),\n",
    "        ('COLON', r':'),\n",
    "        ('SEMICOLON', r';'),\n",
    "        ('NEWLINE', r'\\n'),\n",
    "        ('WHITESPACE', r'[ \\t]+'),                            # Whitespace\n",
    "        # INDENT and DEDENT tokens are not matched by regex but generated based on whitespace\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, source_code: str):\n",
    "        self.source_code = source_code\n",
    "        self.tokens = []\n",
    "        self.errors = []\n",
    "        self.line = 1\n",
    "        self.column = 1\n",
    "        self.indent_levels = [0]  # Start with indent level 0\n",
    "    \n",
    "    def tokenize(self) -> Generator[Token, None, None]:\n",
    "        \"\"\"Tokenize the source code and yield tokens.\"\"\"\n",
    "        # Process the source code line by line to handle indentation properly\n",
    "        lines = self.source_code.split('\\n')\n",
    "        \n",
    "        for line_num, line in enumerate(lines):\n",
    "            self.line = line_num + 1\n",
    "            self.column = 1\n",
    "            \n",
    "            #calculating the amount of leading whitespace (indentation) at the beginning of the current line\n",
    "            if line.strip():  # Non-empty line      #strip() is equivalent of trim() in JS\n",
    "                indent_size = len(line) - len(line.lstrip())    #lstrip() will remove leading spaces in the line i.e. remove any indentation; and the difference in length tells you how much whitespace there was\n",
    "                indent_tokens = self._handle_indentation(indent_size)\n",
    "                for token in indent_tokens:\n",
    "                    yield token\n",
    "            else:   # Skip empty lines but still count them for line numbers\n",
    "                yield Token('NEWLINE', '\\\\n', self.line, self.column)\n",
    "                continue\n",
    "            \n",
    "            # Process the rest of the line\n",
    "            i = indent_size if 'indent_size' in locals() else 0\n",
    "            line_content = line\n",
    "            \n",
    "            while i < len(line_content):    #traversing a line character by character\n",
    "                match = None\n",
    "                \n",
    "                ## Skip spaces and tabs (already handled indentation)\n",
    "                ##if line_content[i].isspace():   #isspace() checks if the entire line is whitespace or not; here it checks whether a single character is whitespace or not since its applied on line_content[i]\n",
    "                ##    i += 1\n",
    "                ##    self.column += 1\n",
    "                ##    continue\n",
    "                \n",
    "                # Try to match each token pattern\n",
    "                for token_type, pattern in self.TOKEN_SPECS:\n",
    "                    regex = re.compile(pattern) #compiling the pattern into a regex so that we can use it to find tokens in the line\n",
    "                    match = regex.match(line_content, i)    #match() will check if the \"starting\" of the string matches the given regex or not, line_content gives the line whose starting it has to compare with the regex with i telling from which point in the line to assume as thhe starting of the line\n",
    "                    #if a match is found, 'match' will contain an object with info about the found match (like start and end, its value and so on), otherwise it'll contain \"none\"\n",
    "                    \n",
    "                    if match:\n",
    "                        value = match.group(0)  #group will give the value of the match object\n",
    "                        \n",
    "                        if token_type == 'WHITESPACE':\n",
    "                            #whitespace is not yielded becuz parser receives stream of tokens without space and doesnt care about space\n",
    "                            # Just update column and continue\n",
    "                            self.column += len(value)\n",
    "                            i += len(value)\n",
    "                            continue\n",
    "                        elif token_type == 'COMMENT':\n",
    "                            # Ignore comments\n",
    "                            i += len(value)\n",
    "                            self.column += len(value)\n",
    "                            break   # Break out of the current character processing loop after handling comments\n",
    "                        else:\n",
    "                            # For all other tokens\n",
    "                            token = Token(token_type, value, self.line, self.column)\n",
    "                            yield token\n",
    "                        \n",
    "                        i += len(value)\n",
    "                        self.column += len(value)\n",
    "                        break\n",
    "                \n",
    "                if not match:\n",
    "                    # No token matched, raise an error\n",
    "                    error_msg = f\"Invalid character: '{line_content[i]}'\"\n",
    "                    error = Error(error_msg, self.line, self.column)\n",
    "                    self.errors.append(error)\n",
    "                    print(error)  # Print the error but continue\n",
    "                    i += 1\n",
    "                    self.column += 1\n",
    "            \n",
    "            # Add NEWLINE at the end of each line except the last one\n",
    "            if line_num < len(lines) - 1 or self.source_code.endswith('\\n'):\n",
    "                yield Token('NEWLINE', '\\\\n', self.line, self.column)\n",
    "        \n",
    "        # Output any pending dedents at the end of the file\n",
    "        #end of file means all indented blocks have been dedented so pop all elements of the indent_levels stack\n",
    "        while len(self.indent_levels) > 1:\n",
    "            self.indent_levels.pop()    \n",
    "            yield Token('DEDENT', '', self.line, self.column)\n",
    "        \n",
    "        # End of file token\n",
    "        yield Token('EOF', '', self.line, self.column)\n",
    "    \n",
    "    def _handle_indentation(self, indent_size: int) -> List[Token]:\n",
    "        \"\"\"Handle Python's indentation-based block structure. Returns a list of INDENT or DEDENT tokens as needed.\"\"\"\n",
    "        tokens = []\n",
    "        previous_line_indent = self.indent_levels[-1]\n",
    "        \n",
    "        if indent_size > previous_line_indent:\n",
    "            # This is an indentation (start of a new block)\n",
    "            self.indent_levels.append(indent_size)  #when a new block is recognized through indentation its indentation level is pushed in the stack so that w ecan later check whether that block was dedented properly or not\n",
    "            tokens.append(Token('INDENT', ' ' * (indent_size - previous_line_indent), self.line, 1))\n",
    "        \n",
    "        elif indent_size < previous_line_indent:\n",
    "            # This is a dedentation (end of one or more blocks)\n",
    "            while self.indent_levels and indent_size < self.indent_levels[-1]: # ensuring that the latest code block is being dedented\n",
    "                self.indent_levels.pop()\n",
    "                tokens.append(Token('DEDENT', '', self.line, 1))\n",
    "            \n",
    "            if indent_size != self.indent_levels[-1]:\n",
    "                # Invalid indentation\n",
    "                error_msg = f\"Inconsistent indentation\"\n",
    "                error = Error(error_msg, self.line, 1)\n",
    "                self.errors.append(error)\n",
    "                print(error)  # Print the error but continue\n",
    "                \n",
    "                \n",
    "                # and what about handling indent_size == self.indent_levels[-1]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b0182e",
   "metadata": {},
   "source": [
    "## Test Script for Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c75670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Basic Assignment ===\n",
      "Source code:\n",
      "x = 10\n",
      "\n",
      "Tokens:\n",
      "Token(IDENTIFIER, 'x', line=1, col=1)\n",
      "Token(OP_ASSIGN, '=', line=1, col=3)\n",
      "Token(INTEGER, '10', line=1, col=5)\n",
      "Token(EOF, '', line=1, col=7)\n",
      "\n",
      "Total tokens: 4\n",
      "\n",
      "=== Testing Function Definition ===\n",
      "Source code:\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "Tokens:\n",
      "Token(KEYWORD, 'def', line=1, col=1)\n",
      "Token(IDENTIFIER, 'add', line=1, col=5)\n",
      "Token(LPAREN, '(', line=1, col=8)\n",
      "Token(IDENTIFIER, 'a', line=1, col=9)\n",
      "Token(COMMA, ',', line=1, col=10)\n",
      "Token(IDENTIFIER, 'b', line=1, col=12)\n",
      "Token(RPAREN, ')', line=1, col=13)\n",
      "Token(COLON, ':', line=1, col=14)\n",
      "Token(NEWLINE, '\\n', line=1, col=15)\n",
      "Token(INDENT, '    ', line=2, col=1)\n",
      "Token(KEYWORD, 'return', line=2, col=1)\n",
      "Token(IDENTIFIER, 'a', line=2, col=8)\n",
      "Token(OP_PLUS, '+', line=2, col=10)\n",
      "Token(IDENTIFIER, 'b', line=2, col=12)\n",
      "Token(DEDENT, '', line=2, col=13)\n",
      "Token(EOF, '', line=2, col=13)\n",
      "\n",
      "Total tokens: 16\n",
      "\n",
      "=== Testing If Statement ===\n",
      "Source code:\n",
      "if x > 10:\n",
      "    print(\"Greater than 10\")\n",
      "else:\n",
      "    print(\"Less than or equal to 10\")\n",
      "\n",
      "Tokens:\n",
      "Token(KEYWORD, 'if', line=1, col=1)\n",
      "Token(IDENTIFIER, 'x', line=1, col=4)\n",
      "Token(OP_GT, '>', line=1, col=6)\n",
      "Token(INTEGER, '10', line=1, col=8)\n",
      "Token(COLON, ':', line=1, col=10)\n",
      "Token(NEWLINE, '\\n', line=1, col=11)\n",
      "Token(INDENT, '    ', line=2, col=1)\n",
      "Token(IDENTIFIER, 'print', line=2, col=1)\n",
      "Token(LPAREN, '(', line=2, col=6)\n",
      "Token(STRING, '\"Greater than 10\"', line=2, col=7)\n",
      "Token(RPAREN, ')', line=2, col=24)\n",
      "Token(NEWLINE, '\\n', line=2, col=25)\n",
      "Token(DEDENT, '', line=3, col=1)\n",
      "Token(KEYWORD, 'else', line=3, col=1)\n",
      "Token(COLON, ':', line=3, col=5)\n",
      "Token(NEWLINE, '\\n', line=3, col=6)\n",
      "Token(INDENT, '    ', line=4, col=1)\n",
      "Token(IDENTIFIER, 'print', line=4, col=1)\n",
      "Token(LPAREN, '(', line=4, col=6)\n",
      "Token(STRING, '\"Less than or equal to 10\"', line=4, col=7)\n",
      "Token(RPAREN, ')', line=4, col=33)\n",
      "Token(DEDENT, '', line=4, col=34)\n",
      "Token(EOF, '', line=4, col=34)\n",
      "\n",
      "Total tokens: 23\n",
      "\n",
      "=== Testing Literals and Operators ===\n",
      "Source code:\n",
      "# Testing literals\n",
      "x = 42\n",
      "y = 3.14\n",
      "name = \"John\"\n",
      "flag = True\n",
      "result = x + y * 2\n",
      "equal = x == y\n",
      "\n",
      "Tokens:\n",
      "Token(NEWLINE, '\\n', line=1, col=19)\n",
      "Token(IDENTIFIER, 'x', line=2, col=1)\n",
      "Token(OP_ASSIGN, '=', line=2, col=3)\n",
      "Token(INTEGER, '42', line=2, col=5)\n",
      "Token(NEWLINE, '\\n', line=2, col=7)\n",
      "Token(IDENTIFIER, 'y', line=3, col=1)\n",
      "Token(OP_ASSIGN, '=', line=3, col=3)\n",
      "Token(FLOAT, '3.14', line=3, col=5)\n",
      "Token(NEWLINE, '\\n', line=3, col=9)\n",
      "Token(IDENTIFIER, 'name', line=4, col=1)\n",
      "Token(OP_ASSIGN, '=', line=4, col=6)\n",
      "Token(STRING, '\"John\"', line=4, col=8)\n",
      "Token(NEWLINE, '\\n', line=4, col=14)\n",
      "Token(IDENTIFIER, 'flag', line=5, col=1)\n",
      "Token(OP_ASSIGN, '=', line=5, col=6)\n",
      "Token(KEYWORD, 'True', line=5, col=8)\n",
      "Token(NEWLINE, '\\n', line=5, col=12)\n",
      "Token(IDENTIFIER, 'result', line=6, col=1)\n",
      "Token(OP_ASSIGN, '=', line=6, col=8)\n",
      "Token(IDENTIFIER, 'x', line=6, col=10)\n",
      "Token(OP_PLUS, '+', line=6, col=12)\n",
      "Token(IDENTIFIER, 'y', line=6, col=14)\n",
      "Token(OP_MULT, '*', line=6, col=16)\n",
      "Token(INTEGER, '2', line=6, col=18)\n",
      "Token(NEWLINE, '\\n', line=6, col=19)\n",
      "Token(IDENTIFIER, 'equal', line=7, col=1)\n",
      "Token(OP_ASSIGN, '=', line=7, col=7)\n",
      "Token(IDENTIFIER, 'x', line=7, col=9)\n",
      "Token(OP_EQ, '==', line=7, col=11)\n",
      "Token(IDENTIFIER, 'y', line=7, col=14)\n",
      "Token(EOF, '', line=7, col=15)\n",
      "\n",
      "Total tokens: 31\n",
      "\n",
      "=== Testing Loops ===\n",
      "Source code:\n",
      "# Testing loops\n",
      "for i in range(10):\n",
      "    if i % 2 == 0:\n",
      "        print(\"Even\")\n",
      "    else:\n",
      "        print(\"Odd\")\n",
      "\n",
      "# While loop\n",
      "count = 0\n",
      "while count < 5:\n",
      "    count += 1\n",
      "\n",
      "\n",
      "Tokens:\n",
      "Token(NEWLINE, '\\n', line=1, col=16)\n",
      "Token(KEYWORD, 'for', line=2, col=1)\n",
      "Token(IDENTIFIER, 'i', line=2, col=5)\n",
      "Token(KEYWORD, 'in', line=2, col=7)\n",
      "Token(IDENTIFIER, 'range', line=2, col=10)\n",
      "Token(LPAREN, '(', line=2, col=15)\n",
      "Token(INTEGER, '10', line=2, col=16)\n",
      "Token(RPAREN, ')', line=2, col=18)\n",
      "Token(COLON, ':', line=2, col=19)\n",
      "Token(NEWLINE, '\\n', line=2, col=20)\n",
      "Token(INDENT, '    ', line=3, col=1)\n",
      "Token(KEYWORD, 'if', line=3, col=1)\n",
      "Token(IDENTIFIER, 'i', line=3, col=4)\n",
      "Token(OP_MOD, '%', line=3, col=6)\n",
      "Token(INTEGER, '2', line=3, col=8)\n",
      "Token(OP_EQ, '==', line=3, col=10)\n",
      "Token(INTEGER, '0', line=3, col=13)\n",
      "Token(COLON, ':', line=3, col=14)\n",
      "Token(NEWLINE, '\\n', line=3, col=15)\n",
      "Token(INDENT, '    ', line=4, col=1)\n",
      "Token(IDENTIFIER, 'print', line=4, col=1)\n",
      "Token(LPAREN, '(', line=4, col=6)\n",
      "Token(STRING, '\"Even\"', line=4, col=7)\n",
      "Token(RPAREN, ')', line=4, col=13)\n",
      "Token(NEWLINE, '\\n', line=4, col=14)\n",
      "Token(DEDENT, '', line=5, col=1)\n",
      "Token(KEYWORD, 'else', line=5, col=1)\n",
      "Token(COLON, ':', line=5, col=5)\n",
      "Token(NEWLINE, '\\n', line=5, col=6)\n",
      "Token(INDENT, '    ', line=6, col=1)\n",
      "Token(IDENTIFIER, 'print', line=6, col=1)\n",
      "Token(LPAREN, '(', line=6, col=6)\n",
      "Token(STRING, '\"Odd\"', line=6, col=7)\n",
      "Token(RPAREN, ')', line=6, col=12)\n",
      "Token(NEWLINE, '\\n', line=6, col=13)\n",
      "Token(NEWLINE, '\\n', line=7, col=1)\n",
      "Token(DEDENT, '', line=8, col=1)\n",
      "Token(DEDENT, '', line=8, col=1)\n",
      "Token(NEWLINE, '\\n', line=8, col=13)\n",
      "Token(IDENTIFIER, 'count', line=9, col=1)\n",
      "Token(OP_ASSIGN, '=', line=9, col=7)\n",
      "Token(INTEGER, '0', line=9, col=9)\n",
      "Token(NEWLINE, '\\n', line=9, col=10)\n",
      "Token(KEYWORD, 'while', line=10, col=1)\n",
      "Token(IDENTIFIER, 'count', line=10, col=7)\n",
      "Token(OP_LT, '<', line=10, col=13)\n",
      "Token(INTEGER, '5', line=10, col=15)\n",
      "Token(COLON, ':', line=10, col=16)\n",
      "Token(NEWLINE, '\\n', line=10, col=17)\n",
      "Token(INDENT, '    ', line=11, col=1)\n",
      "Token(IDENTIFIER, 'count', line=11, col=1)\n",
      "Token(OP_PLUS, '+', line=11, col=7)\n",
      "Token(OP_ASSIGN, '=', line=11, col=8)\n",
      "Token(INTEGER, '1', line=11, col=10)\n",
      "Token(NEWLINE, '\\n', line=11, col=11)\n",
      "Token(NEWLINE, '\\n', line=12, col=1)\n",
      "Token(DEDENT, '', line=12, col=1)\n",
      "Token(EOF, '', line=12, col=1)\n",
      "\n",
      "Total tokens: 58\n",
      "\n",
      "=== Testing Error Handling ===\n",
      "Source code:\n",
      "x = 10 @\n",
      "\n",
      "Tokens:\n",
      "Token(IDENTIFIER, 'x', line=1, col=1)\n",
      "Token(OP_ASSIGN, '=', line=1, col=3)\n",
      "Token(INTEGER, '10', line=1, col=5)\n",
      "Error: Invalid character: '@' at line 1, column 8\n",
      "Token(EOF, '', line=1, col=9)\n",
      "\n",
      "Total tokens: 4\n",
      "\n",
      "Errors (1):\n",
      "  Error: Invalid character: '@' at line 1, column 8\n",
      "\n",
      "=== Testing Inconsistent Indentation ===\n",
      "Source code:\n",
      "def test():\n",
      "    x = 1\n",
      "   y = 2  # Inconsistent indentation\n",
      "\n",
      "\n",
      "Tokens:\n",
      "Token(KEYWORD, 'def', line=1, col=1)\n",
      "Token(IDENTIFIER, 'test', line=1, col=5)\n",
      "Token(LPAREN, '(', line=1, col=9)\n",
      "Token(RPAREN, ')', line=1, col=10)\n",
      "Token(COLON, ':', line=1, col=11)\n",
      "Token(NEWLINE, '\\n', line=1, col=12)\n",
      "Token(INDENT, '    ', line=2, col=1)\n",
      "Token(IDENTIFIER, 'x', line=2, col=1)\n",
      "Token(OP_ASSIGN, '=', line=2, col=3)\n",
      "Token(INTEGER, '1', line=2, col=5)\n",
      "Token(NEWLINE, '\\n', line=2, col=6)\n",
      "Error: Inconsistent indentation at line 3, column 1\n",
      "Token(DEDENT, '', line=3, col=1)\n",
      "Token(IDENTIFIER, 'y', line=3, col=1)\n",
      "Token(OP_ASSIGN, '=', line=3, col=3)\n",
      "Token(INTEGER, '2', line=3, col=5)\n",
      "Token(NEWLINE, '\\n', line=3, col=34)\n",
      "Token(NEWLINE, '\\n', line=4, col=1)\n",
      "Token(EOF, '', line=4, col=1)\n",
      "\n",
      "Total tokens: 18\n",
      "\n",
      "Errors (1):\n",
      "  Error: Inconsistent indentation at line 3, column 1\n"
     ]
    }
   ],
   "source": [
    "def test_lexer(source_code, test_name=\"\"):\n",
    "    print(f\"\\n=== Testing {test_name} ===\")\n",
    "    print(f\"Source code:\\n{source_code}\")\n",
    "    print(\"\\nTokens:\")\n",
    "    \n",
    "    lexer = Lexer(source_code)\n",
    "    token_count = 0\n",
    "    \n",
    "    try:\n",
    "        for token in lexer.tokenize():\n",
    "            print(token)\n",
    "            token_count += 1\n",
    "        \n",
    "        print(f\"\\nTotal tokens: {token_count}\")\n",
    "        if lexer.errors:\n",
    "            print(f\"\\nErrors ({len(lexer.errors)}):\")\n",
    "            for error in lexer.errors:\n",
    "                print(f\"  {error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Test cases\n",
    "if __name__ == \"__main__\":\n",
    "    # Test 1: Basic variable assignment\n",
    "    test_lexer(\"x = 10\", \"Basic Assignment\")\n",
    "\n",
    "    # Test 2: Simple function definition\n",
    "    test_lexer(\"\"\"def add(a, b):\n",
    "    return a + b\"\"\", \"Function Definition\")\n",
    "\n",
    "    # Test 3: If statement with proper indentation\n",
    "    test_lexer(\"\"\"if x > 10:\n",
    "    print(\"Greater than 10\")\n",
    "else:\n",
    "    print(\"Less than or equal to 10\")\"\"\", \"If Statement\")\n",
    "\n",
    "    # Test 4: Various literals and operators\n",
    "    test_lexer(\"\"\"# Testing literals\n",
    "x = 42\n",
    "y = 3.14\n",
    "name = \"John\"\n",
    "flag = True\n",
    "result = x + y * 2\n",
    "equal = x == y\"\"\", \"Literals and Operators\")\n",
    "\n",
    "    # Test 5: Loops\n",
    "    test_lexer(\"\"\"# Testing loops\n",
    "for i in range(10):\n",
    "    if i % 2 == 0:\n",
    "        print(\"Even\")\n",
    "    else:\n",
    "        print(\"Odd\")\n",
    "\n",
    "# While loop\n",
    "count = 0\n",
    "while count < 5:\n",
    "    count += 1\n",
    "\"\"\", \"Loops\")\n",
    "\n",
    "    # Test 6: Test error handling\n",
    "    test_lexer(\"x = 10 @\", \"Error Handling\")\n",
    "\n",
    "    # Test 7: Test inconsistent indentation\n",
    "    test_lexer(\"\"\"def test():\n",
    "    x = 1\n",
    "   y = 2  # Inconsistent indentation\n",
    "\"\"\", \"Inconsistent Indentation\")\n",
    "\n",
    "    # Interactive testing option\n",
    "    do_interactive = input(\"\\nDo you want to run an interactive test? (y/n): \")\n",
    "    if do_interactive.lower() == 'y':\n",
    "        print(\"\\n=== Interactive Lexer Test ===\")\n",
    "        print(\"Enter Python code (type 'exit()' on a new line to finish):\")\n",
    "        \n",
    "        lines = []\n",
    "        while True:\n",
    "            line = input(\"> \")\n",
    "            if line.strip() == \"exit()\":\n",
    "                break\n",
    "            lines.append(line)\n",
    "        \n",
    "        source_code = \"\\n\".join(lines)\n",
    "        test_lexer(source_code, \"Interactive Input\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452263c9",
   "metadata": {},
   "source": [
    "## ***ABSTRACT SYNTAX TREE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e402a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file is of abstract syntax tree (AST) node definitions.\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "# Base class for all AST nodes ASTNode is the base (parent) class for all other AST node types.\n",
    "#It doesn’t do anything itself, but helps us group all node types together under one type.\n",
    "\n",
    "class ASTNode:\n",
    "    pass\n",
    "\n",
    "# Root node; body is a list of things in the program like function definitions, statements, etc.\n",
    "@dataclass\n",
    "class Program(ASTNode):\n",
    "    body: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "# Statements\n",
    "@dataclass\n",
    "class FunctionDef(ASTNode):\n",
    "    name: str\n",
    "    params: List[str]\n",
    "    body: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class IfStatement(ASTNode):\n",
    "    condition: ASTNode\n",
    "    then_branch: List[ASTNode]\n",
    "    elif_branches: List[tuple[ASTNode, List[ASTNode]]]\n",
    "    else_branch: Optional[List[ASTNode]]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class WhileLoop(ASTNode):\n",
    "    condition: ASTNode\n",
    "    body: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class ForLoop(ASTNode):\n",
    "    var: str\n",
    "    iterable: ASTNode\n",
    "    body: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Return(ASTNode):\n",
    "    value: Optional[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Assignment(ASTNode):\n",
    "    target: str\n",
    "    value: ASTNode\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class ExpressionStatement(ASTNode):\n",
    "    expression: ASTNode\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "# Expressions\n",
    "@dataclass\n",
    "class BinaryOp(ASTNode):\n",
    "    left: ASTNode\n",
    "    operator: str\n",
    "    right: ASTNode\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class UnaryOp(ASTNode):\n",
    "    operator: str\n",
    "    operand: ASTNode\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Call(ASTNode):\n",
    "    func: ASTNode\n",
    "    args: List[ASTNode]\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Identifier(ASTNode):\n",
    "    name: str\n",
    "    line: int\n",
    "    column: int\n",
    "\n",
    "@dataclass\n",
    "class Literal(ASTNode):\n",
    "    value: Union[str, int, float, bool, None]\n",
    "    line: int\n",
    "    column: int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13823b3",
   "metadata": {},
   "source": [
    "## ***AST VISUALIZER***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e2c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ast_visualizer.py\n",
    "\n",
    "from graphviz import Digraph\n",
    "from typing import Union, List\n",
    "def print_ast(node: ASTNode, indent: str = ''):\n",
    "    info = []\n",
    "    if hasattr(node, \"inferred_type\") and node.inferred_type:\n",
    "        info.append(f\"type={node.inferred_type}\")\n",
    "    if hasattr(node, \"constant_value\") and node.constant_value is not None:\n",
    "        info.append(f\"const={node.constant_value}\")\n",
    "    info_str = f\" [{', '.join(info)}]\" if info else \"\"\n",
    "\n",
    "    if isinstance(node, Program):\n",
    "        print(indent + \"Program\" + info_str)\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"  \")\n",
    "    elif isinstance(node, FunctionDef):\n",
    "        info = []\n",
    "        if hasattr(node, \"return_type\") and node.return_type:\n",
    "            info.append(f\"return_type={node.return_type}\")\n",
    "        info_str = f\" [{', '.join(info)}]\" if info else \"\"\n",
    "        print(indent + f\"FunctionDef({node.name})\" + info_str)\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"  \")\n",
    "    elif isinstance(node, IfStatement):\n",
    "        print(indent + \"IfStatement\" + info_str)\n",
    "        print(indent + \"  Condition:\")\n",
    "        print_ast(node.condition, indent + \"    \")\n",
    "        print(indent + \"  Then:\")\n",
    "        for stmt in node.then_branch:\n",
    "            print_ast(stmt, indent + \"    \")\n",
    "        for cond, branch in node.elif_branches:\n",
    "            print(indent + \"  Elif:\")\n",
    "            print_ast(cond, indent + \"    \")\n",
    "            for stmt in branch:\n",
    "                print_ast(stmt, indent + \"      \")\n",
    "        if node.else_branch:\n",
    "            print(indent + \"  Else:\")\n",
    "            for stmt in node.else_branch:\n",
    "                print_ast(stmt, indent + \"    \")\n",
    "    elif isinstance(node, WhileLoop):\n",
    "        print(indent + \"WhileLoop\" + info_str)\n",
    "        print(indent + \"  Condition:\")\n",
    "        print_ast(node.condition, indent + \"    \")\n",
    "        print(indent + \"  Body:\")\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"    \")\n",
    "    elif isinstance(node, ForLoop):\n",
    "        print(indent + f\"ForLoop(var={node.var})\" + info_str)\n",
    "        print(indent + \"  Iterable:\")\n",
    "        print_ast(node.iterable, indent + \"    \")\n",
    "        print(indent + \"  Body:\")\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"    \")\n",
    "    elif isinstance(node, Return):\n",
    "        print(indent + \"Return\" + info_str)\n",
    "        if node.value:\n",
    "            print_ast(node.value, indent + \"  \")\n",
    "    elif isinstance(node, Assignment):\n",
    "        print(indent + f\"Assignment(target={node.target})\" + info_str)\n",
    "        print_ast(node.value, indent + \"  \")\n",
    "    elif isinstance(node, ExpressionStatement):\n",
    "        print(indent + \"ExpressionStatement\" + info_str)\n",
    "        print_ast(node.expression, indent + \"  \")\n",
    "    elif isinstance(node, BinaryOp):\n",
    "        print(indent + f\"BinaryOp({node.operator})\" + info_str)\n",
    "        print_ast(node.left, indent + \"  \")\n",
    "        print_ast(node.right, indent + \"  \")\n",
    "    elif isinstance(node, UnaryOp):\n",
    "        print(indent + f\"UnaryOp({node.operator})\" + info_str)\n",
    "        print_ast(node.operand, indent + \"  \")\n",
    "    elif isinstance(node, Call):\n",
    "        print(indent + \"Call\" + info_str)\n",
    "        print_ast(node.func, indent + \"  \")\n",
    "        for arg in node.args:\n",
    "            print_ast(arg, indent + \"    \")\n",
    "    elif isinstance(node, Identifier):\n",
    "        print(indent + f\"Identifier({node.name})\" + info_str)\n",
    "    elif isinstance(node, Literal):\n",
    "        print(indent + f\"Literal({repr(node.value)})\" + info_str)\n",
    "    else:\n",
    "        print(indent + f\"UnknownNode({node})\" + info_str)\n",
    "        \n",
    "# Optional: Graphviz visualizer\n",
    "def _build_graph(node: ASTNode, dot: Digraph, parent: str = None, counter=[0]):\n",
    "    node_id = f\"node{counter[0]}\"\n",
    "    counter[0] += 1\n",
    "\n",
    "    # Build label with annotations\n",
    "    label = type(node).__name__\n",
    "    # Add main info\n",
    "    if isinstance(node, Identifier):\n",
    "        label += f\"({node.name})\"\n",
    "    elif isinstance(node, Literal):\n",
    "        label += f\"({repr(node.value)})\"\n",
    "    elif isinstance(node, Assignment):\n",
    "        label += f\"({node.target})\"\n",
    "    elif isinstance(node, BinaryOp):\n",
    "        label += f\"({node.operator})\"\n",
    "    elif isinstance(node, UnaryOp):\n",
    "        label += f\"({node.operator})\"\n",
    "    elif isinstance(node, FunctionDef):\n",
    "        label += f\"({node.name})\"\n",
    "        if hasattr(node, \"return_type\") and node.return_type:\n",
    "            label += f\"\\\\nreturn_type={node.return_type}\"\n",
    "    elif isinstance(node, ForLoop):\n",
    "        label += f\"({node.var})\"\n",
    "\n",
    "    # Add annotation info\n",
    "    info = []\n",
    "    if hasattr(node, \"inferred_type\") and node.inferred_type:\n",
    "        info.append(f\"type={node.inferred_type}\")\n",
    "    if hasattr(node, \"constant_value\") and node.constant_value is not None:\n",
    "        info.append(f\"const={node.constant_value}\")\n",
    "    if info:\n",
    "        label += \"\\\\n\" + \", \".join(info)\n",
    "\n",
    "    dot.node(node_id, label)\n",
    "\n",
    "    if parent:\n",
    "        dot.edge(parent, node_id)\n",
    "\n",
    "    for field in getattr(node, '__dataclass_fields__', {}):\n",
    "        child = getattr(node, field)\n",
    "        if isinstance(child, ASTNode):\n",
    "            _build_graph(child, dot, node_id, counter)\n",
    "        elif isinstance(child, list):\n",
    "            for item in child:\n",
    "                if isinstance(item, ASTNode):\n",
    "                    _build_graph(item, dot, node_id, counter)\n",
    "        elif isinstance(child, tuple):\n",
    "            for item in child:\n",
    "                if isinstance(item, ASTNode):\n",
    "                    _build_graph(item, dot, node_id, counter)\n",
    "\n",
    "    return dot\n",
    "\n",
    "def visualize_ast(node: ASTNode):\n",
    "    dot = Digraph(comment=\"AST\")\n",
    "    _build_graph(node, dot)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104272b6",
   "metadata": {},
   "source": [
    "## ***PARSER***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e0823d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom error class for parser errors\n",
    "class ParserError(Exception):\n",
    "    pass\n",
    "\n",
    "# Parser class converts tokens into an AST\n",
    "class Parser:\n",
    "    def __init__(self, lexer: Lexer):\n",
    "        self.tokens = list(lexer.tokenize())  # Convert lexer generator into list of tokens\n",
    "        self.pos = 0  # Current position in token list\n",
    "        self.current_token = self.tokens[self.pos]  # Currently looked-at token\n",
    "\n",
    "    def error(self, msg: str):\n",
    "        # Raise a ParserError with current token's position\n",
    "        raise ParserError(f\"{msg} at line {self.current_token.line}, column {self.current_token.column}\")\n",
    "    \n",
    "    def skip_newlines(self):\n",
    "        # Ignore NEWLINE tokens before/after blocks or statements\n",
    "        while self.current_token.type == 'NEWLINE':\n",
    "            self.advance()\n",
    "\n",
    "    def advance(self):\n",
    "        # Move to the next token\n",
    "        self.pos += 1\n",
    "        if self.pos < len(self.tokens):\n",
    "            self.current_token = self.tokens[self.pos]\n",
    "\n",
    "    def expect(self, token_type: str):\n",
    "        # Ensure the current token is of the expected type, or throw error\n",
    "        if self.current_token.type == token_type:\n",
    "            self.advance()\n",
    "        else:\n",
    "            self.error(f\"Expected token {token_type}, got {self.current_token.type}\")\n",
    "\n",
    "    def match(self, token_type: str):\n",
    "        # Match a token and advance if matched\n",
    "        if self.current_token.type == token_type:\n",
    "            self.advance()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def parse(self) -> Program:\n",
    "        # Parse a full program (list of statements)\n",
    "        body = []\n",
    "        self.skip_newlines()\n",
    "        while self.current_token.type != 'EOF':\n",
    "            stmt = self.parse_statement()\n",
    "            if stmt:\n",
    "                body.append(stmt)\n",
    "            self.skip_newlines()\n",
    "        return Program(body=body, line=0, column=0) \n",
    "\n",
    "    def parse_statement(self) -> ASTNode:\n",
    "        # Decide which type of statement to parse\n",
    "        if self.current_token.type == 'KEYWORD':\n",
    "            if self.current_token.value == 'def':\n",
    "                return self.parse_function_def()\n",
    "            elif self.current_token.value == 'return':\n",
    "                return self.parse_return()\n",
    "            elif self.current_token.value == 'if':\n",
    "                return self.parse_if()\n",
    "            elif self.current_token.value == 'while':\n",
    "                return self.parse_while()\n",
    "            elif self.current_token.value == 'for':\n",
    "                return self.parse_for()\n",
    "            \n",
    "        #######COULDNT WORK DURING SEMANTIC ANALYSIS SO CHNAGED THE LOGIC HERE##########\n",
    "        # If not a keyword, it's either an assignment or expression\n",
    "        # expr = self.parse_expression()\n",
    "        # if isinstance(expr, Identifier) and self.match('OP_ASSIGN'):\n",
    "        #     value = self.parse_expression()\n",
    "        #     return Assignment(target=expr.name, value=value)\n",
    "        # return ExpressionStatement(expr)\n",
    "        ################################################################################\n",
    "        \n",
    "        # If not a keyword, it could be assignment or expression\n",
    "        if self.current_token.type == 'IDENTIFIER':\n",
    "            # Lookahead to check for assignment\n",
    "            next_token = self.tokens[self.pos + 1] if self.pos + 1 < len(self.tokens) else None\n",
    "            if next_token and next_token.type == 'OP_ASSIGN':\n",
    "                assign_token = self.current_token\n",
    "                identifier = self.current_token.value\n",
    "                self.advance()  # consume identifier\n",
    "                self.advance()  # consume '='\n",
    "                value = self.parse_expression()\n",
    "                return Assignment(target=identifier, value=value, line=assign_token.line, column=assign_token.column)\n",
    "\n",
    "        # Otherwise, treat it as an expression statement\n",
    "        expr_token = self.current_token\n",
    "        expr = self.parse_expression()\n",
    "        return ExpressionStatement(expression=expr, line=expr_token.line, column=expr_token.column)\n",
    "\n",
    "\n",
    "    def parse_function_def(self) -> FunctionDef:\n",
    "        # Parse function definition: def name(params):\\n  <body>\n",
    "        def_token = self.current_token\n",
    "        self.expect('KEYWORD')  # 'def'\n",
    "        if self.current_token.type != 'IDENTIFIER':\n",
    "            self.error(\"Expected function name\")\n",
    "        name = self.current_token.value\n",
    "        self.advance()\n",
    "        self.expect('LPAREN')\n",
    "\n",
    "        # Parse parameter list\n",
    "        params = []\n",
    "        if self.current_token.type != 'RPAREN':\n",
    "            while True:\n",
    "                if self.current_token.type != 'IDENTIFIER':\n",
    "                    self.error(\"Expected parameter name\")\n",
    "                params.append(self.current_token.value)\n",
    "                self.advance()\n",
    "                if not self.match('COMMA'):\n",
    "                    break\n",
    "\n",
    "        self.expect('RPAREN')\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        body = self.parse_block()\n",
    "        return FunctionDef(name=name, params=params, body=body, line=def_token.line, column=def_token.column)\n",
    "\n",
    "    def parse_return(self) -> Return:\n",
    "        token = self.current_token\n",
    "        # Parse return statement\n",
    "        self.expect('KEYWORD')  # 'return'\n",
    "        if self.current_token.type == 'NEWLINE':\n",
    "            return Return(value=None, line=token.line, column=token.column)\n",
    "        value = self.parse_expression()\n",
    "        return Return(value=value, line=token.line, column=token.column)\n",
    "\n",
    "    def parse_if(self) -> IfStatement:\n",
    "        if_token = self.current_token\n",
    "        # Parse if-elif-else statement\n",
    "        self.expect('KEYWORD')  # 'if'\n",
    "        condition = self.parse_expression()\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        then_branch = self.parse_block()\n",
    "\n",
    "        elif_branches = []\n",
    "        # Handle optional elif blocks\n",
    "        while self.current_token.type == 'KEYWORD' and self.current_token.value == 'elif':\n",
    "            self.advance()\n",
    "            cond = self.parse_expression()\n",
    "            self.expect('COLON')\n",
    "            self.expect('NEWLINE')\n",
    "            self.expect('INDENT')\n",
    "            body = self.parse_block()\n",
    "            elif_branches.append((cond, body))\n",
    "\n",
    "        else_branch = None\n",
    "        # Handle optional else block\n",
    "        if self.current_token.type == 'KEYWORD' and self.current_token.value == 'else':\n",
    "            self.advance()\n",
    "            self.expect('COLON')\n",
    "            self.expect('NEWLINE')\n",
    "            self.expect('INDENT')\n",
    "            else_branch = self.parse_block()\n",
    "\n",
    "        return IfStatement(condition, then_branch, elif_branches, else_branch, line=if_token.line, column=if_token.column)\n",
    "\n",
    "    def parse_while(self) -> WhileLoop:\n",
    "        while_token = self.current_token\n",
    "        # Parse while loop\n",
    "        self.expect('KEYWORD')  # 'while'\n",
    "        condition = self.parse_expression()\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        body = self.parse_block()\n",
    "        return WhileLoop(condition=condition, body=body, line=while_token.line, column=while_token.column)\n",
    "\n",
    "    def parse_for(self) -> ForLoop:\n",
    "        for_token = self.current_token\n",
    "        # Parse for loop: for x in iterable:\n",
    "        self.expect('KEYWORD')  # 'for'\n",
    "        if self.current_token.type != 'IDENTIFIER':\n",
    "            self.error(\"Expected variable name\")\n",
    "        var = self.current_token.value\n",
    "        self.advance()\n",
    "        self.expect('KEYWORD')  # 'in'\n",
    "        iterable = self.parse_expression()\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        body = self.parse_block()\n",
    "        return ForLoop(var=var, iterable=iterable, body=body, line=for_token.line, column=for_token.column)\n",
    "\n",
    "    def parse_block(self) -> List[ASTNode]:\n",
    "        # Parse an indented block of statements\n",
    "        body = []\n",
    "        self.skip_newlines()\n",
    "        while self.current_token.type not in ('DEDENT', 'EOF'):\n",
    "            stmt = self.parse_statement()\n",
    "            if stmt:\n",
    "                body.append(stmt)\n",
    "            self.skip_newlines()\n",
    "        self.expect('DEDENT')\n",
    "        return body\n",
    "\n",
    "    def parse_expression(self, precedence=0) -> ASTNode:\n",
    "        # Parse binary expressions with precedence (e.g., 1 + 2 * 3)\n",
    "        left = self.parse_primary()\n",
    "        while self.is_operator(self.current_token) and self.get_precedence(self.current_token) >= precedence:\n",
    "            op_token = self.current_token\n",
    "            self.advance()\n",
    "            right = self.parse_expression(self.get_precedence(op_token) + 1)\n",
    "            left = BinaryOp(left=left, operator=op_token.value, right=right, line=op_token.line, column=op_token.column)\n",
    "        return left\n",
    "\n",
    "    def parse_primary(self) -> ASTNode:\n",
    "        # Parse literals, variables, function calls, unary ops, and parenthesis\n",
    "        token = self.current_token\n",
    "        if token.type == 'INTEGER':\n",
    "            self.advance()\n",
    "            return Literal(value=int(token.value), line=token.line, column=token.column)\n",
    "        elif token.type == 'FLOAT':\n",
    "            self.advance()\n",
    "            return Literal(value=float(token.value), line=token.line, column=token.column)\n",
    "        elif token.type == 'STRING':\n",
    "            self.advance()\n",
    "            return Literal(value=token.value[1:-1], line=token.line, column=token.column)\n",
    "        elif token.type == 'KEYWORD':\n",
    "            if token.value in ('True', 'False', 'None'):\n",
    "                self.advance()\n",
    "                val = {'True': True, 'False': False, 'None': None}[token.value]\n",
    "                return Literal(value=val, line=token.line, column=token.column)\n",
    "        elif token.type == 'IDENTIFIER':\n",
    "            self.advance()\n",
    "            if self.match('LPAREN'):  # Function call\n",
    "                args = []\n",
    "                if self.current_token.type != 'RPAREN':\n",
    "                    while True:\n",
    "                        args.append(self.parse_expression())\n",
    "                        if not self.match('COMMA'):\n",
    "                            break\n",
    "                self.expect('RPAREN')\n",
    "                return Call(func=Identifier(name=token.value, line=token.line, column=token.column), args=args, line=token.line, column=token.column)\n",
    "            return Identifier(name=token.value, line=token.line, column=token.column)\n",
    "        elif token.type == 'OP_MINUS':\n",
    "            self.advance()\n",
    "            operand = self.parse_primary()\n",
    "            return UnaryOp(operator='-', operand=operand)\n",
    "        elif token.type == 'LPAREN':\n",
    "            self.advance()\n",
    "            expr = self.parse_expression()\n",
    "            self.expect('RPAREN')\n",
    "            return expr\n",
    "        else:\n",
    "            self.error(f\"Unexpected token {token}\")\n",
    "\n",
    "    def is_operator(self, token: Token) -> bool:\n",
    "        # Check if token is an operator\n",
    "        return token.type.startswith('OP_')\n",
    "\n",
    "    def get_precedence(self, token: Token) -> int:\n",
    "        # Define operator precedence levels (higher = tighter binding)\n",
    "        precedence = {\n",
    "            'OP_OR': 1,\n",
    "            'OP_AND': 2,\n",
    "            'OP_EQ': 3, 'OP_NE': 3,\n",
    "            'OP_LT': 4, 'OP_LE': 4, 'OP_GT': 4, 'OP_GE': 4,\n",
    "            'OP_PLUS': 5, 'OP_MINUS': 5,\n",
    "            'OP_MULT': 6, 'OP_MOD': 6,\n",
    "            'OP_ASSIGN': 0,  # Assignment is handled separately\n",
    "        }\n",
    "        return precedence.get(token.type, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb48a8bc",
   "metadata": {},
   "source": [
    "## Testing upto parser and AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd7c4e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program\n",
      "  FunctionDef(factorial)\n",
      "    IfStatement\n",
      "      Condition:\n",
      "        BinaryOp(==)\n",
      "          Identifier(n)\n",
      "          Literal(0)\n",
      "      Then:\n",
      "        Return\n",
      "          Literal(1)\n",
      "      Else:\n",
      "        Return\n",
      "          BinaryOp(*)\n",
      "            Identifier(n)\n",
      "            Call\n",
      "              Identifier(factorial)\n",
      "                BinaryOp(-)\n",
      "                  Identifier(n)\n",
      "                  Literal(1)\n",
      "  FunctionDef(is_even)\n",
      "    Return\n",
      "      BinaryOp(==)\n",
      "        BinaryOp(%)\n",
      "          Identifier(num)\n",
      "          Literal(2)\n",
      "        Literal(0)\n",
      "  Assignment(target=x)\n",
      "    Literal(5)\n",
      "  Assignment(target=fact)\n",
      "    Call\n",
      "      Identifier(factorial)\n",
      "        Identifier(x)\n",
      "  IfStatement\n",
      "    Condition:\n",
      "      Call\n",
      "        Identifier(is_even)\n",
      "          Identifier(fact)\n",
      "    Then:\n",
      "      ExpressionStatement\n",
      "        Call\n",
      "          Identifier(print)\n",
      "            Literal('Even factorial')\n",
      "    Else:\n",
      "      ExpressionStatement\n",
      "        Call\n",
      "          Identifier(print)\n",
      "            Literal('Odd factorial')\n",
      "  ForLoop(var=i)\n",
      "    Iterable:\n",
      "      Call\n",
      "        Identifier(range)\n",
      "          Literal(3)\n",
      "    Body:\n",
      "      Assignment(target=result)\n",
      "        Call\n",
      "          Identifier(factorial)\n",
      "            Identifier(i)\n",
      "      ExpressionStatement\n",
      "        Call\n",
      "          Identifier(print)\n",
      "            Identifier(result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ast_tree.png'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# code = '''\n",
    "# def add(x, y):\n",
    "#     return x + y\n",
    "\n",
    "# a = add(3, 5)\n",
    "# '''\n",
    "\n",
    "# code = \"\"\"\n",
    "# def foo(x):\n",
    "#     if x > 0:\n",
    "#         return x\n",
    "#     else:\n",
    "#         return -x\n",
    "# \"\"\"\n",
    "\n",
    "code = '''\n",
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n - 1)\n",
    "\n",
    "def is_even(num):\n",
    "    return num % 2 == 0\n",
    "\n",
    "x = 5\n",
    "fact = factorial(x)\n",
    "\n",
    "if is_even(fact):\n",
    "    print(\"Even factorial\")\n",
    "else:\n",
    "    print(\"Odd factorial\")\n",
    "\n",
    "for i in range(3):\n",
    "    result = factorial(i)\n",
    "    print(result)\n",
    "'''\n",
    "\n",
    "\n",
    "lexer = Lexer(code)\n",
    "parser = Parser(lexer)\n",
    "ast = parser.parse()\n",
    "\n",
    "#Console view\n",
    "print_ast(ast)\n",
    "\n",
    "\n",
    "#graph\n",
    "dot = visualize_ast(ast)\n",
    "dot.render('ast_tree', view=True, format='png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3c0576",
   "metadata": {},
   "source": [
    "## ***SEMANTIC ANALYSIS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom exception class used to indicate semantic errors in the code being analyzed\n",
    "class SemanticError(Exception):\n",
    "    pass\n",
    "\n",
    "# Set of built-in function names that user-defined functions/variables should not override\n",
    "BUILTINS = {'print', 'len', 'range', 'input', 'int', 'float', 'str', 'bool'}  # Extend as needed\n",
    "\n",
    "# Scope class manages variables/functions within a block or function, supports nested scoping\n",
    "class Scope:\n",
    "    def __init__(self, parent=None):\n",
    "        self.parent = parent             # Reference to the parent scope (for nested scopes)\n",
    "        self.variables = {}              # declared variable names in current scope\n",
    "        self.functions = {}              # Dictionary of declared functions: {func_name: param_list}\n",
    "        self.in_function = False         # Flag to check if this scope is inside a function\n",
    "\n",
    "    # Declare a variable in the current scope; return False if it already exists\n",
    "    def declare_var(self, name, var_type=None):\n",
    "        if name in self.variables:\n",
    "            return False  # Duplicate in same scope\n",
    "        self.variables[name] = {\"type\": var_type}\n",
    "        return True\n",
    "\n",
    "    # Check whether a variable is declared in current or any parent scope\n",
    "    def is_var_declared(self, name):\n",
    "        if name in self.variables:\n",
    "            return True\n",
    "        if self.parent:\n",
    "            return self.parent.is_var_declared(name)\n",
    "        return False\n",
    "\n",
    "    # Declare a function with a list of parameters; returns False if already declared\n",
    "    def declare_func(self, name, func_def):\n",
    "        if name in self.functions:\n",
    "            return False\n",
    "        self.functions[name] = func_def\n",
    "        return True\n",
    "\n",
    "    # Recursively retrieve the parameter list of a declared function\n",
    "    def get_func(self, name):\n",
    "        if name in self.functions:\n",
    "            return self.functions[name]\n",
    "        if self.parent:\n",
    "            return self.parent.get_func(name)\n",
    "        return None\n",
    "\n",
    "    # Check if a function is declared by trying to get it\n",
    "    def is_func_declared(self, name):\n",
    "        return self.get_func(name) is not None\n",
    "    \n",
    "    #to show symbol table \n",
    "    def print_symbols(self, indent=0):\n",
    "        prefix = \"  \" * indent\n",
    "        print(f\"{prefix}Scope:\")\n",
    "        if self.variables:\n",
    "            for name, info in self.variables.items():\n",
    "                print(f\"{prefix}  Variable: {name}, Type: {info.get('type', 'unknown')}\")\n",
    "        if self.functions:\n",
    "            for fname, func_def in self.functions.items():\n",
    "                param_strs = [f\"{p}: {t}\" for p, t in func_def.param_types.items()]\n",
    "                return_type = getattr(func_def, 'return_type', None)\n",
    "                return_type_str = f\", Return: {return_type}\" if return_type else \"\"\n",
    "                print(f\"{prefix}  Function: {fname}({', '.join(param_strs)}){return_type_str}\")\n",
    "        if self.parent:\n",
    "            self.parent.print_symbols(indent + 1)\n",
    "\n",
    "# SemanticAnalyzer walks through the AST to validate semantics and detect errors\n",
    "class SemanticAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.global_scope = Scope()        # Top-level scope for global variables/functions\n",
    "        self.current_scope = self.global_scope  # Pointer to current active scope\n",
    "        self.errors = []                   # List to store error messages\n",
    "\n",
    "\n",
    "    # Report a semantic error with line, column, and node context\n",
    "    def error(self, msg, node):\n",
    "        line = getattr(node, 'line', '?')\n",
    "        col = getattr(node, 'column', '?')\n",
    "        node_name = getattr(node, 'name', type(node).__name__)\n",
    "        self.errors.append(f\"[Line {line}, Column {col}] Error at '{node_name}': {msg}\")\n",
    "        # self.errors.append(formatted)\n",
    "\n",
    "    # Entry point to start analyzing the AST\n",
    "    def analyze(self, node):\n",
    "        self.visit(node)  # Start visiting from the root node\n",
    "        if self.errors:\n",
    "            raise SemanticError(\"\\n\".join(self.errors))\n",
    "\n",
    "    # Dispatch method that calls the appropriate visit_* method based on node type\n",
    "    def visit(self, node):\n",
    "        method = 'visit_' + type(node).__name__\n",
    "        visitor = getattr(self, method, self.generic_visit)\n",
    "        return visitor(node)\n",
    "\n",
    "    # Generic visitor for composite nodes (e.g., containing other nodes in fields/lists/tuples)\n",
    "    def generic_visit(self, node):\n",
    "        for field in getattr(node, '__dataclass_fields__', {}):\n",
    "            value = getattr(node, field)\n",
    "            if isinstance(value, ASTNode):\n",
    "                self.visit(value)\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, ASTNode):\n",
    "                        self.visit(item)\n",
    "            elif isinstance(value, tuple):\n",
    "                for item in value:\n",
    "                    if isinstance(item, ASTNode):\n",
    "                        self.visit(item)\n",
    "\n",
    "    # Visit a program node which consists of multiple statements\n",
    "    def visit_Program(self, node: Program):\n",
    "        for stmt in node.body:\n",
    "            self.visit(stmt)\n",
    "\n",
    "    # Visit a function definition and validate function name, parameters, and body\n",
    "    def visit_FunctionDef(self, node: FunctionDef):\n",
    "        if not self.current_scope.declare_func(node.name, node):\n",
    "            self.error(f\"Duplicate function definition '{node.name}'\", node)\n",
    "        func_scope = Scope(parent=self.current_scope)\n",
    "        func_scope.in_function = True\n",
    "\n",
    "        node.param_types = {}\n",
    "        for param in node.params:\n",
    "            p_name = param if isinstance(param, str) else param[0]\n",
    "            p_type = None if isinstance(param, str) else param[1]\n",
    "            func_scope.declare_var(p_name, p_type)\n",
    "            node.param_types[p_name] = p_type\n",
    "\n",
    "        prev_scope = self.current_scope\n",
    "        self.current_scope = func_scope\n",
    "\n",
    "        return_types = set()\n",
    "        for stmt in node.body:\n",
    "            self.visit(stmt)\n",
    "            if isinstance(stmt, Return) and hasattr(stmt, 'inferred_type') and stmt.inferred_type is not None:\n",
    "                return_types.add(stmt.inferred_type)\n",
    "\n",
    "        self.current_scope = prev_scope\n",
    "        node.return_type = return_types.pop() if len(return_types) == 1 else 'multiple' if return_types else 'None'\n",
    "\n",
    "    # Visit an assignment: validate left-hand name, check for name conflicts, and analyze RHS\n",
    "    def visit_Assignment(self, node: Assignment):\n",
    "        if node.target in BUILTINS:\n",
    "            self.error(f\"Cannot assign to built-in name '{node.target}'\", node)\n",
    "        if self.current_scope.is_func_declared(node.target):\n",
    "            self.error(f\"Cannot assign to function name '{node.target}'\", node)\n",
    "        self.visit(node.value)\n",
    "        var_type = getattr(node.value, 'inferred_type', None)\n",
    "        node.inferred_type = var_type\n",
    "        self.current_scope.declare_var(node.target, var_type)\n",
    "\n",
    "    # Visit an identifier node to check if it was declared\n",
    "    def visit_Identifier(self, node: Identifier):\n",
    "        scope = self.current_scope\n",
    "        while scope:\n",
    "            if node.name in scope.variables:\n",
    "                node.inferred_type = scope.variables[node.name][\"type\"]\n",
    "                return\n",
    "            scope = scope.parent\n",
    "        if self.current_scope.is_func_declared(node.name):\n",
    "            self.error(f\"Function '{node.name}' used as a variable\", node)\n",
    "        else:\n",
    "            self.error(f\"Undeclared variable '{node.name}'\", node)\n",
    "\n",
    "    # Visit a function call and validate function existence and argument count\n",
    "    def visit_Call(self, node: Call):\n",
    "        func_def = self.current_scope.get_func(node.func.name)\n",
    "        if func_def is None:\n",
    "            self.error(f\"Call to undefined function '{node.func.name}'\", node)\n",
    "        else:\n",
    "            # Infer parameter types if not set\n",
    "            param_types_changed = False\n",
    "            for (pname, exp_type), arg in zip(func_def.param_types.items(), node.args):\n",
    "                self.visit(arg)\n",
    "                actual = getattr(arg, 'inferred_type', None)\n",
    "                if exp_type is None:\n",
    "                    func_def.param_types[pname] = actual  # Infer type from first call\n",
    "                    param_types_changed = True\n",
    "                elif actual != exp_type:\n",
    "                    self.error(f\"Type mismatch in argument: expected {exp_type}, got {actual}\", arg)\n",
    "            if len(node.args) != len(func_def.param_types):\n",
    "                self.error(f\"Function '{node.func.name}' expects {len(func_def.param_types)} arguments, got {len(node.args)}\", node)\n",
    "            # Re-analyze function body if parameter types were updated\n",
    "            if param_types_changed:\n",
    "                prev_scope = self.current_scope\n",
    "                func_scope = Scope(parent=self.global_scope)\n",
    "                func_scope.in_function = True\n",
    "                for pname, ptype in func_def.param_types.items():\n",
    "                    func_scope.declare_var(pname, ptype)\n",
    "                self.current_scope = func_scope\n",
    "                return_types = set()\n",
    "                for stmt in func_def.body:\n",
    "                    self.visit(stmt)\n",
    "                    if isinstance(stmt, Return) and hasattr(stmt, 'inferred_type') and stmt.inferred_type is not None:\n",
    "                        return_types.add(stmt.inferred_type)\n",
    "                self.current_scope = prev_scope\n",
    "                func_def.return_type = return_types.pop() if len(return_types) == 1 else 'multiple' if return_types else 'None'\n",
    "        if func_def and hasattr(func_def, 'return_type'):\n",
    "            node.inferred_type = func_def.return_type\n",
    "\n",
    "\n",
    "    # Visit a return statement and ensure it's inside a function\n",
    "    def visit_Return(self, node: Return):\n",
    "        scope = self.current_scope\n",
    "        while scope:\n",
    "            if scope.in_function:\n",
    "                break\n",
    "            scope = scope.parent\n",
    "        else:\n",
    "            self.error(\"Return statement outside function\", node)\n",
    "\n",
    "        if node.value:\n",
    "            self.visit(node.value)\n",
    "            node.inferred_type = getattr(node.value, 'inferred_type', None)\n",
    "\n",
    "    # Visit if/elif/else blocks and analyze each conditional branch\n",
    "    def visit_IfStatement(self, node: IfStatement):\n",
    "        self.visit(node.condition)\n",
    "        for stmt in node.then_branch:\n",
    "            self.visit(stmt)\n",
    "        for cond, body in node.elif_branches:\n",
    "            self.visit(cond)\n",
    "            for stmt in body:\n",
    "                self.visit(stmt)\n",
    "        if node.else_branch:\n",
    "            for stmt in node.else_branch:\n",
    "                self.visit(stmt)\n",
    "\n",
    "    # Visit while loop and analyze condition and body statements\n",
    "    def visit_WhileLoop(self, node: WhileLoop):\n",
    "        self.visit(node.condition)\n",
    "        for stmt in node.body:\n",
    "            self.visit(stmt)\n",
    "\n",
    "    # Visit for loop: declare loop variable in new scope and analyze loop body\n",
    "    def visit_ForLoop(self, node: ForLoop):\n",
    "        self.visit(node.iterable)\n",
    "        loop_scope = Scope(parent=self.current_scope)\n",
    "        if not loop_scope.declare_var(node.var):\n",
    "            self.error(f\"Loop variable '{node.var}' already declared\", node)\n",
    "        prev_scope = self.current_scope\n",
    "        self.current_scope = loop_scope\n",
    "        for stmt in node.body:\n",
    "            self.visit(stmt)\n",
    "        self.current_scope = prev_scope\n",
    "\n",
    "    # Visit an expression statement (e.g., standalone function call)\n",
    "    def visit_ExpressionStatement(self, node: ExpressionStatement):\n",
    "        self.visit(node.expression)\n",
    "\n",
    "    # Visit a binary operation node and analyze both left and right operands\n",
    "    def visit_BinaryOp(self, node: BinaryOp):\n",
    "        self.visit(node.left)\n",
    "        self.visit(node.right)\n",
    "        \n",
    "        ltype = getattr(node.left, 'inferred_type', None)\n",
    "        rtype = getattr(node.right, 'inferred_type', None)\n",
    "\n",
    "        # Handle type inference for numeric operations\n",
    "        numeric_ops = {'+', '-', '*', '/', '%', '**'}\n",
    "\n",
    "        if ltype and rtype:\n",
    "            if node.operator in numeric_ops:\n",
    "                if ltype in {'int', 'float'} and rtype in {'int', 'float'}:\n",
    "                    # Type promotion rule: int + float => float\n",
    "                    if ltype == 'float' or rtype == 'float':\n",
    "                        node.inferred_type = 'float'\n",
    "                    else:\n",
    "                        node.inferred_type = 'int'\n",
    "                else:\n",
    "                    self.error(f\"Unsupported operand types for {node.operator}: '{ltype}' and '{rtype}'\", node)\n",
    "            elif node.operator in {'==', '!=', '<', '>', '<=', '>='}:\n",
    "                node.inferred_type = 'bool'\n",
    "            elif node.operator in {'and', 'or'}:\n",
    "                if ltype == rtype == 'bool':\n",
    "                    node.inferred_type = 'bool'\n",
    "                else:\n",
    "                    self.error(f\"Logical operators require boolean operands, got '{ltype}' and '{rtype}'\", node)\n",
    "            else:\n",
    "                self.error(f\"Unknown binary operator '{node.operator}'\", node)\n",
    "\n",
    "        # Constant folding (optional)\n",
    "        if hasattr(node.left, 'constant_value') and hasattr(node.right, 'constant_value'):\n",
    "            try:\n",
    "                node.constant_value = eval(f\"{repr(node.left.constant_value)} {node.operator} {repr(node.right.constant_value)}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            \n",
    "    # Visit a unary operation node and analyze its operand\n",
    "    def visit_UnaryOp(self, node: UnaryOp):\n",
    "        self.visit(node.operand)\n",
    "        if hasattr(node.operand, 'inferred_type'):\n",
    "            node.inferred_type = node.operand.inferred_type\n",
    "        if hasattr(node.operand, 'constant_value'):\n",
    "            try:\n",
    "                node.constant_value = eval(f\"{node.operator}{node.operand.constant_value}\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Visit a literal node (e.g., number, string); literals are always valid\n",
    "    def visit_Literal(self, node: Literal):\n",
    "        node.inferred_type = type(node.value).__name__\n",
    "        node.constant_value = node.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0439696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AST before semantic analysis:\n",
      "Program\n",
      "  FunctionDef(printUser)\n",
      "    ExpressionStatement\n",
      "      Call\n",
      "        Identifier(print)\n",
      "          BinaryOp(+)\n",
      "            Literal('User is ')\n",
      "            Identifier(user)\n",
      "  ExpressionStatement\n",
      "    Call\n",
      "      Identifier(printUser)\n",
      "        Literal('Hadiah')\n",
      "Semantic analysis failed: [Line 3, Column 1] Error at 'Call': Call to undefined function 'print'\n",
      "[Line 3, Column 1] Error at 'Call': Call to undefined function 'print'\n"
     ]
    }
   ],
   "source": [
    "source = \"\"\"\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "def add(a, b):\n",
    "    result = a + b\n",
    "    return result\n",
    "\n",
    "value = 5\n",
    "squared = square(value)\n",
    "total = add(squared, 10)\n",
    "\n",
    "def test():\n",
    "    message = \"All good!\"\n",
    "    return message\n",
    "\"\"\"\n",
    "parseTest= '''\n",
    "def average_grade(students):  \n",
    "    total = 0\n",
    "    for s in students:\n",
    "        total = total + s\n",
    "    return total / len(students)\n",
    "\n",
    "grades = [85, 90, 78]\n",
    "result = average_grade(grades)\n",
    "print(result)\n",
    "\n",
    "'''\n",
    "semanticTest='''\n",
    "def printUser(name):\n",
    "    print(\"User is \" + user)\n",
    "    \n",
    "printUser(\"Hadiah\")\n",
    "\n",
    "'''\n",
    "\n",
    "lexer = Lexer(semanticTest)\n",
    "parser = Parser(lexer)\n",
    "ast = parser.parse()\n",
    "analyzer = SemanticAnalyzer()\n",
    "\n",
    "print(\"AST before semantic analysis:\")\n",
    "print_ast(ast)\n",
    "\n",
    "try:\n",
    "    analyzer.analyze(ast)\n",
    "    print(\"Semantic analysis passed!\\n\")\n",
    "    print(\"\\nSymbol Table:\")\n",
    "    analyzer.global_scope.print_symbols()\n",
    "\n",
    "    print(\"\\nAST after semantic analysis (with annotations):\")\n",
    "    print_ast(ast)\n",
    "    # Generate annotated AST graph\n",
    "    dot = visualize_ast(ast)\n",
    "    dot.render('ast_tree', view=True, format='png')\n",
    "except Exception as e:\n",
    "    print(\"Semantic analysis failed:\", e)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfb2cbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### AST Before Semantic Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program\n",
      "  FunctionDef(add)\n",
      "    Assignment(target=result)\n",
      "      BinaryOp(+)\n",
      "        Identifier(a)\n",
      "        Identifier(b)\n",
      "    Return\n",
      "      Identifier(result)\n",
      "  Assignment(target=x)\n",
      "    Literal(1)\n",
      "  Assignment(target=y)\n",
      "    Literal(2.5)\n",
      "  Assignment(target=z)\n",
      "    Call\n",
      "      Identifier(add)\n",
      "        Identifier(x)\n",
      "        Identifier(y)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:green; font-weight:bold'>✅ Semantic analysis passed!</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Symbol Table"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scope:\n",
      "  Variable: x, Type: int\n",
      "  Variable: y, Type: float\n",
      "  Variable: z, Type: float\n",
      "  Function: add(a: int, b: float), Return: float\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### AST After Semantic Analysis (With Annotations)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program\n",
      "  FunctionDef(add) [return_type=float]\n",
      "    Assignment(target=result) [type=float]\n",
      "      BinaryOp(+) [type=float]\n",
      "        Identifier(a) [type=int]\n",
      "        Identifier(b) [type=float]\n",
      "    Return [type=float]\n",
      "      Identifier(result) [type=float]\n",
      "  Assignment(target=x) [type=int]\n",
      "    Literal(1) [type=int, const=1]\n",
      "  Assignment(target=y) [type=float]\n",
      "    Literal(2.5) [type=float, const=2.5]\n",
      "  Assignment(target=z) [type=float]\n",
      "    Call [type=float]\n",
      "      Identifier(add)\n",
      "        Identifier(x) [type=int]\n",
      "        Identifier(y) [type=float]\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore, Style, init\n",
    "from IPython.display import Markdown, display\n",
    "# Enable ANSI color in terminal\n",
    "init(autoreset=True)\n",
    "\n",
    "source = \"\"\"\n",
    "def add(a, b):\n",
    "    result = a + b\n",
    "    return result\n",
    "\n",
    "x = 1\n",
    "y = 2.5\n",
    "z = add(x, y)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lexer = Lexer(source)\n",
    "parser = Parser(lexer)\n",
    "ast = parser.parse()\n",
    "\n",
    "display(Markdown(\"### AST Before Semantic Analysis\"))\n",
    "print_ast(ast)\n",
    "\n",
    "analyzer = SemanticAnalyzer()\n",
    "\n",
    "try:\n",
    "    analyzer.analyze(ast)\n",
    "\n",
    "    display(Markdown(f\"<span style='color:green; font-weight:bold'>✅ Semantic analysis passed!</span>\"))\n",
    "\n",
    "    display(Markdown(\"### Symbol Table\"))\n",
    "    analyzer.global_scope.print_symbols()\n",
    "    \n",
    "    display(Markdown(\"### AST After Semantic Analysis (With Annotations)\"))\n",
    "    print_ast(ast)\n",
    "\n",
    "    dot = visualize_ast(ast)\n",
    "    dot.render('ast_tree', view=True, format='png')\n",
    "\n",
    "except Exception as e:\n",
    "    display(Markdown(f\"<span style='color:red; font-weight:bold'>❌ Semantic analysis failed:</span> {e}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27632b7",
   "metadata": {},
   "source": [
    "### Code Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(self):\n",
    "        self.optimizations_applied = 0\n",
    "        self.modified = True  # Track if any optimizations were made\n",
    "        self.constants = {}   # track constant values\n",
    "        self.scope_stack = [{}]  # Stack of scopes for tracking variables in different scopes\n",
    "    \n",
    "    def visit_Identifier(self, node: Identifier) -> ASTNode:\n",
    "        \"\"\"Propagate known constant values\"\"\"\n",
    "        # Look for constant value in all scopes, from innermost to outermost\n",
    "        for scope in reversed(self.scope_stack):\n",
    "            if node.name in scope:\n",
    "                self.modified = True\n",
    "                self.optimizations_applied += 1\n",
    "                # Create new literal and preserve any existing attributes\n",
    "                new_literal = Literal(value=scope[node.name], line=node.line, column=node.column)\n",
    "                # Copy any additional attributes that might exist (like type annotations)\n",
    "                for attr in dir(node):\n",
    "                    if not attr.startswith('_') and attr not in ['name', 'line', 'column']:\n",
    "                        if hasattr(node, attr) and not callable(getattr(node, attr)):\n",
    "                            try:\n",
    "                                setattr(new_literal, attr, getattr(node, attr))\n",
    "                            except:\n",
    "                                pass\n",
    "                return new_literal\n",
    "        return node\n",
    "    \n",
    "    def optimize(self, node: ASTNode) -> ASTNode:\n",
    "        \"\"\"Main optimization entry point\"\"\"\n",
    "        if node is None:\n",
    "            return None\n",
    "            \n",
    "        # Keep optimizing until no more changes can be made\n",
    "        max_iterations = 10  # Prevent infinite loops\n",
    "        iteration = 0\n",
    "        \n",
    "        while self.modified and iteration < max_iterations:\n",
    "            self.modified = False\n",
    "            old_optimizations = self.optimizations_applied\n",
    "            node = self.visit(node)\n",
    "            iteration += 1\n",
    "            \n",
    "            # If no new optimizations were applied, we're done\n",
    "            if self.optimizations_applied == old_optimizations:\n",
    "                break\n",
    "                \n",
    "        return node\n",
    "    \n",
    "    def visit(self, node: ASTNode) -> Optional[ASTNode]:\n",
    "        \"\"\"Visit and potentially transform a node\"\"\"\n",
    "        if node is None:\n",
    "            return None\n",
    "            \n",
    "        method = 'visit_' + type(node).__name__\n",
    "        visitor = getattr(self, method, self.generic_visit)\n",
    "        return visitor(node)\n",
    "    \n",
    "    def generic_visit(self, node: ASTNode) -> ASTNode:\n",
    "        \"\"\"Default visitor that traverses all fields\"\"\"\n",
    "        for field in getattr(node, '__dataclass_fields__', {}):\n",
    "            value = getattr(node, field)\n",
    "            if isinstance(value, ASTNode):\n",
    "                optimized = self.visit(value)\n",
    "                if optimized is not None:\n",
    "                    setattr(node, field, optimized)\n",
    "            elif isinstance(value, list):\n",
    "                new_list = []\n",
    "                for item in value:\n",
    "                    if isinstance(item, ASTNode):\n",
    "                        optimized = self.visit(item)\n",
    "                        if optimized is not None:\n",
    "                            new_list.append(optimized)\n",
    "                    else:\n",
    "                        new_list.append(item)\n",
    "                setattr(node, field, new_list)\n",
    "        return node\n",
    "\n",
    "    def visit_Program(self, node: Program) -> Program:\n",
    "        \"\"\"Optimize the program's body\"\"\"\n",
    "        optimized_body = []\n",
    "        for stmt in node.body:\n",
    "            result = self.visit(stmt)\n",
    "            if result is not None:\n",
    "                if isinstance(result, list):\n",
    "                    optimized_body.extend(result)\n",
    "                else:\n",
    "                    optimized_body.append(result)\n",
    "        node.body = optimized_body\n",
    "        return node\n",
    "\n",
    "    def visit_BinaryOp(self, node: BinaryOp) -> ASTNode:\n",
    "        \"\"\"Enhanced constant folding for binary operations\"\"\"\n",
    "        # Visit operands first to ensure constant propagation happens\n",
    "        node.left = self.visit(node.left)\n",
    "        node.right = self.visit(node.right)\n",
    "        \n",
    "        # Try to evaluate if both operands are literals\n",
    "        left_val = getattr(node.left, 'value', None) if isinstance(node.left, Literal) else None\n",
    "        right_val = getattr(node.right, 'value', None) if isinstance(node.right, Literal) else None\n",
    "        \n",
    "        if left_val is not None and right_val is not None:\n",
    "            try:\n",
    "                if node.operator == '+':\n",
    "                    value = left_val + right_val\n",
    "                elif node.operator == '-':\n",
    "                    value = left_val - right_val\n",
    "                elif node.operator == '*':\n",
    "                    value = left_val * right_val\n",
    "                elif node.operator == '/':\n",
    "                    value = left_val / right_val\n",
    "                elif node.operator == '%':\n",
    "                    value = left_val % right_val\n",
    "                elif node.operator == '==':\n",
    "                    value = left_val == right_val\n",
    "                elif node.operator == '!=':\n",
    "                    value = left_val != right_val\n",
    "                elif node.operator == '<':\n",
    "                    value = left_val < right_val\n",
    "                elif node.operator == '>':\n",
    "                    value = left_val > right_val\n",
    "                elif node.operator == '<=':\n",
    "                    value = left_val <= right_val\n",
    "                elif node.operator == '>=':\n",
    "                    value = left_val >= right_val\n",
    "                else:\n",
    "                    return node\n",
    "                \n",
    "                self.modified = True\n",
    "                self.optimizations_applied += 1\n",
    "                # Create new literal and preserve any existing attributes\n",
    "                new_literal = Literal(value=value, line=node.line, column=node.column)\n",
    "                # Copy any additional attributes that might exist (like type annotations)\n",
    "                for attr in dir(node):\n",
    "                    if not attr.startswith('_') and attr not in ['left', 'right', 'operator', 'line', 'column', 'value']:\n",
    "                        if hasattr(node, attr) and not callable(getattr(node, attr)):\n",
    "                            try:\n",
    "                                setattr(new_literal, attr, getattr(node, attr))\n",
    "                            except:\n",
    "                                pass\n",
    "                return new_literal\n",
    "            except (ZeroDivisionError, TypeError, ValueError):\n",
    "                # Don't optimize if operation would cause an error\n",
    "                return node\n",
    "        return node\n",
    "\n",
    "    def visit_IfStatement(self, node: IfStatement) -> Optional[List[ASTNode]]:\n",
    "        \"\"\"Optimize if statements\"\"\"\n",
    "        # First optimize the condition\n",
    "        node.condition = self.visit(node.condition)\n",
    "        \n",
    "        # If condition is a constant literal\n",
    "        if isinstance(node.condition, Literal):\n",
    "            self.modified = True\n",
    "            self.optimizations_applied += 1\n",
    "            if node.condition.value:\n",
    "                # True condition - only keep then branch\n",
    "                optimized_then = []\n",
    "                for stmt in node.then_branch:\n",
    "                    result = self.visit(stmt)\n",
    "                    if result is not None:\n",
    "                        if isinstance(result, list):\n",
    "                            optimized_then.extend(result)\n",
    "                        else:\n",
    "                            optimized_then.append(result)\n",
    "                return optimized_then\n",
    "            elif node.else_branch:\n",
    "                # False condition - only keep else branch\n",
    "                optimized_else = []\n",
    "                for stmt in node.else_branch:\n",
    "                    result = self.visit(stmt)\n",
    "                    if result is not None:\n",
    "                        if isinstance(result, list):\n",
    "                            optimized_else.extend(result)\n",
    "                        else:\n",
    "                            optimized_else.append(result)\n",
    "                return optimized_else\n",
    "            else:\n",
    "                # False condition with no else - remove entirely\n",
    "                return []\n",
    "        \n",
    "        # Optimize all branches\n",
    "        node.then_branch = []\n",
    "        for stmt in node.then_branch:\n",
    "            result = self.visit(stmt)\n",
    "            if result is not None:\n",
    "                if isinstance(result, list):\n",
    "                    node.then_branch.extend(result)\n",
    "                else:\n",
    "                    node.then_branch.append(result)\n",
    "                    \n",
    "        node.elif_branches = []\n",
    "        for cond, body in node.elif_branches:\n",
    "            optimized_cond = self.visit(cond)\n",
    "            optimized_body = []\n",
    "            for stmt in body:\n",
    "                result = self.visit(stmt)\n",
    "                if result is not None:\n",
    "                    if isinstance(result, list):\n",
    "                        optimized_body.extend(result)\n",
    "                    else:\n",
    "                        optimized_body.append(result)\n",
    "            node.elif_branches.append((optimized_cond, optimized_body))\n",
    "            \n",
    "        if node.else_branch:\n",
    "            optimized_else = []\n",
    "            for stmt in node.else_branch:\n",
    "                result = self.visit(stmt)\n",
    "                if result is not None:\n",
    "                    if isinstance(result, list):\n",
    "                        optimized_else.extend(result)\n",
    "                    else:\n",
    "                        optimized_else.append(result)\n",
    "            node.else_branch = optimized_else\n",
    "        \n",
    "        return node\n",
    "\n",
    "    def visit_WhileLoop(self, node: WhileLoop) -> Optional[WhileLoop]:\n",
    "        \"\"\"Optimize while loops\"\"\"\n",
    "        node.condition = self.visit(node.condition)\n",
    "        \n",
    "        # If condition is a constant false, remove the loop\n",
    "        if isinstance(node.condition, Literal) and not node.condition.value:\n",
    "            self.modified = True\n",
    "            self.optimizations_applied += 1\n",
    "            return None\n",
    "            \n",
    "        # Optimize loop body\n",
    "        optimized_body = []\n",
    "        for stmt in node.body:\n",
    "            result = self.visit(stmt)\n",
    "            if result is not None:\n",
    "                if isinstance(result, list):\n",
    "                    optimized_body.extend(result)\n",
    "                else:\n",
    "                    optimized_body.append(result)\n",
    "        node.body = optimized_body\n",
    "        return node\n",
    "\n",
    "    def visit_FunctionDef(self, node: FunctionDef) -> FunctionDef:\n",
    "        \"\"\"Handle function scope\"\"\"\n",
    "        self.scope_stack.append({})  # Push new scope\n",
    "        \n",
    "        optimized_body = []\n",
    "        for stmt in node.body:\n",
    "            result = self.visit(stmt)\n",
    "            if result is not None:\n",
    "                if isinstance(result, list):\n",
    "                    optimized_body.extend(result)\n",
    "                else:\n",
    "                    optimized_body.append(result)\n",
    "        node.body = optimized_body\n",
    "        \n",
    "        self.scope_stack.pop()  # Pop function scope\n",
    "        return node\n",
    "\n",
    "    def visit_Return(self, node: Return) -> Return:\n",
    "        \"\"\"Optimize return value expressions\"\"\"\n",
    "        if node.value:\n",
    "            node.value = self.visit(node.value)\n",
    "        return node\n",
    "\n",
    "    def visit_Assignment(self, node: Assignment) -> Assignment:\n",
    "        \"\"\"Optimize assignment values and track constants\"\"\"\n",
    "        # First optimize the value expression\n",
    "        node.value = self.visit(node.value)\n",
    "        \n",
    "        # If the result is a literal, track it as a constant\n",
    "        if isinstance(node.value, Literal):\n",
    "            self.scope_stack[-1][node.target] = node.value.value\n",
    "            # Mark as modified to ensure another pass happens\n",
    "            self.modified = True\n",
    "        else:\n",
    "            # If assigning a non-constant, remove from constants if it exists\n",
    "            if node.target in self.scope_stack[-1]:\n",
    "                del self.scope_stack[-1][node.target]\n",
    "        \n",
    "        return node\n",
    "\n",
    "    def visit_ExpressionStatement(self, node: ExpressionStatement) -> ExpressionStatement:\n",
    "        \"\"\"Optimize expressions in expression statements\"\"\"\n",
    "        node.expression = self.visit(node.expression)\n",
    "        return node\n",
    "\n",
    "    def visit_Call(self, node: Call) -> Call:\n",
    "        \"\"\"Optimize function calls (visit arguments)\"\"\"\n",
    "        if hasattr(node, 'args'):\n",
    "            node.args = [self.visit(arg) for arg in node.args]\n",
    "        return node\n",
    "\n",
    "# Example usage:\n",
    "def optimize_ast(ast: ASTNode) -> ASTNode:\n",
    "    optimizer = Optimizer()\n",
    "    optimized_ast = optimizer.optimize(ast)\n",
    "    print(f\"Applied {optimizer.optimizations_applied} optimizations\")\n",
    "    return optimized_ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f288c86",
   "metadata": {},
   "source": [
    "### Just for debugging the optimizer cuz of some issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e2d627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class DebugOptimizer:\n",
    "    def __init__(self):\n",
    "        self.optimizations_applied = 0\n",
    "        self.modified = True\n",
    "        self.constants = {}\n",
    "        self.scope_stack = [{}]\n",
    "        self.debug = True  # Enable debug output\n",
    "    \n",
    "    def log(self, message):\n",
    "        if self.debug:\n",
    "            print(f\"[OPTIMIZER DEBUG] {message}\")\n",
    "    \n",
    "    def visit_Identifier(self, node: Identifier) -> ASTNode:\n",
    "        \"\"\"Propagate known constant values\"\"\"\n",
    "        self.log(f\"Visiting identifier: {node.name}\")\n",
    "        self.log(f\"Current scope stack: {self.scope_stack}\")\n",
    "        \n",
    "        # Look for constant value in all scopes, from innermost to outermost\n",
    "        for i, scope in enumerate(reversed(self.scope_stack)):\n",
    "            if node.name in scope:\n",
    "                self.log(f\"Found constant {node.name} = {scope[node.name]} in scope {len(self.scope_stack)-1-i}\")\n",
    "                self.modified = True\n",
    "                self.optimizations_applied += 1\n",
    "                new_literal = Literal(value=scope[node.name], line=node.line, column=node.column)\n",
    "                \n",
    "                # Copy any additional attributes from the original node\n",
    "                for attr in ['type', 'const', 'scope']:\n",
    "                    if hasattr(node, attr):\n",
    "                        try:\n",
    "                            setattr(new_literal, attr, getattr(node, attr))\n",
    "                            self.log(f\"Copied attribute {attr} = {getattr(node, attr)}\")\n",
    "                        except:\n",
    "                            pass\n",
    "                            \n",
    "                return new_literal\n",
    "        \n",
    "        self.log(f\"No constant found for {node.name}\")\n",
    "        return node\n",
    "    \n",
    "    def optimize(self, node: ASTNode) -> ASTNode:\n",
    "        \"\"\"Main optimization entry point\"\"\"\n",
    "        if node is None:\n",
    "            return None\n",
    "        \n",
    "        self.log(\"Starting optimization\")\n",
    "        max_iterations = 10\n",
    "        iteration = 0\n",
    "        \n",
    "        while self.modified and iteration < max_iterations:\n",
    "            self.log(f\"Optimization pass {iteration + 1}\")\n",
    "            self.modified = False\n",
    "            old_optimizations = self.optimizations_applied\n",
    "            \n",
    "            node = self.visit(node)\n",
    "            iteration += 1\n",
    "            \n",
    "            new_optimizations = self.optimizations_applied - old_optimizations\n",
    "            self.log(f\"Pass {iteration} applied {new_optimizations} optimizations\")\n",
    "            \n",
    "            if new_optimizations == 0:\n",
    "                self.log(\"No new optimizations, stopping\")\n",
    "                break\n",
    "                \n",
    "        self.log(f\"Optimization complete after {iteration} passes\")\n",
    "        return node\n",
    "    \n",
    "    def visit(self, node: ASTNode) -> Optional[ASTNode]:\n",
    "        \"\"\"Visit and potentially transform a node\"\"\"\n",
    "        if node is None:\n",
    "            return None\n",
    "            \n",
    "        method = 'visit_' + type(node).__name__\n",
    "        visitor = getattr(self, method, self.generic_visit)\n",
    "        return visitor(node)\n",
    "    \n",
    "    def generic_visit(self, node: ASTNode) -> ASTNode:\n",
    "        \"\"\"Default visitor that traverses all fields\"\"\"\n",
    "        for field in getattr(node, '__dataclass_fields__', {}):\n",
    "            value = getattr(node, field)\n",
    "            if isinstance(value, ASTNode):\n",
    "                optimized = self.visit(value)\n",
    "                if optimized is not None:\n",
    "                    setattr(node, field, optimized)\n",
    "            elif isinstance(value, list):\n",
    "                new_list = []\n",
    "                for item in value:\n",
    "                    if isinstance(item, ASTNode):\n",
    "                        optimized = self.visit(item)\n",
    "                        if optimized is not None:\n",
    "                            new_list.append(optimized)\n",
    "                    else:\n",
    "                        new_list.append(item)\n",
    "                setattr(node, field, new_list)\n",
    "        return node\n",
    "\n",
    "    def visit_Program(self, node: Program) -> Program:\n",
    "        \"\"\"Optimize the program's body\"\"\"\n",
    "        self.log(\"Visiting Program\")\n",
    "        optimized_body = []\n",
    "        for stmt in node.body:\n",
    "            result = self.visit(stmt)\n",
    "            if result is not None:\n",
    "                if isinstance(result, list):\n",
    "                    optimized_body.extend(result)\n",
    "                else:\n",
    "                    optimized_body.append(result)\n",
    "        node.body = optimized_body\n",
    "        return node\n",
    "\n",
    "    def visit_BinaryOp(self, node: BinaryOp) -> ASTNode:\n",
    "        \"\"\"Enhanced constant folding for binary operations\"\"\"\n",
    "        self.log(f\"Visiting BinaryOp: {node.operator}\")\n",
    "        \n",
    "        # Visit operands first\n",
    "        node.left = self.visit(node.left)\n",
    "        node.right = self.visit(node.right)\n",
    "        \n",
    "        # Check if we can fold\n",
    "        left_val = getattr(node.left, 'value', None) if isinstance(node.left, Literal) else None\n",
    "        right_val = getattr(node.right, 'value', None) if isinstance(node.right, Literal) else None\n",
    "        \n",
    "        self.log(f\"Left operand: {type(node.left).__name__}, value: {left_val}\")\n",
    "        self.log(f\"Right operand: {type(node.right).__name__}, value: {right_val}\")\n",
    "        \n",
    "        if left_val is not None and right_val is not None:\n",
    "            try:\n",
    "                if node.operator == '+':\n",
    "                    value = left_val + right_val\n",
    "                elif node.operator == '-':\n",
    "                    value = left_val - right_val\n",
    "                elif node.operator == '*':\n",
    "                    value = left_val * right_val\n",
    "                elif node.operator == '/':\n",
    "                    value = left_val / right_val\n",
    "                elif node.operator == '%':\n",
    "                    value = left_val % right_val\n",
    "                else:\n",
    "                    self.log(f\"Unknown operator: {node.operator}\")\n",
    "                    return node\n",
    "                \n",
    "                self.log(f\"Folding {left_val} {node.operator} {right_val} = {value}\")\n",
    "                self.modified = True\n",
    "                self.optimizations_applied += 1\n",
    "                \n",
    "                new_literal = Literal(value=value, line=node.line, column=node.column)\n",
    "                \n",
    "                # Copy attributes from original node\n",
    "                for attr in ['type', 'const', 'scope']:\n",
    "                    if hasattr(node, attr):\n",
    "                        try:\n",
    "                            setattr(new_literal, attr, getattr(node, attr))\n",
    "                        except:\n",
    "                            pass\n",
    "                            \n",
    "                return new_literal\n",
    "            except Exception as e:\n",
    "                self.log(f\"Error during folding: {e}\")\n",
    "                return node\n",
    "        return node\n",
    "\n",
    "    def visit_Assignment(self, node: Assignment) -> Assignment:\n",
    "        \"\"\"Optimize assignment values and track constants\"\"\"\n",
    "        self.log(f\"Visiting Assignment: {node.target}\")\n",
    "        \n",
    "        # First optimize the value expression\n",
    "        node.value = self.visit(node.value)\n",
    "        \n",
    "        # If the result is a literal, track it as a constant\n",
    "        if isinstance(node.value, Literal):\n",
    "            self.log(f\"Storing constant: {node.target} = {node.value.value}\")\n",
    "            self.scope_stack[-1][node.target] = node.value.value\n",
    "            self.modified = True\n",
    "        else:\n",
    "            self.log(f\"Assignment {node.target} is not a constant: {type(node.value).__name__}\")\n",
    "            # Remove from constants if it exists\n",
    "            if node.target in self.scope_stack[-1]:\n",
    "                del self.scope_stack[-1][node.target]\n",
    "                self.log(f\"Removed {node.target} from constants\")\n",
    "        \n",
    "        return node\n",
    "\n",
    "    def visit_FunctionDef(self, node: FunctionDef) -> FunctionDef:\n",
    "        \"\"\"Handle function scope\"\"\"\n",
    "        self.log(f\"Entering function: {getattr(node, 'name', 'unnamed')}\")\n",
    "        self.scope_stack.append({})\n",
    "        \n",
    "        optimized_body = []\n",
    "        for stmt in node.body:\n",
    "            result = self.visit(stmt)\n",
    "            if result is not None:\n",
    "                if isinstance(result, list):\n",
    "                    optimized_body.extend(result)\n",
    "                else:\n",
    "                    optimized_body.append(result)\n",
    "        node.body = optimized_body\n",
    "        \n",
    "        self.scope_stack.pop()\n",
    "        self.log(f\"Exiting function\")\n",
    "        return node\n",
    "\n",
    "    def visit_Return(self, node: Return) -> Return:\n",
    "        \"\"\"Optimize return value expressions\"\"\"\n",
    "        self.log(\"Visiting Return\")\n",
    "        if node.value:\n",
    "            node.value = self.visit(node.value)\n",
    "        return node\n",
    "\n",
    "    def visit_ExpressionStatement(self, node: ExpressionStatement) -> ExpressionStatement:\n",
    "        \"\"\"Optimize expressions in expression statements\"\"\"\n",
    "        node.expression = self.visit(node.expression)\n",
    "        return node\n",
    "\n",
    "    def visit_Call(self, node: Call) -> Call:\n",
    "        \"\"\"Optimize function calls\"\"\"\n",
    "        if hasattr(node, 'args'):\n",
    "            node.args = [self.visit(arg) for arg in node.args]\n",
    "        return node\n",
    "\n",
    "# Modified test function\n",
    "def debug_optimize_ast(ast: ASTNode) -> ASTNode:\n",
    "    optimizer = DebugOptimizer()\n",
    "    optimized_ast = optimizer.optimize(ast)\n",
    "    print(f\"Applied {optimizer.optimizations_applied} optimizations\")\n",
    "    return optimized_ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1761d2",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02556330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Optimization: Complex Expression Folding ===\n",
      "Source code:\n",
      "\n",
      "def calculate():\n",
      "    a = 5 + 3 * 2\n",
      "    b = 10 / 2\n",
      "    c = a + b - (2 * 3)\n",
      "    return c\n",
      "\n",
      "result = calculate()\n",
      "\n",
      "\n",
      "Before optimization:\n",
      "Program\n",
      "  FunctionDef(calculate) [return_type=int]\n",
      "    Assignment(target=a) [type=int]\n",
      "      BinaryOp(+) [type=int, const=11]\n",
      "        Literal(5) [type=int, const=5]\n",
      "        BinaryOp(*) [type=int, const=6]\n",
      "          Literal(3) [type=int, const=3]\n",
      "          Literal(2) [type=int, const=2]\n",
      "    Assignment(target=b) [type=int]\n",
      "      BinaryOp(/) [type=int, const=5.0]\n",
      "        Literal(10) [type=int, const=10]\n",
      "        Literal(2) [type=int, const=2]\n",
      "    Assignment(target=c) [type=int]\n",
      "      BinaryOp(-) [type=int]\n",
      "        BinaryOp(+) [type=int]\n",
      "          Identifier(a) [type=int]\n",
      "          Identifier(b) [type=int]\n",
      "        BinaryOp(*) [type=int, const=6]\n",
      "          Literal(2) [type=int, const=2]\n",
      "          Literal(3) [type=int, const=3]\n",
      "    Return [type=int]\n",
      "      Identifier(c) [type=int]\n",
      "  Assignment(target=result) [type=int]\n",
      "    Call [type=int]\n",
      "      Identifier(calculate)\n",
      "[OPTIMIZER DEBUG] Starting optimization\n",
      "[OPTIMIZER DEBUG] Optimization pass 1\n",
      "[OPTIMIZER DEBUG] Visiting Program\n",
      "[OPTIMIZER DEBUG] Entering function: calculate\n",
      "[OPTIMIZER DEBUG] Visiting Assignment: a\n",
      "[OPTIMIZER DEBUG] Visiting BinaryOp: +\n",
      "[OPTIMIZER DEBUG] Visiting BinaryOp: *\n",
      "[OPTIMIZER DEBUG] Left operand: Literal, value: 3\n",
      "[OPTIMIZER DEBUG] Right operand: Literal, value: 2\n",
      "[OPTIMIZER DEBUG] Folding 3 * 2 = 6\n",
      "[OPTIMIZER DEBUG] Left operand: Literal, value: 5\n",
      "[OPTIMIZER DEBUG] Right operand: Literal, value: 6\n",
      "[OPTIMIZER DEBUG] Folding 5 + 6 = 11\n",
      "[OPTIMIZER DEBUG] Storing constant: a = 11\n",
      "[OPTIMIZER DEBUG] Visiting Assignment: b\n",
      "[OPTIMIZER DEBUG] Visiting BinaryOp: /\n",
      "[OPTIMIZER DEBUG] Left operand: Literal, value: 10\n",
      "[OPTIMIZER DEBUG] Right operand: Literal, value: 2\n",
      "[OPTIMIZER DEBUG] Folding 10 / 2 = 5.0\n",
      "[OPTIMIZER DEBUG] Storing constant: b = 5.0\n",
      "[OPTIMIZER DEBUG] Visiting Assignment: c\n",
      "[OPTIMIZER DEBUG] Visiting BinaryOp: -\n",
      "[OPTIMIZER DEBUG] Visiting BinaryOp: +\n",
      "[OPTIMIZER DEBUG] Visiting identifier: a\n",
      "[OPTIMIZER DEBUG] Current scope stack: [{}, {'a': 11, 'b': 5.0}]\n",
      "[OPTIMIZER DEBUG] Found constant a = 11 in scope 1\n",
      "[OPTIMIZER DEBUG] Visiting identifier: b\n",
      "[OPTIMIZER DEBUG] Current scope stack: [{}, {'a': 11, 'b': 5.0}]\n",
      "[OPTIMIZER DEBUG] Found constant b = 5.0 in scope 1\n",
      "[OPTIMIZER DEBUG] Left operand: Literal, value: 11\n",
      "[OPTIMIZER DEBUG] Right operand: Literal, value: 5.0\n",
      "[OPTIMIZER DEBUG] Folding 11 + 5.0 = 16.0\n",
      "[OPTIMIZER DEBUG] Visiting BinaryOp: *\n",
      "[OPTIMIZER DEBUG] Left operand: Literal, value: 2\n",
      "[OPTIMIZER DEBUG] Right operand: Literal, value: 3\n",
      "[OPTIMIZER DEBUG] Folding 2 * 3 = 6\n",
      "[OPTIMIZER DEBUG] Left operand: Literal, value: 16.0\n",
      "[OPTIMIZER DEBUG] Right operand: Literal, value: 6\n",
      "[OPTIMIZER DEBUG] Folding 16.0 - 6 = 10.0\n",
      "[OPTIMIZER DEBUG] Storing constant: c = 10.0\n",
      "[OPTIMIZER DEBUG] Visiting Return\n",
      "[OPTIMIZER DEBUG] Visiting identifier: c\n",
      "[OPTIMIZER DEBUG] Current scope stack: [{}, {'a': 11, 'b': 5.0, 'c': 10.0}]\n",
      "[OPTIMIZER DEBUG] Found constant c = 10.0 in scope 1\n",
      "[OPTIMIZER DEBUG] Exiting function\n",
      "[OPTIMIZER DEBUG] Visiting Assignment: result\n",
      "[OPTIMIZER DEBUG] Assignment result is not a constant: Call\n",
      "[OPTIMIZER DEBUG] Pass 1 applied 9 optimizations\n",
      "[OPTIMIZER DEBUG] Optimization pass 2\n",
      "[OPTIMIZER DEBUG] Visiting Program\n",
      "[OPTIMIZER DEBUG] Entering function: calculate\n",
      "[OPTIMIZER DEBUG] Visiting Assignment: a\n",
      "[OPTIMIZER DEBUG] Storing constant: a = 11\n",
      "[OPTIMIZER DEBUG] Visiting Assignment: b\n",
      "[OPTIMIZER DEBUG] Storing constant: b = 5.0\n",
      "[OPTIMIZER DEBUG] Visiting Assignment: c\n",
      "[OPTIMIZER DEBUG] Storing constant: c = 10.0\n",
      "[OPTIMIZER DEBUG] Visiting Return\n",
      "[OPTIMIZER DEBUG] Exiting function\n",
      "[OPTIMIZER DEBUG] Visiting Assignment: result\n",
      "[OPTIMIZER DEBUG] Assignment result is not a constant: Call\n",
      "[OPTIMIZER DEBUG] Pass 2 applied 0 optimizations\n",
      "[OPTIMIZER DEBUG] No new optimizations, stopping\n",
      "[OPTIMIZER DEBUG] Optimization complete after 2 passes\n",
      "Applied 9 optimizations\n",
      "\n",
      "After optimization:\n",
      "Program\n",
      "  FunctionDef(calculate) [return_type=int]\n",
      "    Assignment(target=a) [type=int]\n",
      "      Literal(11)\n",
      "    Assignment(target=b) [type=int]\n",
      "      Literal(5.0)\n",
      "    Assignment(target=c) [type=int]\n",
      "      Literal(10.0)\n",
      "    Return [type=int]\n",
      "      Literal(10.0)\n",
      "  Assignment(target=result) [type=int]\n",
      "    Call [type=int]\n",
      "      Identifier(calculate)\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore, Style, init\n",
    "from IPython.display import Markdown, display\n",
    "init(autoreset=True)\n",
    "\n",
    "def test_optimization(source_code, test_name=\"\"):\n",
    "    print(f\"\\n=== Testing Optimization: {test_name} ===\")\n",
    "    print(f\"Source code:\\n{source_code}\")\n",
    "    \n",
    "    # Parse and analyze first\n",
    "    lexer = Lexer(source_code)\n",
    "    parser = Parser(lexer)\n",
    "    ast = parser.parse()\n",
    "    \n",
    "    # Initialize analyzer with built-ins\n",
    "    analyzer = SemanticAnalyzer()\n",
    "    \n",
    "    try:\n",
    "        analyzer.analyze(ast)\n",
    "        \n",
    "        print(\"\\nBefore optimization:\")\n",
    "        print_ast(ast)\n",
    "        \n",
    "        # Run optimization\n",
    "        optimized_ast = optimize_ast(ast)\n",
    "        \n",
    "        print(\"\\nAfter optimization:\")\n",
    "        print_ast(optimized_ast)\n",
    "        \n",
    "        # Visualize before/after\n",
    "        #dot_before = visualize_ast(ast)\n",
    "        #dot_before.render('ast_before_opt', view=True, format='png')\n",
    "        \n",
    "        #dot_after = visualize_ast(optimized_ast)\n",
    "        #dot_after.render('ast_after_opt', view=True, format='png')\n",
    "        \n",
    "    except SemanticError as e:\n",
    "        print(f\"\\nSemantic Error: {e}\")\n",
    "\n",
    "# Test cases\n",
    "# 1. Constant folding\n",
    "# test_optimization(\"\"\"\n",
    "# x = 2 + 3 * 4\n",
    "# y = 10 + 20 + 30\n",
    "# \"\"\", \"Constant Folding\")\n",
    "\n",
    "# # 2. Dead code elimination in if statements\n",
    "# test_optimization(\"\"\"\n",
    "# if True:\n",
    "#     x = 10\n",
    "#     y = 20\n",
    "# else:\n",
    "#     x = 30\n",
    "#     y = 40\n",
    "\n",
    "# if False:\n",
    "#     a = \"This will be removed\"\n",
    "# \"\"\", \"Dead Code in If Statements\")\n",
    "\n",
    "# 3. Dead code in while loops\n",
    "# test_optimization(\"\"\"\n",
    "# while False:\n",
    "#     print(\"This loop will be removed\")\n",
    "    \n",
    "# x = 1\n",
    "# while True:\n",
    "#     x = x + 1\n",
    "# \"\"\", \"Dead Code in While Loops\")\n",
    "\n",
    "# 4. Complex expression folding\n",
    "test_optimization(\"\"\"\n",
    "def calculate():\n",
    "    a = 5 + 3 * 2\n",
    "    b = 10 / 2\n",
    "    c = a + b - (2 * 3)\n",
    "    return c\n",
    "\n",
    "result = calculate()\n",
    "\"\"\", \"Complex Expression Folding\")\n",
    "\n",
    "# 5. Mixed optimizations\n",
    "# test_optimization(\"\"\"\n",
    "# def test(x):\n",
    "#     y = 2 + 3 * 4\n",
    "#     if True:\n",
    "#         return y + 10\n",
    "#     else:\n",
    "#         return y - 10\n",
    "\n",
    "# while False:\n",
    "#     print(\"Dead code\")\n",
    "\n",
    "# result = test(5)\n",
    "# \"\"\", \"Mixed Optimizations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

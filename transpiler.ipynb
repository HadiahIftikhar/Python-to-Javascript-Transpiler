{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed207ce",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "##### Keywords: if, else, elif, while, for, in, def, return, True, False, None\n",
    "##### Operators: +, -, *, /, %, **, =, ==, !=, <, >, <=, >=, and, or, not\n",
    "##### Delimiters: (, ), {, }, [, ], ',' , '.', ':', ';'\n",
    "##### Literals: INTEGER, FLOAT, STRING\n",
    "##### Other: IDENTIFIER, INDENT, DEDENT, NEWLINE, EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96572fc",
   "metadata": {},
   "source": [
    "## Token and Error Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910907aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Generator, List, Optional, Tuple\n",
    "\n",
    "class Token:\n",
    "    def __init__(self, type: str, value: str, line: int, column: int):\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "        self.line = line\n",
    "        self.column = column\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Token({self.type}, '{self.value}', line={self.line}, col={self.column})\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "class Error:\n",
    "    def __init__(self, message: str, line: int, column: int):\n",
    "        self.message = message\n",
    "        self.line = line\n",
    "        self.column = column\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Error: {self.message} at line {self.line}, column {self.column}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d04a7",
   "metadata": {},
   "source": [
    "## Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec43f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    # Defining regular expressions for token\n",
    "    TOKEN_SPECS = [\n",
    "        ('COMMENT', r'#.*'),                                  # Comments\n",
    "        ('STRING', r'\\\"([^\\\\\\\"]|\\\\.)*\\\"|\\'([^\\\\\\']|\\\\.)*\\''), # String literals\n",
    "        ('FLOAT', r'\\d+\\.\\d+'),                               # Float literals\n",
    "        ('INTEGER', r'\\d+'),                                  # Integer literals\n",
    "        ('KEYWORD', r'(if|else|elif|while|for|in|def|return|True|False|None)\\b'),  # Keywords\n",
    "        ('IDENTIFIER', r'[a-zA-Z_]\\w*'),                      # Identifiers\n",
    "        # Operators (multi-character ones first)\n",
    "        ('OP_EQ', r'=='),\n",
    "        ('OP_NE', r'!='),\n",
    "        ('OP_LE', r'<='),\n",
    "        ('OP_GE', r'>='),\n",
    "        ('OP_ASSIGN', r'='),\n",
    "        ('OP_PLUS', r'\\+'),\n",
    "        ('OP_MINUS', r'-'),\n",
    "        ('OP_MULT', r'\\*\\*|\\/\\/|\\*|\\/'),  # ** (power), // (floor div), * (mult), / (div)\n",
    "        ('OP_MOD', r'%'),\n",
    "        ('OP_LT', r'<'),\n",
    "        ('OP_GT', r'>'),\n",
    "        # Delimiters\n",
    "        ('LPAREN', r'\\('),\n",
    "        ('RPAREN', r'\\)'),\n",
    "        ('LBRACKET', r'\\['),\n",
    "        ('RBRACKET', r'\\]'),\n",
    "        ('LBRACE', r'\\{'),\n",
    "        ('RBRACE', r'\\}'),\n",
    "        ('COMMA', r','),\n",
    "        ('DOT', r'\\.'),\n",
    "        ('COLON', r':'),\n",
    "        ('SEMICOLON', r';'),\n",
    "        ('NEWLINE', r'\\n'),\n",
    "        ('WHITESPACE', r'[ \\t]+'),                            # Whitespace\n",
    "        # INDENT and DEDENT tokens are not matched by regex but generated based on whitespace\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, source_code: str):\n",
    "        self.source_code = source_code\n",
    "        self.tokens = []\n",
    "        self.errors = []\n",
    "        self.line = 1\n",
    "        self.column = 1\n",
    "        self.indent_levels = [0]  # Start with indent level 0\n",
    "    \n",
    "    def tokenize(self) -> Generator[Token, None, None]:\n",
    "        \"\"\"Tokenize the source code and yield tokens.\"\"\"\n",
    "        # Process the source code line by line to handle indentation properly\n",
    "        lines = self.source_code.split('\\n')\n",
    "        \n",
    "        for line_num, line in enumerate(lines):\n",
    "            self.line = line_num + 1\n",
    "            self.column = 1\n",
    "            \n",
    "            #calculating the amount of leading whitespace (indentation) at the beginning of the current line\n",
    "            if line.strip():  # Non-empty line      #strip() is equivalent of trim() in JS\n",
    "                indent_size = len(line) - len(line.lstrip())    #lstrip() will remove leading spaces in the line i.e. remove any indentation; and the difference in length tells you how much whitespace there was\n",
    "                indent_tokens = self._handle_indentation(indent_size)\n",
    "                for token in indent_tokens:\n",
    "                    yield token\n",
    "            else:   # Skip empty lines but still count them for line numbers\n",
    "                yield Token('NEWLINE', '\\\\n', self.line, self.column)\n",
    "                continue\n",
    "            \n",
    "            # Process the rest of the line\n",
    "            i = indent_size if 'indent_size' in locals() else 0\n",
    "            line_content = line\n",
    "            \n",
    "            while i < len(line_content):    #traversing a line character by character\n",
    "                match = None\n",
    "                \n",
    "                ## Skip spaces and tabs (already handled indentation)\n",
    "                ##if line_content[i].isspace():   #isspace() checks if the entire line is whitespace or not; here it checks whether a single character is whitespace or not since its applied on line_content[i]\n",
    "                ##    i += 1\n",
    "                ##    self.column += 1\n",
    "                ##    continue\n",
    "                \n",
    "                # Try to match each token pattern\n",
    "                for token_type, pattern in self.TOKEN_SPECS:\n",
    "                    regex = re.compile(pattern) #compiling the pattern into a regex so that we can use it to find tokens in the line\n",
    "                    match = regex.match(line_content, i)    #match() will check if the \"starting\" of the string matches the given regex or not, line_content gives the line whose starting it has to compare with the regex with i telling from which point in the line to assume as thhe starting of the line\n",
    "                    #if a match is found, 'match' will contain an object with info about the found match (like start and end, its value and so on), otherwise it'll contain \"none\"\n",
    "                    \n",
    "                    if match:\n",
    "                        value = match.group(0)  #group will give the value of the match object\n",
    "                        \n",
    "                        if token_type == 'WHITESPACE':\n",
    "                            #whitespace is not yielded becuz parser receives stream of tokens without space and doesnt care about space\n",
    "                            # Just update column and continue\n",
    "                            self.column += len(value)\n",
    "                            i += len(value)\n",
    "                            continue\n",
    "                        elif token_type == 'COMMENT':\n",
    "                            # Ignore comments\n",
    "                            i += len(value)\n",
    "                            self.column += len(value)\n",
    "                            break   # Break out of the current character processing loop after handling comments\n",
    "                        else:\n",
    "                            # For all other tokens\n",
    "                            token = Token(token_type, value, self.line, self.column)\n",
    "                            yield token\n",
    "                        \n",
    "                        i += len(value)\n",
    "                        self.column += len(value)\n",
    "                        break\n",
    "                \n",
    "                if not match:\n",
    "                    # No token matched, raise an error\n",
    "                    error_msg = f\"Invalid character: '{line_content[i]}'\"\n",
    "                    error = Error(error_msg, self.line, self.column)\n",
    "                    self.errors.append(error)\n",
    "                    print(error)  # Print the error but continue\n",
    "                    i += 1\n",
    "                    self.column += 1\n",
    "            \n",
    "            # Add NEWLINE at the end of each line except the last one\n",
    "            if line_num < len(lines) - 1 or self.source_code.endswith('\\n'):\n",
    "                yield Token('NEWLINE', '\\\\n', self.line, self.column)\n",
    "        \n",
    "        # Output any pending dedents at the end of the file\n",
    "        #end of file means all indented blocks have been dedented so pop all elements of the indent_levels stack\n",
    "        while len(self.indent_levels) > 1:\n",
    "            self.indent_levels.pop()    \n",
    "            yield Token('DEDENT', '', self.line, self.column)\n",
    "        \n",
    "        # End of file token\n",
    "        yield Token('EOF', '', self.line, self.column)\n",
    "    \n",
    "    def _handle_indentation(self, indent_size: int) -> List[Token]:\n",
    "        \"\"\"Handle Python's indentation-based block structure. Returns a list of INDENT or DEDENT tokens as needed.\"\"\"\n",
    "        tokens = []\n",
    "        previous_line_indent = self.indent_levels[-1]\n",
    "        \n",
    "        if indent_size > previous_line_indent:\n",
    "            # This is an indentation (start of a new block)\n",
    "            self.indent_levels.append(indent_size)  #when a new block is recognized through indentation its indentation level is pushed in the stack so that w ecan later check whether that block was dedented properly or not\n",
    "            tokens.append(Token('INDENT', ' ' * (indent_size - previous_line_indent), self.line, 1))\n",
    "        \n",
    "        elif indent_size < previous_line_indent:\n",
    "            # This is a dedentation (end of one or more blocks)\n",
    "            while self.indent_levels and indent_size < self.indent_levels[-1]: # ensuring that the latest code block is being dedented\n",
    "                self.indent_levels.pop()\n",
    "                tokens.append(Token('DEDENT', '', self.line, 1))\n",
    "            \n",
    "            if indent_size != self.indent_levels[-1]:\n",
    "                # Invalid indentation\n",
    "                error_msg = f\"Inconsistent indentation\"\n",
    "                error = Error(error_msg, self.line, 1)\n",
    "                self.errors.append(error)\n",
    "                print(error)  # Print the error but continue\n",
    "                \n",
    "                \n",
    "                # and what about handling indent_size == self.indent_levels[-1]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b0182e",
   "metadata": {},
   "source": [
    "## Test Script for Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c75670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lexer(source_code, test_name=\"\"):\n",
    "    print(f\"\\n=== Testing {test_name} ===\")\n",
    "    print(f\"Source code:\\n{source_code}\")\n",
    "    print(\"\\nTokens:\")\n",
    "    \n",
    "    lexer = Lexer(source_code)\n",
    "    token_count = 0\n",
    "    \n",
    "    try:\n",
    "        for token in lexer.tokenize():\n",
    "            print(token)\n",
    "            token_count += 1\n",
    "        \n",
    "        print(f\"\\nTotal tokens: {token_count}\")\n",
    "        if lexer.errors:\n",
    "            print(f\"\\nErrors ({len(lexer.errors)}):\")\n",
    "            for error in lexer.errors:\n",
    "                print(f\"  {error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Test cases\n",
    "if __name__ == \"__main__\":\n",
    "    # Test 1: Basic variable assignment\n",
    "    test_lexer(\"x = 10\", \"Basic Assignment\")\n",
    "\n",
    "    # Test 2: Simple function definition\n",
    "    test_lexer(\"\"\"def add(a, b):\n",
    "    return a + b\"\"\", \"Function Definition\")\n",
    "\n",
    "    # Test 3: If statement with proper indentation\n",
    "    test_lexer(\"\"\"if x > 10:\n",
    "    print(\"Greater than 10\")\n",
    "else:\n",
    "    print(\"Less than or equal to 10\")\"\"\", \"If Statement\")\n",
    "\n",
    "    # Test 4: Various literals and operators\n",
    "    test_lexer(\"\"\"# Testing literals\n",
    "x = 42\n",
    "y = 3.14\n",
    "name = \"John\"\n",
    "flag = True\n",
    "result = x + y * 2\n",
    "equal = x == y\"\"\", \"Literals and Operators\")\n",
    "\n",
    "    # Test 5: Loops\n",
    "    test_lexer(\"\"\"# Testing loops\n",
    "for i in range(10):\n",
    "    if i % 2 == 0:\n",
    "        print(\"Even\")\n",
    "    else:\n",
    "        print(\"Odd\")\n",
    "\n",
    "# While loop\n",
    "count = 0\n",
    "while count < 5:\n",
    "    count += 1\n",
    "\"\"\", \"Loops\")\n",
    "\n",
    "    # Test 6: Test error handling\n",
    "    test_lexer(\"x = 10 @\", \"Error Handling\")\n",
    "\n",
    "    # Test 7: Test inconsistent indentation\n",
    "    test_lexer(\"\"\"def test():\n",
    "    x = 1\n",
    "   y = 2  # Inconsistent indentation\n",
    "\"\"\", \"Inconsistent Indentation\")\n",
    "\n",
    "    # Interactive testing option\n",
    "    do_interactive = input(\"\\nDo you want to run an interactive test? (y/n): \")\n",
    "    if do_interactive.lower() == 'y':\n",
    "        print(\"\\n=== Interactive Lexer Test ===\")\n",
    "        print(\"Enter Python code (type 'exit()' on a new line to finish):\")\n",
    "        \n",
    "        lines = []\n",
    "        while True:\n",
    "            line = input(\"> \")\n",
    "            if line.strip() == \"exit()\":\n",
    "                break\n",
    "            lines.append(line)\n",
    "        \n",
    "        source_code = \"\\n\".join(lines)\n",
    "        test_lexer(source_code, \"Interactive Input\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452263c9",
   "metadata": {},
   "source": [
    "## ***ABSTRACT SYNTAX TREE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e402a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file is of abstract syntax tree (AST) node definitions.\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "# Base class for all AST nodes ASTNode is the base (parent) class for all other AST node types.\n",
    "#It doesnâ€™t do anything itself, but helps us group all node types together under one type.\n",
    "\n",
    "class ASTNode:\n",
    "    pass\n",
    "\n",
    "# Root node; body is a list of things in the program like function definitions, statements, etc.\n",
    "@dataclass\n",
    "class Program(ASTNode):\n",
    "    body: List[ASTNode]\n",
    "\n",
    "# Statements\n",
    "@dataclass\n",
    "class FunctionDef(ASTNode):\n",
    "    name: str\n",
    "    params: List[str]\n",
    "    body: List[ASTNode]\n",
    "\n",
    "@dataclass\n",
    "class IfStatement(ASTNode):\n",
    "    condition: ASTNode\n",
    "    then_branch: List[ASTNode]\n",
    "    elif_branches: List[tuple[ASTNode, List[ASTNode]]]\n",
    "    else_branch: Optional[List[ASTNode]]\n",
    "\n",
    "@dataclass\n",
    "class WhileLoop(ASTNode):\n",
    "    condition: ASTNode\n",
    "    body: List[ASTNode]\n",
    "\n",
    "@dataclass\n",
    "class ForLoop(ASTNode):\n",
    "    var: str\n",
    "    iterable: ASTNode\n",
    "    body: List[ASTNode]\n",
    "\n",
    "@dataclass\n",
    "class Return(ASTNode):\n",
    "    value: Optional[ASTNode]\n",
    "\n",
    "@dataclass\n",
    "class Assignment(ASTNode):\n",
    "    target: str\n",
    "    value: ASTNode\n",
    "\n",
    "@dataclass\n",
    "class ExpressionStatement(ASTNode):\n",
    "    expression: ASTNode\n",
    "\n",
    "# Expressions\n",
    "@dataclass\n",
    "class BinaryOp(ASTNode):\n",
    "    left: ASTNode\n",
    "    operator: str\n",
    "    right: ASTNode\n",
    "\n",
    "@dataclass\n",
    "class UnaryOp(ASTNode):\n",
    "    operator: str\n",
    "    operand: ASTNode\n",
    "\n",
    "@dataclass\n",
    "class Call(ASTNode):\n",
    "    func: ASTNode\n",
    "    args: List[ASTNode]\n",
    "\n",
    "@dataclass\n",
    "class Identifier(ASTNode):\n",
    "    name: str\n",
    "\n",
    "@dataclass\n",
    "class Literal(ASTNode):\n",
    "    value: Union[str, int, float, bool, None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13823b3",
   "metadata": {},
   "source": [
    "## ***AST VISUALIZER***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e2c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from typing import Union, List\n",
    "\n",
    "def print_ast(node: ASTNode, indent: str = ''):\n",
    "    \"\"\"Print the AST in a tree-like structure in the console.\"\"\"\n",
    "    if isinstance(node, Program):\n",
    "        print(indent + \"Program\")\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"  \")\n",
    "    elif isinstance(node, FunctionDef):\n",
    "        print(indent + f\"FunctionDef({node.name})\")\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"  \")\n",
    "    elif isinstance(node, IfStatement):\n",
    "        print(indent + \"IfStatement\")\n",
    "        print(indent + \"  Condition:\")\n",
    "        print_ast(node.condition, indent + \"    \")\n",
    "        print(indent + \"  Then:\")\n",
    "        for stmt in node.then_branch:\n",
    "            print_ast(stmt, indent + \"    \")\n",
    "        for cond, branch in node.elif_branches:\n",
    "            print(indent + \"  Elif:\")\n",
    "            print_ast(cond, indent + \"    \")\n",
    "            for stmt in branch:\n",
    "                print_ast(stmt, indent + \"      \")\n",
    "        if node.else_branch:\n",
    "            print(indent + \"  Else:\")\n",
    "            for stmt in node.else_branch:\n",
    "                print_ast(stmt, indent + \"    \")\n",
    "    elif isinstance(node, WhileLoop):\n",
    "        print(indent + \"WhileLoop\")\n",
    "        print(indent + \"  Condition:\")\n",
    "        print_ast(node.condition, indent + \"    \")\n",
    "        print(indent + \"  Body:\")\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"    \")\n",
    "    elif isinstance(node, ForLoop):\n",
    "        print(indent + f\"ForLoop(var={node.var})\")\n",
    "        print(indent + \"  Iterable:\")\n",
    "        print_ast(node.iterable, indent + \"    \")\n",
    "        print(indent + \"  Body:\")\n",
    "        for stmt in node.body:\n",
    "            print_ast(stmt, indent + \"    \")\n",
    "    elif isinstance(node, Return):\n",
    "        print(indent + \"Return\")\n",
    "        if node.value:\n",
    "            print_ast(node.value, indent + \"  \")\n",
    "    elif isinstance(node, Assignment):\n",
    "        print(indent + f\"Assignment(target={node.target})\")\n",
    "        print_ast(node.value, indent + \"  \")\n",
    "    elif isinstance(node, ExpressionStatement):\n",
    "        print(indent + \"ExpressionStatement\")\n",
    "        print_ast(node.expression, indent + \"  \")\n",
    "    elif isinstance(node, BinaryOp):\n",
    "        print(indent + f\"BinaryOp({node.operator})\")\n",
    "        print_ast(node.left, indent + \"  \")\n",
    "        print_ast(node.right, indent + \"  \")\n",
    "    elif isinstance(node, UnaryOp):\n",
    "        print(indent + f\"UnaryOp({node.operator})\")\n",
    "        print_ast(node.operand, indent + \"  \")\n",
    "    elif isinstance(node, Call):\n",
    "        print(indent + \"Call\")\n",
    "        print_ast(node.func, indent + \"  \")\n",
    "        for arg in node.args:\n",
    "            print_ast(arg, indent + \"    \")\n",
    "    elif isinstance(node, Identifier):\n",
    "        print(indent + f\"Identifier({node.name})\")\n",
    "    elif isinstance(node, Literal):\n",
    "        print(indent + f\"Literal({repr(node.value)})\")\n",
    "    else:\n",
    "        print(indent + f\"UnknownNode({node})\")\n",
    "\n",
    "# Optional: Graphviz visualizer\n",
    "def visualize_ast(node: ASTNode) -> Digraph:\n",
    "    dot = Digraph()\n",
    "    _build_graph(node, dot)\n",
    "    return dot\n",
    "\n",
    "def _build_graph(node: ASTNode, dot: Digraph, parent: str = None, counter=[0]):\n",
    "    node_id = f\"node{counter[0]}\"\n",
    "    counter[0] += 1\n",
    "\n",
    "    label = type(node).__name__\n",
    "    if isinstance(node, Identifier):\n",
    "        label += f\"({node.name})\"\n",
    "    elif isinstance(node, Literal):\n",
    "        label += f\"({repr(node.value)})\"\n",
    "    elif isinstance(node, Assignment):\n",
    "        label += f\"({node.target})\"\n",
    "    elif isinstance(node, BinaryOp):\n",
    "        label += f\"({node.operator})\"\n",
    "    elif isinstance(node, UnaryOp):\n",
    "        label += f\"({node.operator})\"\n",
    "    elif isinstance(node, FunctionDef):\n",
    "        label += f\"({node.name})\"\n",
    "    elif isinstance(node, ForLoop):\n",
    "        label += f\"({node.var})\"\n",
    "\n",
    "    dot.node(node_id, label)\n",
    "\n",
    "    if parent:\n",
    "        dot.edge(parent, node_id)\n",
    "\n",
    "    for field in getattr(node, '__dataclass_fields__', {}):\n",
    "        child = getattr(node, field)\n",
    "        if isinstance(child, ASTNode):\n",
    "            _build_graph(child, dot, node_id, counter)\n",
    "        elif isinstance(child, list):\n",
    "            for item in child:\n",
    "                if isinstance(item, ASTNode):\n",
    "                    _build_graph(item, dot, node_id, counter)\n",
    "        elif isinstance(child, tuple):\n",
    "            for item in child:\n",
    "                if isinstance(item, ASTNode):\n",
    "                    _build_graph(item, dot, node_id, counter)\n",
    "\n",
    "    return dot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104272b6",
   "metadata": {},
   "source": [
    "## ***PARSER***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0823d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser.py\n",
    "\n",
    "from treeNodes import *  # Import AST node classes like Program, Identifier, etc.\n",
    "\n",
    "# Custom error class for parser errors\n",
    "class ParserError(Exception):\n",
    "    pass\n",
    "\n",
    "# Parser class converts tokens into an AST\n",
    "class Parser:\n",
    "    def __init__(self, lexer: Lexer):\n",
    "        self.tokens = list(lexer.tokenize())  # Convert lexer generator into list of tokens\n",
    "        self.pos = 0  # Current position in token list\n",
    "        self.current_token = self.tokens[self.pos]  # Currently looked-at token\n",
    "\n",
    "    def error(self, msg: str):\n",
    "        # Raise a ParserError with current token's position\n",
    "        raise ParserError(f\"{msg} at line {self.current_token.line}, column {self.current_token.column}\")\n",
    "    \n",
    "    def skip_newlines(self):\n",
    "        # Ignore NEWLINE tokens before/after blocks or statements\n",
    "        while self.current_token.type == 'NEWLINE':\n",
    "            self.advance()\n",
    "\n",
    "    def advance(self):\n",
    "        # Move to the next token\n",
    "        self.pos += 1\n",
    "        if self.pos < len(self.tokens):\n",
    "            self.current_token = self.tokens[self.pos]\n",
    "\n",
    "    def expect(self, token_type: str):\n",
    "        # Ensure the current token is of the expected type, or throw error\n",
    "        if self.current_token.type == token_type:\n",
    "            self.advance()\n",
    "        else:\n",
    "            self.error(f\"Expected token {token_type}, got {self.current_token.type}\")\n",
    "\n",
    "    def match(self, token_type: str):\n",
    "        # Match a token and advance if matched\n",
    "        if self.current_token.type == token_type:\n",
    "            self.advance()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def parse(self) -> Program:\n",
    "        # Parse a full program (list of statements)\n",
    "        body = []\n",
    "        self.skip_newlines()\n",
    "        while self.current_token.type != 'EOF':\n",
    "            stmt = self.parse_statement()\n",
    "            if stmt:\n",
    "                body.append(stmt)\n",
    "            self.skip_newlines()\n",
    "        return Program(body)\n",
    "\n",
    "    def parse_statement(self) -> ASTNode:\n",
    "        # Decide which type of statement to parse\n",
    "        if self.current_token.type == 'KEYWORD':\n",
    "            if self.current_token.value == 'def':\n",
    "                return self.parse_function_def()\n",
    "            elif self.current_token.value == 'return':\n",
    "                return self.parse_return()\n",
    "            elif self.current_token.value == 'if':\n",
    "                return self.parse_if()\n",
    "            elif self.current_token.value == 'while':\n",
    "                return self.parse_while()\n",
    "            elif self.current_token.value == 'for':\n",
    "                return self.parse_for()\n",
    "\n",
    "        # If not a keyword, it's either an assignment or expression\n",
    "        expr = self.parse_expression()\n",
    "        if isinstance(expr, Identifier) and self.match('OP_ASSIGN'):\n",
    "            value = self.parse_expression()\n",
    "            return Assignment(target=expr.name, value=value)\n",
    "        return ExpressionStatement(expr)\n",
    "\n",
    "    def parse_function_def(self) -> FunctionDef:\n",
    "        # Parse function definition: def name(params):\\n  <body>\n",
    "        self.expect('KEYWORD')  # 'def'\n",
    "        if self.current_token.type != 'IDENTIFIER':\n",
    "            self.error(\"Expected function name\")\n",
    "        name = self.current_token.value\n",
    "        self.advance()\n",
    "        self.expect('LPAREN')\n",
    "\n",
    "        # Parse parameter list\n",
    "        params = []\n",
    "        if self.current_token.type != 'RPAREN':\n",
    "            while True:\n",
    "                if self.current_token.type != 'IDENTIFIER':\n",
    "                    self.error(\"Expected parameter name\")\n",
    "                params.append(self.current_token.value)\n",
    "                self.advance()\n",
    "                if not self.match('COMMA'):\n",
    "                    break\n",
    "\n",
    "        self.expect('RPAREN')\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        body = self.parse_block()\n",
    "        return FunctionDef(name=name, params=params, body=body)\n",
    "\n",
    "    def parse_return(self) -> Return:\n",
    "        # Parse return statement\n",
    "        self.expect('KEYWORD')  # 'return'\n",
    "        if self.current_token.type == 'NEWLINE':\n",
    "            return Return(value=None)\n",
    "        value = self.parse_expression()\n",
    "        return Return(value=value)\n",
    "\n",
    "    def parse_if(self) -> IfStatement:\n",
    "        # Parse if-elif-else statement\n",
    "        self.expect('KEYWORD')  # 'if'\n",
    "        condition = self.parse_expression()\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        then_branch = self.parse_block()\n",
    "\n",
    "        elif_branches = []\n",
    "        # Handle optional elif blocks\n",
    "        while self.current_token.type == 'KEYWORD' and self.current_token.value == 'elif':\n",
    "            self.advance()\n",
    "            cond = self.parse_expression()\n",
    "            self.expect('COLON')\n",
    "            self.expect('NEWLINE')\n",
    "            self.expect('INDENT')\n",
    "            body = self.parse_block()\n",
    "            elif_branches.append((cond, body))\n",
    "\n",
    "        else_branch = None\n",
    "        # Handle optional else block\n",
    "        if self.current_token.type == 'KEYWORD' and self.current_token.value == 'else':\n",
    "            self.advance()\n",
    "            self.expect('COLON')\n",
    "            self.expect('NEWLINE')\n",
    "            self.expect('INDENT')\n",
    "            else_branch = self.parse_block()\n",
    "\n",
    "        return IfStatement(condition, then_branch, elif_branches, else_branch)\n",
    "\n",
    "    def parse_while(self) -> WhileLoop:\n",
    "        # Parse while loop\n",
    "        self.expect('KEYWORD')  # 'while'\n",
    "        condition = self.parse_expression()\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        body = self.parse_block()\n",
    "        return WhileLoop(condition, body)\n",
    "\n",
    "    def parse_for(self) -> ForLoop:\n",
    "        # Parse for loop: for x in iterable:\n",
    "        self.expect('KEYWORD')  # 'for'\n",
    "        if self.current_token.type != 'IDENTIFIER':\n",
    "            self.error(\"Expected variable name\")\n",
    "        var = self.current_token.value\n",
    "        self.advance()\n",
    "        self.expect('KEYWORD')  # 'in'\n",
    "        iterable = self.parse_expression()\n",
    "        self.expect('COLON')\n",
    "        self.expect('NEWLINE')\n",
    "        self.expect('INDENT')\n",
    "        body = self.parse_block()\n",
    "        return ForLoop(var, iterable, body)\n",
    "\n",
    "    def parse_block(self) -> List[ASTNode]:\n",
    "        # Parse an indented block of statements\n",
    "        body = []\n",
    "        self.skip_newlines()\n",
    "        while self.current_token.type not in ('DEDENT', 'EOF'):\n",
    "            stmt = self.parse_statement()\n",
    "            if stmt:\n",
    "                body.append(stmt)\n",
    "            self.skip_newlines()\n",
    "        self.expect('DEDENT')\n",
    "        return body\n",
    "\n",
    "    def parse_expression(self, precedence=0) -> ASTNode:\n",
    "        # Parse binary expressions with precedence (e.g., 1 + 2 * 3)\n",
    "        left = self.parse_primary()\n",
    "        while self.is_operator(self.current_token) and self.get_precedence(self.current_token) >= precedence:\n",
    "            op_token = self.current_token\n",
    "            self.advance()\n",
    "            right = self.parse_expression(self.get_precedence(op_token) + 1)\n",
    "            left = BinaryOp(left=left, operator=op_token.value, right=right)\n",
    "        return left\n",
    "\n",
    "    def parse_primary(self) -> ASTNode:\n",
    "        # Parse literals, variables, function calls, unary ops, and parenthesis\n",
    "        token = self.current_token\n",
    "        if token.type == 'INTEGER':\n",
    "            self.advance()\n",
    "            return Literal(value=int(token.value))\n",
    "        elif token.type == 'FLOAT':\n",
    "            self.advance()\n",
    "            return Literal(value=float(token.value))\n",
    "        elif token.type == 'STRING':\n",
    "            self.advance()\n",
    "            return Literal(value=token.value[1:-1])  # Remove surrounding quotes\n",
    "        elif token.type == 'KEYWORD':\n",
    "            if token.value in ('True', 'False', 'None'):\n",
    "                self.advance()\n",
    "                val = {'True': True, 'False': False, 'None': None}[token.value]\n",
    "                return Literal(val)\n",
    "        elif token.type == 'IDENTIFIER':\n",
    "            self.advance()\n",
    "            if self.match('LPAREN'):  # Function call\n",
    "                args = []\n",
    "                if self.current_token.type != 'RPAREN':\n",
    "                    while True:\n",
    "                        args.append(self.parse_expression())\n",
    "                        if not self.match('COMMA'):\n",
    "                            break\n",
    "                self.expect('RPAREN')\n",
    "                return Call(func=Identifier(token.value), args=args)\n",
    "            return Identifier(name=token.value)\n",
    "        elif token.type == 'OP_MINUS':\n",
    "            self.advance()\n",
    "            operand = self.parse_primary()\n",
    "            return UnaryOp(operator='-', operand=operand)\n",
    "        elif token.type == 'LPAREN':\n",
    "            self.advance()\n",
    "            expr = self.parse_expression()\n",
    "            self.expect('RPAREN')\n",
    "            return expr\n",
    "        else:\n",
    "            self.error(f\"Unexpected token {token}\")\n",
    "\n",
    "    def is_operator(self, token: Token) -> bool:\n",
    "        # Check if token is an operator\n",
    "        return token.type.startswith('OP_')\n",
    "\n",
    "    def get_precedence(self, token: Token) -> int:\n",
    "        # Define operator precedence levels (higher = tighter binding)\n",
    "        precedence = {\n",
    "            'OP_OR': 1,\n",
    "            'OP_AND': 2,\n",
    "            'OP_EQ': 3, 'OP_NE': 3,\n",
    "            'OP_LT': 4, 'OP_LE': 4, 'OP_GT': 4, 'OP_GE': 4,\n",
    "            'OP_PLUS': 5, 'OP_MINUS': 5,\n",
    "            'OP_MULT': 6, 'OP_MOD': 6,\n",
    "            'OP_ASSIGN': 0,  # Assignment is handled separately\n",
    "        }\n",
    "        return precedence.get(token.type, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb48a8bc",
   "metadata": {},
   "source": [
    "## Testing upto parser and AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd7c4e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program\n",
      "  FunctionDef(factorial)\n",
      "    IfStatement\n",
      "      Condition:\n",
      "        BinaryOp(==)\n",
      "          Identifier(n)\n",
      "          Literal(0)\n",
      "      Then:\n",
      "        Return\n",
      "          Literal(1)\n",
      "      Else:\n",
      "        Return\n",
      "          BinaryOp(*)\n",
      "            Identifier(n)\n",
      "            Call\n",
      "              Identifier(factorial)\n",
      "                BinaryOp(-)\n",
      "                  Identifier(n)\n",
      "                  Literal(1)\n",
      "  FunctionDef(is_even)\n",
      "    Return\n",
      "      BinaryOp(==)\n",
      "        BinaryOp(%)\n",
      "          Identifier(num)\n",
      "          Literal(2)\n",
      "        Literal(0)\n",
      "  ExpressionStatement\n",
      "    BinaryOp(=)\n",
      "      Identifier(x)\n",
      "      Literal(5)\n",
      "  ExpressionStatement\n",
      "    BinaryOp(=)\n",
      "      Identifier(fact)\n",
      "      Call\n",
      "        Identifier(factorial)\n",
      "          Identifier(x)\n",
      "  IfStatement\n",
      "    Condition:\n",
      "      Call\n",
      "        Identifier(is_even)\n",
      "          Identifier(fact)\n",
      "    Then:\n",
      "      ExpressionStatement\n",
      "        Call\n",
      "          Identifier(print)\n",
      "            Literal('Even factorial')\n",
      "    Else:\n",
      "      ExpressionStatement\n",
      "        Call\n",
      "          Identifier(print)\n",
      "            Literal('Odd factorial')\n",
      "  ForLoop(var=i)\n",
      "    Iterable:\n",
      "      Call\n",
      "        Identifier(range)\n",
      "          Literal(3)\n",
      "    Body:\n",
      "      ExpressionStatement\n",
      "        BinaryOp(=)\n",
      "          Identifier(result)\n",
      "          Call\n",
      "            Identifier(factorial)\n",
      "              Identifier(i)\n",
      "      ExpressionStatement\n",
      "        Call\n",
      "          Identifier(print)\n",
      "            Identifier(result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ast_tree.png'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# code = '''\n",
    "# def add(x, y):\n",
    "#     return x + y\n",
    "\n",
    "# a = add(3, 5)\n",
    "# '''\n",
    "\n",
    "# code = \"\"\"\n",
    "# def foo(x):\n",
    "#     if x > 0:\n",
    "#         return x\n",
    "#     else:\n",
    "#         return -x\n",
    "# \"\"\"\n",
    "\n",
    "code = '''\n",
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n - 1)\n",
    "\n",
    "def is_even(num):\n",
    "    return num % 2 == 0\n",
    "\n",
    "x = 5\n",
    "fact = factorial(x)\n",
    "\n",
    "if is_even(fact):\n",
    "    print(\"Even factorial\")\n",
    "else:\n",
    "    print(\"Odd factorial\")\n",
    "\n",
    "for i in range(3):\n",
    "    result = factorial(i)\n",
    "    print(result)\n",
    "'''\n",
    "\n",
    "\n",
    "lexer = Lexer(code)\n",
    "parser = Parser(lexer)\n",
    "ast = parser.parse()\n",
    "\n",
    "#Console view\n",
    "print_ast(ast)\n",
    "\n",
    "\n",
    "#graph\n",
    "dot = visualize_ast(ast)\n",
    "dot.render('ast_tree', view=True, format='png')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
